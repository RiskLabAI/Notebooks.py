{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d517ed2e",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center; width: 100%;\">  \n",
    "  <div style=\"display: flex; flex-direction: column; align-items: center; justify-content: center; width: 100px; margin-right: 20px;\">    \n",
    "    <a href=\"https://risklab.ai\" style=\"border: 0; line-height: 1;\">\n",
    "      <img src=\"../../utils/risklab_ai.gif\" width=\"100px\" style=\"border: 0; vertical-align: middle;\"/>\n",
    "    </a>\n",
    "  </div>  \n",
    "  <div style=\"flex-grow: 1;\">\n",
    "    <h1 style=\"margin: 0; font-weight: bold; text-align: left; font-size: 38px;\">\n",
    "      The Power of CPCV\n",
    "    </h1>\n",
    "  </div>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a68e31",
   "metadata": {},
   "source": [
    "In the previous tutorial, we used `PurgedKFold` to get a single, reliable out-of-sample (OOS) accuracy score. But this leads to a critical question:\n",
    "\n",
    "**\"How do we know we weren't just lucky?\"**\n",
    "\n",
    "A single backtest path, even a purged one, could be an outlier. `CombinatorialPurged` (CPCV) solves this. Instead of one path, it runs *many* backtest paths by combining different train/test splits. This allows us to see the **distribution** of performance metrics, giving a much more robust assessment of our strategy.\n",
    "\n",
    "This notebook will show you how to:\n",
    "1.  Run `CombinatorialPurged` (CPCV) to get *all* backtest paths.\n",
    "2.  Run `BaggedCombinatorialPurged` (B-CPCV) to see the effect of bagging.\n",
    "3.  Run `AdaptiveCombinatorialPurged` (A-CPCV) to see feature-based splits.\n",
    "4.  Plot a histogram of these performance scores to compare their distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup and Imports\n",
    "\n",
    "This setup is identical to the `PurgedKFold` tutorial for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335644c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Third-party for data and modeling\n",
    "import yfinance as yf\n",
    "import ta\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# RiskLabAI Imports\n",
    "from RiskLabAI.backtest.validation import CrossValidatorController\n",
    "import RiskLabAI.utils.publication_plots as pub_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbba82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib style updated. Theme: 'dark', Quality: 300 DPI.\n",
      "Plot saving enabled. Saving to: 'figs'\n"
     ]
    }
   ],
   "source": [
    "# Global Plotting Settings\n",
    "SAVE_PLOTS = False  \n",
    "PLOT_THEME = 'dark' # Options: 'light', 'medium'. 'dark', 'light-transparent', \n",
    "PLOT_QUALITY = 300  \n",
    "SAVE_DIR = 'figs'     \n",
    "\n",
    "pub_plots.setup_publication_style(\n",
    "    theme=PLOT_THEME,\n",
    "    quality=PLOT_QUALITY,\n",
    "    save_plots=SAVE_PLOTS,\n",
    "    save_dir=SAVE_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86535aa4",
   "metadata": {},
   "source": [
    "## 1. Load Data & Generate Signals\n",
    "\n",
    "We use the same data generation as the previous tutorial to create our `X`, `y`, and `event_times`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "068d174c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SPY (ETF) Data Loaded (TZ-Naive) ---\n",
      "Aligned data shapes: X=(3761, 2), y=(3761,), t1=(3761,)\n",
      "                  rsi       roc\n",
      "Date                           \n",
      "2010-01-22  27.005684 -4.361140\n",
      "2010-01-25  31.251067 -4.189553\n",
      "2010-01-26  29.721870 -4.724122\n",
      "2010-01-27  33.673012 -3.369715\n",
      "2010-01-28  29.364934 -5.278273\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import ta\n",
    "from ta.utils import dropna\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "ticker_symbol = \"SPY\"\n",
    "start_date = \"2010-01-01\"\n",
    "end_date = \"2025-01-01\"\n",
    "\n",
    "data = yf.Ticker(ticker_symbol).history(\n",
    "    start=start_date, \n",
    "    end=end_date, \n",
    "    auto_adjust=True\n",
    ")\n",
    "\n",
    "# --- CRITICAL FIX: Remove timezone information to prevent comparison errors ---\n",
    "data.index = data.index.tz_localize(None)\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# --- 2. Generate Features (X) ---\n",
    "X = pd.DataFrame(index=data.index)\n",
    "X['rsi'] = ta.momentum.RSIIndicator(data['Close'], window=14).rsi()\n",
    "X['roc'] = ta.momentum.ROCIndicator(data['Close'], window=10).roc()\n",
    "\n",
    "# --- 3. Generate Labels (y) ---\n",
    "look_forward = 20\n",
    "y = data['Close'].pct_change(look_forward).shift(-look_forward)\n",
    "y = pd.Series((y > 0).astype(int), name='label')\n",
    "\n",
    "# --- 4. Define Event Times (t1) ---\n",
    "event_times = pd.Series(y.index, index=y.index).apply(lambda x: x + pd.DateOffset(days=look_forward))\n",
    "\n",
    "# --- 5. Align Data ---\n",
    "all_data = pd.concat([X, y, event_times.rename('t1')], axis=1).dropna()\n",
    "\n",
    "X = all_data.drop(columns=['label', 't1'])\n",
    "y = all_data['label']\n",
    "event_times = all_data['t1']\n",
    "\n",
    "# --- NEW: Create a feature for A-CPCV ---\n",
    "X_rsi_feature = X['rsi']\n",
    "# --------------------------------------\n",
    "\n",
    "print(f\"--- SPY (ETF) Data Loaded (TZ-Naive) ---\")\n",
    "print(f\"Aligned data shapes: X={X.shape}, y={y.shape}, t1={event_times.shape}\")\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Backtest Parameters\n",
    "\n",
    "We define the common parameters for our backtests.\n",
    "\n",
    "* `n_splits = 10`: The data is split into 10 groups.\n",
    "* `n_test_groups = 2`: Each test set will consist of 2 of these groups.\n",
    "\n",
    "This will generate $C(10-1, 2-1) = 9$ total backtest paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters defined: n_splits=10, n_test_groups=2\n"
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "n_test_groups = 2\n",
    "embargo_pct = 0.01\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "print(f\"Parameters defined: n_splits={n_splits}, n_test_groups={n_test_groups}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Standard CPCV (Combinatorial Purged)\n",
    "\n",
    "First, we run the standard `CombinatorialPurged` validator. This is the baseline for our combinatorial analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Standard CPCV... (This may take a moment)\n",
      "Backtest complete.\n",
      "Received 9 backtest paths.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Instantiate the Validator ---\n",
    "cv_controller_cpcv = CrossValidatorController(\n",
    "    validator_type='combinatorialpurged',\n",
    "    n_splits=n_splits,\n",
    "    n_test_groups=n_test_groups,\n",
    "    times=event_times,\n",
    "    embargo=embargo_pct\n",
    ")\n",
    "cv_cpcv = cv_controller_cpcv.get_validator()\n",
    "\n",
    "# --- 2. Run All Backtest Paths --- \n",
    "print(f\"Running Standard CPCV... (This may take a moment)\")\n",
    "paths_preds_cpcv = cv_cpcv.backtest_predictions(\n",
    "    estimator=model,\n",
    "    data=X,\n",
    "    labels=y,\n",
    "    n_jobs=-1 # Parallelize the training of C(10,2) = 45 estimators\n",
    ")\n",
    "\n",
    "print(f\"Backtest complete.\")\n",
    "print(f\"Received {len(paths_preds_cpcv)} backtest paths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the Distribution of Performance\n",
    "\n",
    "`paths_preds_cpcv` is a dictionary where each key is a path ID and each value is the OOS prediction array for that path.\n",
    "\n",
    "We can now calculate the accuracy for *each path* and see the full distribution of our model's performance.\n",
    "\n",
    "**NOTE:** The accuracy calculation here is fixed. We must `dropna()` from the prediction series first, as it's sparse, and *then* align `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating accuracy for each CPCV path...\n",
      "  Path 1: Accuracy = 60.49%\n",
      "  Path 2: Accuracy = 60.25%\n",
      "  Path 3: Accuracy = 59.77%\n",
      "  Path 4: Accuracy = 60.57%\n",
      "  Path 5: Accuracy = 59.77%\n",
      "  Path 6: Accuracy = 60.14%\n",
      "  Path 7: Accuracy = 60.41%\n",
      "  Path 8: Accuracy = 61.95%\n",
      "  Path 9: Accuracy = 60.62%\n"
     ]
    }
   ],
   "source": [
    "path_accuracies_cpcv = []\n",
    "\n",
    "print(\"Calculating accuracy for each CPCV path...\")\n",
    "for path_name, predictions in paths_preds_cpcv.items():\n",
    "    \n",
    "    # --- BUG FIX: Correctly score sparse predictions ---\n",
    "    # 1. Create series from array, aligned with original index\n",
    "    pred_series = pd.Series(predictions, index=y.index)\n",
    "    \n",
    "    # 2. Drop NaNs (samples not in a test set for this path)\n",
    "    pred_series = pred_series.dropna()\n",
    "    \n",
    "    # 3. Align the true labels to the prediction index\n",
    "    y_true = y.loc[pred_series.index]\n",
    "    \n",
    "    # 4. Calculate accuracy\n",
    "    acc = accuracy_score(y_true, pred_series)\n",
    "    # -----------------------------------------------------\n",
    "    \n",
    "    path_accuracies_cpcv.append(acc)\n",
    "    print(f\"  {path_name}: Accuracy = {acc * 100:.2f}%\")\n",
    "\n",
    "path_accuracies_cpcv = pd.Series(path_accuracies_cpcv, name='CPCV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bagged CPCV (B-CPCV)\n",
    "\n",
    "Now we run the `BaggedCombinatorialPurged` validator. This applies a BaggingClassifier *wrapper* to each of the $C(n,k)$ estimators, helping to reduce variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Bagged CPCV (B-CPCV)... (This may take a moment)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Instantiate the B-CPCV Validator ---\n",
    "cv_controller_bcpvc = CrossValidatorController(\n",
    "    validator_type='baggedcombinatorialpurged',\n",
    "    n_splits=n_splits,\n",
    "    n_test_groups=n_test_groups,\n",
    "    times=event_times,\n",
    "    embargo=embargo_pct,\n",
    "    # Bagging-specific params\n",
    "    n_estimators=10,      # Number of bags per split\n",
    "    max_samples=0.5,      # 50% of samples per bag\n",
    "    random_state=42,\n",
    "    classifier=True\n",
    ")\n",
    "cv_bcpvc = cv_controller_bcpvc.get_validator()\n",
    "\n",
    "# --- 2. Run All Backtest Paths --- \n",
    "print(f\"Running Bagged CPCV (B-CPCV)... (This may take a moment)\")\n",
    "paths_preds_bcpvc = cv_bcpvc.backtest_predictions(\n",
    "    estimator=model, # The base estimator for bagging\n",
    "    data=X,\n",
    "    labels=y,\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f\"B-CPCV complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_accuracies_bcpvc = []\n",
    "print(\"Calculating accuracy for each B-CPCV path...\")\n",
    "for path_name, predictions in paths_preds_bcpvc.items():\n",
    "    pred_series = pd.Series(predictions, index=y.index).dropna()\n",
    "    y_true = y.loc[pred_series.index]\n",
    "    acc = accuracy_score(y_true, pred_series)\n",
    "    path_accuracies_bcpvc.append(acc)\n",
    "\n",
    "path_accuracies_bcpvc = pd.Series(path_accuracies_bcpvc, name='B-CPCV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Adaptive CPCV (A-CPCV)\n",
    "\n",
    "Finally, we run `AdaptiveCombinatorialPurged`. This advanced validator adjusts the split boundaries based on an `external_feature`. We will use the **RSI** we calculated earlier as our feature. This will make the splits non-uniform, creating test sets based on market regime (e.g., high/low RSI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Instantiate the A-CPCV Validator ---\n",
    "cv_controller_acpcv = CrossValidatorController(\n",
    "    validator_type='adaptivecombinatorialpurged',\n",
    "    n_splits=n_splits,\n",
    "    n_test_groups=n_test_groups,\n",
    "    times=event_times,\n",
    "    embargo=embargo_pct,\n",
    "    # Adaptive-specific params\n",
    "    external_feature=X_rsi_feature, # Use RSI to guide splits\n",
    "    n_subsplits=5, # Finer granularity for adjustment\n",
    "    lower_quantile=0.3,\n",
    "    upper_quantile=0.7\n",
    ")\n",
    "cv_acpcv = cv_controller_acpcv.get_validator()\n",
    "\n",
    "# --- 2. Run All Backtest Paths --- \n",
    "print(f\"Running Adaptive CPCV (A-CPCV)... (This may take a moment)\")\n",
    "paths_preds_acpcv = cv_acpcv.backtest_predictions(\n",
    "    estimator=model,\n",
    "    data=X,\n",
    "    labels=y,\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f\"A-CPCV complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_accuracies_acpcv = []\n",
    "print(\"Calculating accuracy for each A-CPCV path...\")\n",
    "for path_name, predictions in paths_preds_acpcv.items():\n",
    "    pred_series = pd.Series(predictions, index=y.index).dropna()\n",
    "    y_true = y.loc[pred_series.index]\n",
    "    acc = accuracy_score(y_true, pred_series)\n",
    "    path_accuracies_acpcv.append(acc)\n",
    "\n",
    "path_accuracies_acpcv = pd.Series(path_accuracies_acpcv, name='A-CPCV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Comparison\n",
    "\n",
    "Now we plot the histograms of all three combinatorial methods. We can clearly see how **B-CPCV** narrows the distribution, reducing the variance of the outcomes and giving us a more reliable estimate of the *true* mean performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Plot all three distributions\n",
    "sns.histplot(path_accuracies_cpcv, ax=ax, alpha=0.6, label='Standard CPCV', kde=True, stat='density')\n",
    "sns.histplot(path_accuracies_bcpvc, ax=ax, alpha=0.6, label='Bagged CPCV (B-CPCV)', kde=True, stat='density', color='#f37735')\n",
    "sns.histplot(path_accuracies_acpcv, ax=ax, alpha=0.6, label='Adaptive CPCV (A-CPCV)', kde=True, stat='density', color='#d11141')\n",
    "\n",
    "# Add mean lines\n",
    "ax.axvline(path_accuracies_cpcv.mean(), color='blue', linestyle='--', lw=2, label=f'CPCV Mean: {path_accuracies_cpcv.mean()*100:.2f}%')\n",
    "ax.axvline(path_accuracies_bcpvc.mean(), color='orange', linestyle='--', lw=2, label=f'B-CPCV Mean: {path_accuracies_bcpvc.mean()*100:.2f}%')\n",
    "ax.axvline(path_accuracies_acpcv.mean(), color='red', linestyle='--', lw=2, label=f'A-CPCV Mean: {path_accuracies_acpcv.mean()*100:.2f}%')\n",
    "\n",
    "# Apply standard styling\n",
    "pub_plots.apply_plot_style(\n",
    "    ax=ax,\n",
    "    title=f'Comparison of Combinatorial CV Path Accuracies (k={len(path_accuracies_cpcv)} paths)',\n",
    "    xlabel='Out-of-Sample Accuracy',\n",
    "    ylabel='Density',\n",
    "    legend_title='CV Method' # Give the legend a title\n",
    ")\n",
    "\n",
    "# Finalize (show and/or save)\n",
    "plt.tight_layout()\n",
    "pub_plots.finalize_plot(fig, 'cpcv_accuracy_comparison.png')\n",
    "\n",
    "print(\"--- Summary Statistics ---\")\n",
    "summary_df = pd.DataFrame({\n",
    "    'CPCV': path_accuracies_cpcv.describe(),\n",
    "    'B-CPCV': path_accuracies_bcpvc.describe(),\n",
    "    'A-CPCV': path_accuracies_acpcv.describe()\n",
    "})\n",
    "display(summary_df.to_markdown(floatfmt=\".4f\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risklab311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
