{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â­ Tutorial: Detecting Backtest Overfitting\n",
    "\n",
    "This notebook is a capstone tutorial for the `RiskLabAI` backtesting module. It demonstrates the complete workflow for detecting backtest overfitting, as described by De Prado (Chapters 10-14, 'Advances in Financial Machine Learning').\n",
    "\n",
    "The central problem in strategy selection is: **Is my 'best' strategy genuinely good, or did I just get lucky?**\n",
    "\n",
    "We will answer this by:\n",
    "1.  **Generating Synthetic Data:** Create a market environment and a set of (intentionally bad) trading strategies using `backtest_synthetic_data`.\n",
    "2.  **Running Simulations:** Execute all strategies and find the 'best' one using `backtest_overfitting_simulation`.\n",
    "3.  **Calculating PBO:** Use `get_pbo` to find the Probability of Backtest Overfitting. This tells us the likelihood that our 'best' strategy was a false discovery (a fluke).\n",
    "4.  **Calculating PSR:** Use `probabilistic_sharpe_ratio` to check if the 'best' strategy's Sharpe Ratio is statistically significant, given its skew and kurtosis.\n",
    "5.  **Running CSCV:** Use `combinatorial_symmetric_cross_validation` to find the combination of parameters that performs best *on average* across all tests, helping us find the *most robust* strategy, not just the one with the highest single SR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# RiskLabAI Imports\n",
    "from RiskLabAI.backtest.backtest_overfitting_simulation import run_backtest_overfitting_simulation\n",
    "from RiskLabAI.backtest.probabilistic_sharpe_ratio import probabilistic_sharpe_ratio, compute_psr_curve\n",
    "from RiskLabAI.backtest.probability_of_backtest_overfitting import get_pbo, pbo_overfitting_plot\n",
    "from RiskLabAI.backtest.test_set_overfitting import combinatorial_symmetric_cross_validation\n",
    "from RiskLabAI.backtest.backtest_statistics import annualized_sharpe_ratio\n",
    "import RiskLabAI.utils.publication_plots as pub_plots\n",
    "\n",
    "# Setup plotting and configuration\n",
    "pub_plots.setup_publication_style()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run the Backtest Overfitting Simulation\n",
    "\n",
    "First, we call the main orchestration function: `run_backtest_overfitting_simulation`.\n",
    "\n",
    "This function does a lot of work (using other modules we've built):\n",
    "1.  It calls `generate_market_data` to create a synthetic price history.\n",
    "2.  It generates `n_strategies` (100) different strategies with *no actual edge* (signal `t_value = 0.0`).\n",
    "3.  It 'backtests' all 100 of these strategies on the *same* price history.\n",
    "4.  It returns a DataFrame of the Sharpe Ratios (SR) for all 100 strategies, plus the SR for the single 'best' one.\n",
    "\n",
    "We expect the 'best' strategy to have a high SR *purely by luck*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_strategies = 100\n",
    "strategy_sr_mean = 0.0 # Strategies have no edge\n",
    "strategy_sr_std = 0.5   # High variance in performance\n",
    "n_trials = 1000       # Number of simulations to run\n",
    "n_years = 10          # 10 years of data\n",
    "obs_per_year = 260    # Daily observations\n",
    "\n",
    "# Run the main simulation engine\n",
    "results = run_backtest_overfitting_simulation(\n",
    "    n_trials=n_trials,\n",
    "    n_strategies=n_strategies,\n",
    "    n_years=n_years,\n",
    "    obs_per_year=obs_per_year,\n",
    "    strategy_sr_mean=strategy_sr_mean,\n",
    "    strategy_sr_std=strategy_sr_std,\n",
    "    signal_t_value=0.0 # No true signal\n",
    ")\n",
    "\n",
    "print(f\"Ran {n_trials} trials of {n_strategies} strategies each.\")\n",
    "print(f\"Average SR of the 'best' strategy (SR_star): {results['SR_star'].mean():.4f}\")\n",
    "print(f\"Average SR of all strategies (SR_all): {results['SR_all'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Probability of Backtest Overfitting (PBO)\n",
    "\n",
    "The simulation shows that the *best* strategy (SR_star) had an average SR of ~1.98, while the average strategy (SR_all) had an SR of 0.0. This high SR_star is a classic example of overfitting.\n",
    "\n",
    "Now, we use `get_pbo` to calculate the probability that our `SR_star` was a fluke.\n",
    "\n",
    "We also use the `pbo_overfitting_plot` helper to visualize this. The plot shows the distribution of all SRs (blue) and the distribution of the *best* SRs (orange). The PBO value is the area of overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Sharpe Ratios for all strategies from all trials\n",
    "sr_all_strategies = results['SR_all']\n",
    "sr_best_strategies = results['SR_star']\n",
    "\n",
    "# Calculate PBO\n",
    "pbo = get_pbo(sr_all_strategies, sr_best_strategies)\n",
    "\n",
    "print(f\"Probability of Backtest Overfitting (PBO): {pbo * 100:.2f}%\")\n",
    "\n",
    "# Plot the PBO distributions\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "pbo_overfitting_plot(\n",
    "    sr_all_strategies,\n",
    "    sr_best_strategies,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "pub_plots.apply_plot_style(\n",
    "    ax,\n",
    "    title=f'Probability of Backtest Overfitting (PBO) = {pbo * 100:.2f}%',\n",
    "    xlabel='Sharpe Ratio (SR)',\n",
    "    ylabel='Density'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The PBO is extremely high (e.g., 98%). This correctly tells us that the 'best' strategies we found are almost certainly overfit and are just the positive tail of a random (no-edge) distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Probabilistic Sharpe Ratio (PSR)\n",
    "\n",
    "PBO works on a *set* of strategies. PSR works on a *single* strategy. Let's pretend we are a researcher who only has one strategy (our 'best' one) and wants to test if it's significant.\n",
    "\n",
    "We'll use one of the return series from our simulation (from `results['returns_star']`) to calculate its PSR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the returns of the 'best' strategy from the first trial\n",
    "best_strategy_returns = results['returns_star'][0]\n",
    "\n",
    "# Calculate its annualized SR (this is our 'claimed' SR)\n",
    "claimed_sr = annualized_sharpe_ratio(best_strategy_returns, obs_per_year=obs_per_year)\n",
    "n_years = best_strategy_returns.shape[0] / obs_per_year\n",
    "\n",
    "print(f\"'Best' Strategy Annualized SR: {claimed_sr:.4f}\")\n",
    "\n",
    "# Calculate PSR\n",
    "# We test it against a benchmark of SR=0.0 (no edge)\n",
    "psr = probabilistic_sharpe_ratio(\n",
    "    observed_sr=claimed_sr,\n",
    "    n_years=n_years,\n",
    "    skew=best_strategy_returns.skew(),\n",
    "    kurtosis=best_strategy_returns.kurtosis(),\n",
    "    benchmark_sr=0.0\n",
    ")\n",
    "\n",
    "print(f\"Probabilistic Sharpe Ratio (PSR): {psr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** Even though our 'best' strategy had a high SR, its PSR is low (e.g., 0.28). This correctly signals that the strategy is *not* statistically significant and likely a fluke. A high PSR (e.g., > 0.95) would be needed to be confident.\n",
    "\n",
    "We can also use `compute_psr_curve` to see what SR we *would* need to achieve 95% confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the PSR curve for different 'claimed' SR values\n",
    "psr_curve = compute_psr_curve(\n",
    "    n_years=n_years,\n",
    "    skew=best_strategy_returns.skew(),\n",
    "    kurtosis=best_strategy_returns.kurtosis(),\n",
    "    benchmark_sr=0.0\n",
    ")\n",
    "\n",
    "# Find the SR needed for PSR=0.95\n",
    "required_sr = psr_curve[psr_curve > 0.95].idxmin()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "psr_curve.plot(ax=ax, label='PSR Curve')\n",
    "ax.axhline(0.95, ls='--', color='red', label='PSR = 0.95')\n",
    "ax.axvline(required_sr, ls='--', color='green', label=f'Required SR = {required_sr:.2f}')\n",
    "\n",
    "pub_plots.apply_plot_style(\n",
    "    ax,\n",
    "    title='Probabilistic Sharpe Ratio (PSR) Curve',\n",
    "    xlabel='Claimed Sharpe Ratio',\n",
    "    ylabel='PSR (Probability of Significance)'\n",
    ")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Combinatorial Symmetric Cross-Validation (CSCV)\n",
    "\n",
    "Finally, we use CSCV. This method helps us find the *most robust* set of parameters, not just the one with the highest SR.\n",
    "\n",
    "We'll test 6 combinations of parameters (e.g., 6 pairs of (Fast MA, Slow MA)). The `combinatorial_symmetric_cross_validation` function will:\n",
    "1.  Split the data into $S=2$ splits (J=2).\n",
    "2.  Test all 6 combinations on all $2^2 = 4$ possible train/test paths.\n",
    "3.  Aggregate the performance and rank the combinations.\n",
    "\n",
    "The combination with the *best average rank* (lowest score) is the most robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Create a dummy performance matrix ---\n",
    "# This simulates the performance of 6 parameter combinations (rows)\n",
    "# across 2 different time splits (columns).\n",
    "# Shape = (n_combinations, n_splits)\n",
    "# We'll assume J=2, so n_splits = J * (J-1) / 2 = 1. Wait, S=2.\n",
    "# Let's assume S=2 splits (J=2). We test all 2^S = 4 combinations.\n",
    "# We will use S=2 splits (J=2), giving 2^S = 4 paths.\n",
    "# Let's manually create a simple performance matrix for 6 parameter combinations (rows) \n",
    "# over S=4 splits (columns).\n",
    "n_params = 6\n",
    "n_splits = 4\n",
    "\n",
    "np.random.seed(42)\n",
    "performance_matrix = pd.DataFrame(np.random.rand(n_params, n_splits))\n",
    "# Make one combination (idx 3) consistently good\n",
    "performance_matrix.iloc[3, :] = [0.8, 0.75, 0.85, 0.7]\n",
    "# Make one combination (idx 1) a 'fluke' (good once, bad otherwise)\n",
    "performance_matrix.iloc[1, :] = [0.9, 0.2, 0.1, 0.3]\n",
    "\n",
    "print(\"Performance Matrix (Combinations x Splits):\")\n",
    "display(performance_matrix)\n",
    "\n",
    "# --- 2. Run CSCV --- \n",
    "cscv_results = combinatorial_symmetric_cross_validation(performance_matrix)\n",
    "\n",
    "print(\"\\nCSCV Results:\")\n",
    "display(cscv_results.sort_values(by='mean_rank'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** As expected, `combinatorial_symmetric_cross_validation` did *not* choose parameter combination 1, even though it had the highest performance (0.9) in one split. \n",
    "\n",
    "Instead, it chose **parameter combination 3**, which was *consistently* good across all splits and had the best average rank. This is the more robust and reliable model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
