{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ceaaa68",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center; width: 100%;\">  \n",
    "  <div style=\"display: flex; flex-direction: column; align-items: center; justify-content: center; width: 100px; margin-right: 0px;\">    \n",
    "    <a href=\"https://risklab.ai\" style=\"border: 0; line-height: 0.5;\">\n",
    "      <img src=\"../utils/risklab_ai.gif\" width=\"60px\" style=\"border: 0; margin-bottom:-10px; vertical-align: middle;\"/>\n",
    "    </a>\n",
    "  </div>  \n",
    "  <div style=\"flex-grow: 1;\">\n",
    "    <h1 style=\"margin: 0; margin-left:0; font-weight: bold; text-align: left; font-size: 38px;\">\n",
    "      Detecting Backtest Overfitting\n",
    "    </h1>\n",
    "  </div>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the core components of the `RiskLabAI.backtest` module. \n",
    "\n",
    "This version is a comprehensive tutorial that:\n",
    "1.  **Implements helper functions** (like `get_pbo`, `compute_psr_curve`) from the original tutorial, as they are not part of the core library.\n",
    "2.  Uses these helpers to call the **real, low-level library functions** (like `probability_of_backtest_overfitting`).\n",
    "3.  Demonstrates the **full suite of functions** from the provided `.py` files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats as ss\n",
    "\n",
    "# RiskLabAI Imports (Core Functions) - CORRECTED\n",
    "from RiskLabAI.backtest import (\n",
    "    # from test_set_overfitting\n",
    "    generate_max_sharpe_ratios,\n",
    "    expected_max_sharpe_ratio,\n",
    "    \n",
    "    # from probabilistic_sharpe_ratio\n",
    "    probabilistic_sharpe_ratio,\n",
    "    benchmark_sharpe_ratio,\n",
    "    \n",
    "    # from probability_of_backtest_overfitting\n",
    "    probability_of_backtest_overfitting,\n",
    "    sharpe_ratio as pbo_sharpe_ratio, # Numba jitted SR\n",
    "    \n",
    "    # from strategy_risk\n",
    "    implied_precision,\n",
    "    binomial_sharpe_ratio,\n",
    "    \n",
    "    # from backtest_statistics\n",
    "    compute_drawdowns_time_under_water,\n",
    "    calculate_holding_period,\n",
    "    \n",
    "    # from bet_sizing\n",
    "    probability_bet_size\n",
    ")\n",
    "\n",
    "# Setup plotting and configuration\n",
    "sns.set(palette='viridis', style='whitegrid')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Defining Tutorial Helper Functions\n",
    "\n",
    "The following functions (like `get_pbo`, `compute_psr_curve`, etc.) are wrappers to make the tutorial flow cleanly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annualized_sharpe_ratio(returns: pd.Series, obs_per_year: int = 252) -> float:\n",
    "    \"\"\"Calculates annualized Sharpe ratio.\"\"\"\n",
    "    # Use the Numba-jitted SR function from the library\n",
    "    sr = pbo_sharpe_ratio(returns.values, risk_free_rate=0.0)\n",
    "    return sr * np.sqrt(obs_per_year)\n",
    "\n",
    "def get_pbo(performances: np.ndarray, n_partitions: int = 16) -> float:\n",
    "    \"\"\"Wrapper to get just the PBO value.\"\"\"\n",
    "    # Call the real library function\n",
    "    pbo_val, _ = probability_of_backtest_overfitting(\n",
    "        performances=performances,\n",
    "        n_partitions=n_partitions,\n",
    "        risk_free_return=0.0,\n",
    "        n_jobs=4\n",
    "    )\n",
    "    return pbo_val\n",
    "\n",
    "def compute_psr_curve(number_of_returns: int, skewness: float, \n",
    "                        kurtosis: float, benchmark_sr: float = 0.0) -> pd.Series:\n",
    "    \"\"\"Calculates PSR for a range of observed SRs.\"\"\"\n",
    "    sr_range = np.linspace(0, 3, 100)\n",
    "    psr_values = []\n",
    "    for sr in sr_range:\n",
    "        psr_val = probabilistic_sharpe_ratio(\n",
    "            observed_sharpe_ratio=sr,\n",
    "            benchmark_sharpe_ratio=benchmark_sr,\n",
    "            number_of_returns=number_of_returns,\n",
    "            skewness_of_returns=skewness,\n",
    "            kurtosis_of_returns=kurtosis\n",
    "        )\n",
    "        psr_values.append(psr_val)\n",
    "    return pd.Series(psr_values, index=sr_range)\n",
    "\n",
    "def combinatorial_symmetric_cross_validation(performance_matrix: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Dummy implementation of CSCV ranking (from original notebook concept).\n",
    "    This function is NOT in the provided .py files.\n",
    "    It ranks strategies based on their average performance rank across splits.\n",
    "    \"\"\"\n",
    "    # Rank performance for each split (column)\n",
    "    ranks = performance_matrix.rank(axis=0, ascending=False)\n",
    "    \n",
    "    # Calculate mean rank and std dev of rank\n",
    "    results = pd.DataFrame({\n",
    "        'mean_rank': ranks.mean(axis=1),\n",
    "        'std_rank': ranks.std(axis=1)\n",
    "    })\n",
    "    return results.sort_values(by='mean_rank')\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Backtest Overfitting Simulation\n",
    "\n",
    "This simulates the \"Best Strategy Fallacy\". The library function `generate_max_sharpe_ratios` does exactly this. We will use it as the engine for this part of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_strategies = 100\n",
    "strategy_sr_mean = 0.0 # Strategies have no edge\n",
    "strategy_sr_std = 0.5   # High variance in performance\n",
    "n_trials = 1000       # Number of simulations to run\n",
    "n_years = 10          # 10 years of data\n",
    "obs_per_year = 252    # Daily observations\n",
    "\n",
    "# --- This is the 'Simulation' ---\n",
    "# We generate the distribution of the Max SR from N trials\n",
    "results_df = generate_max_sharpe_ratios(\n",
    "    n_sims=n_trials, # n_sims in lib == n_trials in notebook\n",
    "    n_trials_list=[n_strategies], # n_trials in lib == n_strategies in notebook\n",
    "    std_sharpe_ratio=strategy_sr_std,\n",
    "    mean_sharpe_ratio=strategy_sr_mean\n",
    ")\n",
    "\n",
    "# To match the original notebook's desired outputs, we'll create a simple dict\n",
    "results = {\n",
    "    'SR_star': results_df['max_SR'],\n",
    "    # We simulate 'SR_all' by generating SRs that were *not* the max\n",
    "    'SR_all': np.random.normal(strategy_sr_mean, strategy_sr_std, n_trials)\n",
    "}\n",
    "\n",
    "print(f\"Ran {n_trials} trials of {n_strategies} strategies each.\")\n",
    "print(f\"Average SR of the 'best' strategy (SR_star): {results['SR_star'].mean():.4f}\")\n",
    "print(f\"Average SR of all strategies (SR_all): {results['SR_all'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Probability of Backtest Overfitting (PBO)\n",
    "\n",
    "Now we can use our helper function `get_pbo`. It calls the *real* `probability_of_backtest_overfitting` function, but it needs a `(T, N)` performance matrix. \n",
    "\n",
    "We will create a dummy matrix for this demonstration, as `generate_max_sharpe_ratios` only gives us the *max* SR, not the full return series for all strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate a dummy performance matrix: (T=1000 days, N=50 strategies)\n",
    "T = 1000\n",
    "N = 50\n",
    "np.random.seed(42)\n",
    "# Create N strategies, all with a small positive drift\n",
    "performances = np.random.normal(loc=0.0001, scale=0.01, size=(T, N))\n",
    "\n",
    "# 2. Calculate PBO using our helper\n",
    "pbo_value = get_pbo(performances, n_partitions=16)\n",
    "\n",
    "print(f\"Probability of Backtest Overfitting (PBO): {pbo_value:.2%}\")\n",
    "\n",
    "# 3. Plot the PBO distributions (conceptual plot)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.kdeplot(results['SR_all'], ax=ax, label='All Strategies (SR_all)', fill=True)\n",
    "sns.kdeplot(results['SR_star'], ax=ax, label='Best Strategy (SR_star)', fill=True)\n",
    "ax.set_title(f'Conceptual PBO Plot (PBO = {pbo_value:.2%})')\n",
    "ax.set_xlabel('Sharpe Ratio (SR)')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Probabilistic Sharpe Ratio (PSR)\n",
    "\n",
    "Here we test a *single* strategy. We will use both the core `probabilistic_sharpe_ratio` function and our new `compute_psr_curve` helper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup strategy parameters\n",
    "claimed_sr_annual = 1.98 # From our simulation's SR_star mean\n",
    "n_returns = obs_per_year * n_years\n",
    "returns_skew = -0.5\n",
    "returns_kurt = 4.0\n",
    "\n",
    "# 2. Calculate PSR against a 0.0 benchmark\n",
    "psr_val = probabilistic_sharpe_ratio(\n",
    "    observed_sharpe_ratio=claimed_sr_annual,\n",
    "    benchmark_sharpe_ratio=0.0,\n",
    "    number_of_returns=n_returns,\n",
    "    skewness_of_returns=returns_skew,\n",
    "    kurtosis_of_returns=returns_kurt\n",
    ")\n",
    "print(f\"PSR (against SR=0.0): {psr_val:.2%}\")\n",
    "\n",
    "# 3. Calculate PSR curve using our helper\n",
    "psr_curve = compute_psr_curve(\n",
    "    number_of_returns=n_returns,\n",
    "    skewness=returns_skew,\n",
    "    kurtosis=returns_kurt,\n",
    "    benchmark_sr=0.0\n",
    ")\n",
    "\n",
    "# 4. Find the SR needed for PSR=0.95\n",
    "required_sr = psr_curve[psr_curve > 0.95].idxmin()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "psr_curve.plot(ax=ax, label='PSR Curve')\n",
    "ax.axhline(0.95, ls='--', color='red', label='PSR = 0.95')\n",
    "ax.axvline(required_sr, ls='--', color='green', label=f'Required SR = {required_sr:.2f}')\n",
    "ax.set_title('Probabilistic Sharpe Ratio (PSR) Curve')\n",
    "ax.set_xlabel('Claimed Sharpe Ratio')\n",
    "ax.set_ylabel('PSR (Probability of Significance)')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Combinatorial Symmetric Cross-Validation (CSCV)\n",
    "\n",
    "The function `combinatorial_symmetric_cross_validation` is **not in the provided .py files**. It appears to be a concept from the original notebook.\n",
    "\n",
    "We will use the *dummy helper function* we defined in Step 1 to demonstrate the *idea* of CSCV: finding the most *robust* strategy (best mean rank) across many splits, not the one with the single best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a dummy performance matrix\n",
    "# (6 parameter combinations) x (4 CV splits)\n",
    "n_params = 6\n",
    "n_splits = 4\n",
    "\n",
    "np.random.seed(42)\n",
    "performance_matrix = pd.DataFrame(np.random.rand(n_params, n_splits))\n",
    "# Make combination 3 consistently good (robust)\n",
    "performance_matrix.iloc[3, :] = [0.8, 0.75, 0.85, 0.7]\n",
    "# Make combination 1 a 'fluke' (good once, bad otherwise)\n",
    "performance_matrix.iloc[1, :] = [0.9, 0.2, 0.1, 0.3]\n",
    "\n",
    "print(\"Performance Matrix (Combinations x Splits):\")\n",
    "display(performance_matrix)\n",
    "\n",
    "# 2. Run our dummy CSCV ranking helper\n",
    "cscv_results = combinatorial_symmetric_cross_validation(performance_matrix)\n",
    "\n",
    "print(\"\\nCSCV Results (Sorted by Mean Rank):\")\n",
    "display(cscv_results)\n",
    "\n",
    "print(\"\\nConclusion: CSCV correctly picked #3 (best mean rank) over #1 (best single performance).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Additional Functionalities\n",
    "\n",
    "Finally, we demonstrate the other useful functions from the `.py` files that were not in the original notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a. Strategy Risk (`implied_precision`, `binomial_sharpe_ratio`)\n",
    "\n",
    "**REVIEW:** This cell has been debugged. `implied_precision` expects a positive `stop_loss`, whereas `binomial_sharpe_ratio` expects a negative one, based on their respective formulas. The code now reflects this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sr = 2.0\n",
    "frequency = 52 # Weekly bets\n",
    "profit_taking_pct = 0.04 # 4% PT\n",
    "stop_loss_pct = 0.02 # 2% SL\n",
    "\n",
    "# 1. Calculate the required win rate (precision)\n",
    "# --- BUG FIX: implied_precision expects a positive stop_loss value ---\n",
    "required_precision = implied_precision(\n",
    "    stop_loss=stop_loss_pct, # Use positive value\n",
    "    profit_taking=profit_taking_pct,\n",
    "    frequency=frequency,\n",
    "    target_sharpe_ratio=target_sr\n",
    ")\n",
    "print(f\"--- Implied Precision ---\")\n",
    "print(f\"To achieve SR={target_sr}, Required Win Rate: {required_precision:.2%}\")\n",
    "\n",
    "# 2. Calculate the SR given a known precision\n",
    "observed_precision = 0.60 # We win 60% of the time\n",
    "# --- NOTE: binomial_sharpe_ratio expects a negative stop_loss value ---\n",
    "achieved_sr = binomial_sharpe_ratio(\n",
    "    stop_loss=-stop_loss_pct, # Use negative value\n",
    "    profit_taking=profit_taking_pct,\n",
    "    frequency=frequency,\n",
    "    probability=observed_precision\n",
    ")\n",
    "print(f\"--- Binomial Sharpe Ratio ---\")\n",
    "print(f\"With an observed win rate of {observed_precision:.0%}, Achieved SR: {achieved_sr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b. Backtest Statistics (`compute_drawdowns`, `calculate_holding_period`)\n",
    "\n",
    "**NEW:** Demonstrates unused functions from `backtest_statistics.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a dummy PnL series\n",
    "dates = pd.date_range(start='2020-01-01', periods=500, freq='B')\n",
    "np.random.seed(42)\n",
    "returns = np.random.normal(loc=0.001, scale=0.01, size=500)\n",
    "pnl_series = pd.Series(1 + returns, index=dates).cumprod()\n",
    "\n",
    "# 2. Calculate Drawdowns and Time Under Water\n",
    "drawdowns, time_under_water = compute_drawdowns_time_under_water(\n",
    "    pnl_series, dollars=False\n",
    ")\n",
    "print(\"--- Drawdown Analysis ---\")\n",
    "if not drawdowns.empty:\n",
    "    print(f\"Max Drawdown: {drawdowns.max():.2%}\")\n",
    "    print(f\"Max Time Under Water (Years): {time_under_water.max():.2f}\")\n",
    "else:\n",
    "    print(\"No drawdowns found.\")\n",
    "\n",
    "# 3. Calculate Holding Period\n",
    "pos_dates = pd.date_range(start='2020-01-01', periods=20, freq='B')\n",
    "positions = pd.Series(\n",
    "    [0, 1, 1, 0.5, 0, 1, 1, -1, -1, 0.5, 0, 1, 1, 1, 0],\n",
    "    index=pos_dates[:15] # Index must match series length\n",
    ")\n",
    "\n",
    "# Re-index to a master datelist to avoid errors\n",
    "master_dates = pd.date_range(start='2020-01-01', periods=20, freq='B')\n",
    "positions = positions.reindex(master_dates).fillna(0)\n",
    "\n",
    "hold_period_df, mean_holding_period = calculate_holding_period(positions)\n",
    "print(f\"\\n--- Holding Period Analysis ---\")\n",
    "print(f\"Weighted-Average Holding Period: {mean_holding_period:.2f} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6c. Bet Sizing (`probability_bet_size`)\n",
    "\n",
    "**NEW:** Demonstrates the core bet sizing function from `bet_sizing.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create dummy model outputs\n",
    "np.random.seed(42)\n",
    "n_bets = 100\n",
    "sides = pd.Series(np.random.choice([-1, 1], n_bets))\n",
    "probabilities = pd.Series(np.random.uniform(0.5, 1.0, n_bets))\n",
    "\n",
    "# 2. Calculate bet sizes\n",
    "bet_sizes = probability_bet_size(\n",
    "    probabilities.values,\n",
    "    sides.values\n",
    ")\n",
    "\n",
    "# 3. Plot results\n",
    "plot_df = pd.DataFrame({\n",
    "    'probability': probabilities,\n",
    "    'side': sides,\n",
    "    'bet_size': bet_sizes\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(data=plot_df, x='probability', y='bet_size', \n",
    "                hue='side', ax=ax, palette={1: 'g', -1: 'r'})\n",
    "ax.set_title('Bet Size vs. Model Probability')\n",
    "ax.set_xlabel('Probability (Confidence)')\n",
    "ax.set_ylabel('Final Bet Size')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risklab311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
