{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– Advanced Tutorial: Full ML Backtest Simulation\n",
    "\n",
    "This notebook demonstrates the *core* functionality of the `RiskLabAI` library: running a full-scale backtest overfitting simulation.\n",
    "\n",
    "Unlike the conceptual demo, this workflow uses the `overall_backtest_overfitting_simulation` function. This function orchestrates the entire process:\n",
    "\n",
    "1.  **Feature Engineering:** Creates features from prices (FracDiff, Volatility, TA-Lib).\n",
    "2.  **Labeling:** Generates CUSUM events, triple barriers, and meta-labels.\n",
    "3.  **Strategy Generation:** Runs multiple strategy parameter combinations (e.g., different moving average windows).\n",
    "4.  **Model Training:** Trains multiple ML models with hyperparameter grids.\n",
    "5.  **Cross-Validation:** Backtests every combination using all specified CV methods ('Walk-Forward', 'K-Fold', 'Purged K-Fold', 'Combinatorial Purged').\n",
    "6.  **Analysis:** Calculates the final Probability of Backtest Overfitting (PBO) and Deflated Sharpe Ratio (DSR) for each CV method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# ML Model Import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# RiskLabAI Imports\n",
    "# Note: This is the main simulation engine, not used in the other notebook\n",
    "from RiskLabAI.backtest import (\n",
    "    overall_backtest_overfitting_simulation\n",
    ")\n",
    "\n",
    "# Setup plotting and configuration\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Dummy Price Data\n",
    "\n",
    "The simulation functions are data-intensive. We need a sufficiently long price series to generate enough events for labeling and cross-validation.\n",
    "\n",
    "We'll create a 5,000-step (e.g., ~20 years of daily data) random walk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m returns = np.random.normal(loc=\u001b[32m0.0001\u001b[39m, scale=\u001b[32m0.01\u001b[39m, size=n_steps)\n\u001b[32m      4\u001b[39m prices = \u001b[32m100\u001b[39m * (\u001b[32m1\u001b[39m + returns).cumprod()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mprices\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m = pd.date_range(start=\u001b[33m'\u001b[39m\u001b[33m2000-01-01\u001b[39m\u001b[33m'\u001b[39m, periods=n_steps, freq=\u001b[33m'\u001b[39m\u001b[33mB\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCreated dummy price series with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m steps.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m prices.plot(title=\u001b[33m'\u001b[39m\u001b[33mDummy Price Data\u001b[39m\u001b[33m'\u001b[39m, figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m));\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "n_steps = 5000\n",
    "returns = np.random.normal(loc=0.0001, scale=0.01, size=n_steps)\n",
    "prices = 100 * (1 + returns).cumprod()\n",
    "prices.index = pd.date_range(start='2000-01-01', periods=n_steps, freq='B')\n",
    "\n",
    "print(f\"Created dummy price series with {n_steps} steps.\")\n",
    "prices.plot(title='Dummy Price Data', figsize=(10, 6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Strategy & Model Parameters\n",
    "\n",
    "This is the core configuration for the simulation engine. We define dictionaries for our strategy parameters and our ML models, just as required by the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define Strategy Parameters\n",
    "# These are passed to `determine_strategy_side`\n",
    "# We will test 4 combinations of moving average crossovers.\n",
    "strategy_parameters = {\n",
    "    'fast_window': [10, 20, 10, 20], \n",
    "    'slow_window': [30, 50, 40, 60], \n",
    "    'mean_reverting': [False, False, False, False]\n",
    "}\n",
    "\n",
    "# 2. Define ML Models and their Hyperparameter Grids\n",
    "# The simulation will run every model with every hyperparameter set.\n",
    "models = {\n",
    "    'LogisticRegression_L2': {\n",
    "        'Model': LogisticRegression(penalty='l2', solver='liblinear'),\n",
    "        'Parameters': {\n",
    "            'C': [1e-3, 1e-2, 1e-1]\n",
    "        }\n",
    "    },\n",
    "    'LogisticRegression_L1': {\n",
    "        'Model': LogisticRegression(penalty='l1', solver='liblinear'),\n",
    "        'Parameters': {\n",
    "            'C': [1e-3, 1e-2, 1e-1]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# 3. Define Simulation Parameters\n",
    "step_risk_free_rate = 0.0 # Daily risk-free rate for Sharpe calculation\n",
    "n_jobs = 4 # Number of parallel jobs for cross-validation\n",
    "\n",
    "print(\"Configuration defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the Full Simulation\n",
    "\n",
    "We now pass all our configurations to the `overall_backtest_overfitting_simulation` function.\n",
    "\n",
    "**Note:** This is computationally expensive! It is testing:\n",
    "`4 CV Methods` x `4 Strategies` x `2 Models` x `3 Hyperparameters` = **96 backtests**.\n",
    "\n",
    "This may take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting simulation... This may take a few minutes.\")\n",
    "\n",
    "try:\n",
    "    cv_pbo, cv_deflated_sr = overall_backtest_overfitting_simulation(\n",
    "        prices=prices,\n",
    "        strategy_parameters=strategy_parameters,\n",
    "        models=models,\n",
    "        step_risk_free_rate=step_risk_free_rate,\n",
    "        noise_scale=0.0,\n",
    "        random_state=42,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Simulation Complete ---\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during simulation. \\nThis is likely due to the bug in __init__.py or strategy_risk.py. \\nError: {e}\")\n",
    "    cv_pbo = {}\n",
    "    cv_deflated_sr = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Results\n",
    "\n",
    "The simulation returns two dictionaries, `cv_pbo` and `cv_deflated_sr`, containing the final scores for each cross-validation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cv_pbo:\n",
    "    print(\"--- Probability of Backtest Overfitting (PBO) ---\")\n",
    "    pbo_series = pd.Series(cv_pbo, name=\"PBO_Score\")\n",
    "    pbo_series.index.name = \"CV_Method\"\n",
    "    print(pbo_series.to_markdown(floatfmt=\".2%\"))\n",
    "\n",
    "    print(\"\\n--- Deflated Sharpe Ratio (DSR) ---\")\n",
    "    dsr_series = pd.Series(cv_deflated_sr, name=\"DSR_Score\")\n",
    "    dsr_series.index.name = \"CV_Method\"\n",
    "    print(dsr_series.to_markdown(floatfmt=\".4f\"))\n",
    "\n",
    "    # Plotting\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(16, 6))\n",
    "    pbo_series.plot(kind='bar', ax=ax1, title='Probability of Backtest Overfitting (Lower is Better)')\n",
    "    ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.1%}'.format(y)))\n",
    "    ax1.axhline(0.5, ls='--', color='red', label='Overfit Threshold (50%)')\n",
    "    ax1.legend()\n",
    "\n",
    "    dsr_series.plot(kind='bar', ax=ax2, title='Deflated Sharpe Ratio (Higher is Better)')\n",
    "    ax2.axhline(0, ls='--', color='red')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Simulation did not complete successfully. Please apply bug fixes and re-run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Conclusion\n",
    "\n",
    "The PBO score (Prob. of Backtest Overfitting) tells us the likelihood that our 'best' strategy was just a fluke. A score > 50% suggests a high chance of overfitting.\n",
    "\n",
    "In a successful run, you will typically see that **'Combinatorial Purged'** (CPCV) and **'Purged K-Fold'** produce a significantly *lower* (better) PBO score than standard 'K-Fold' or 'Walk-Forward', proving they are more robust against overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risklab311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
