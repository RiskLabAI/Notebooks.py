{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â­ Tutorial: Cross-Validation with PurgedKFold\n",
    "\n",
    "This notebook demonstrates how to use the `PurgedKFold` cross-validator from the `RiskLabAI` library to run a robust financial backtest. \n",
    "\n",
    "Standard `KFold` cross-validation fails in finance because:\n",
    "1.  **Leakage:** The training set can contain information that overlaps with the test set (e.g., from overlapping triple-barrier labels).\n",
    "2.  **Embargo:** Information from the test set can 'leak' back into the training set that follows it.\n",
    "\n",
    "`PurgedKFold` (De Prado, Chapter 7) solves this by:\n",
    "1.  **Purging:** Removing any training samples whose labels are concurrent with test set samples.\n",
    "2.  **Embargoing:** Removing training samples that immediately *follow* the test set to prevent look-ahead bias.\n",
    "\n",
    "We will:\n",
    "1.  Load data and generate features/labels.\n",
    "2.  Define the `event_times` (`t1`) needed for purging.\n",
    "3.  Instantiate and visualize `PurgedKFold`.\n",
    "4.  Run a full backtest loop with a `RandomForestClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Third-party for data and modeling\n",
    "!pip install yfinance ta\n",
    "import yfinance as yf\n",
    "import ta\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# RiskLabAI Imports\n",
    "from RiskLabAI.backtest.validation import PurgedKFold\n",
    "import RiskLabAI.utils.publication_plots as pub_plots\n",
    "\n",
    "# Setup plotting and configuration\n",
    "pub_plots.setup_publication_style()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data & Generate Signals\n",
    "\n",
    "We will load 'SPY' data and generate some simple features and labels. For this example, we will assume a simple fixed-time horizon label (e.g., 20 days), so our `event_times` (`t1`) will be 20 days after the observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download('SPY', start='2010-01-01', end='2023-01-01')['Adj Close']\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# --- 1. Generate Features (X) ---\n",
    "X = pd.DataFrame(index=data.index)\n",
    "X['rsi'] = ta.momentum.RSIIndicator(data['Adj Close'], window=14).rsi()\n",
    "X['roc'] = ta.momentum.ROCIndicator(data['Adj Close'], window=10).roc()\n",
    "\n",
    "# --- 2. Generate Labels (y) ---\n",
    "# For simplicity, our label is: did the price go up 20 days from now?\n",
    "look_forward = 20\n",
    "y = data['Adj Close'].pct_change(look_forward).shift(-look_forward)\n",
    "y = pd.Series((y > 0).astype(int), name='label')\n",
    "\n",
    "# --- 3. Define Event Times (t1) ---\n",
    "# This is CRITICAL for purging. It tells the validator when a label 'ends'.\n",
    "# For our fixed horizon label, it's just the index + 20 days.\n",
    "event_times = pd.Series(y.index, index=y.index).apply(lambda x: x + pd.DateOffset(days=look_forward))\n",
    "\n",
    "# --- 4. Align Data ---\n",
    "# Combine all data and drop NaNs to ensure X, y, and t1 are aligned\n",
    "all_data = pd.concat([X, y, event_times.rename('t1')], axis=1).dropna()\n",
    "\n",
    "X = all_data.drop(columns=['label', 't1'])\n",
    "y = all_data['label']\n",
    "event_times = all_data['t1']\n",
    "\n",
    "print(f\"Aligned data shapes: X={X.shape}, y={y.shape}, t1={event_times.shape}\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualizing Purged K-Fold Splits\n",
    "\n",
    "Before we run the backtest, let's visualize how `PurgedKFold` creates its splits. We'll use a `n_splits=10`.\n",
    "\n",
    "Notice how the **blue (train)** bar is 'purged' (stops early) before the **orange (test)** bar begins, and an 'embargo' (a gap) is left after the test bar ends. This prevents any information leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "embargo_pct = 0.01 # 1% embargo\n",
    "\n",
    "cv = PurgedKFold(\n",
    "    n_splits=n_splits,\n",
    "    embargo_pct=embargo_pct\n",
    ")\n",
    "\n",
    "# --- Plotting the CV splits --- \n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "fold_indices = range(n_splits)\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(cv.split(X, y, event_times)):\n",
    "    # Plot training indices\n",
    "    ax.fill_betweenx(\n",
    "        [i-0.4, i+0.4], \n",
    "        train_idx.min(), \n",
    "        train_idx.max(), \n",
    "        color='#00aedb', \n",
    "        alpha=0.7, \n",
    "        label='Train' if i == 0 else \"_nolegend_\"\n",
    "    )\n",
    "    \n",
    "    # Plot testing indices\n",
    "    ax.fill_betweenx(\n",
    "        [i-0.4, i+0.4], \n",
    "        test_idx.min(), \n",
    "        test_idx.max(), \n",
    "        color='#d11141', \n",
    "        alpha=0.9, \n",
    "        label='Test' if i == 0 else \"_nolegend_\"\n",
    "    )\n",
    "\n",
    "ax.set_yticks(fold_indices)\n",
    "ax.set_yticklabels([f'Fold {i+1}' for i in fold_indices])\n",
    "ax.set_xlabel('Index')\n",
    "ax.set_title(f'Purged K-Fold (n_splits={n_splits}, embargo={embargo_pct})')\n",
    "ax.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Backtesting with PurgedKFold\n",
    "\n",
    "This is the core of the tutorial. We loop through each (train, test) split generated by `cv.split()`:\n",
    "1.  Train a `RandomForestClassifier` on the **training data**.\n",
    "2.  Generate predictions on the **testing data**.\n",
    "3.  Store these out-of-sample (OOS) predictions.\n",
    "\n",
    "After the loop, we will have a complete set of OOS predictions for our entire dataset, which we can then score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "oos_predictions = pd.Series(index=y.index, dtype=float)\n",
    "\n",
    "print(\"Running backtest...\")\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X, y, event_times)):\n",
    "    print(f\"--- Fold {fold+1}/{n_splits} ---\")\n",
    "    \n",
    "    # Get data for this fold\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_test = X.iloc[test_idx]\n",
    "    \n",
    "    # 1. Train the model\n",
    "    print(f\"Training on {len(X_train)} samples...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 2. Generate predictions\n",
    "    print(f\"Predicting on {len(X_test)} samples...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 3. Store OOS predictions\n",
    "    oos_predictions.iloc[test_idx] = y_pred\n",
    "\n",
    "print(\"\\nBacktest complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate OOS Accuracy\n",
    "\n",
    "Now we can compare our complete set of OOS predictions against the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaNs from predictions (for any indices that were not in a test set)\n",
    "oos_predictions = oos_predictions.dropna()\n",
    "y_true = y.loc[oos_predictions.index]\n",
    "\n",
    "accuracy = accuracy_score(y_true, oos_predictions)\n",
    "\n",
    "print(f\"Final Out-of-Sample Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** We have successfully used `PurgedKFold` to run a robust cross-validation backtest, ensuring that no data leakage occurred between our training and testing sets. This OOS accuracy score is a reliable estimate of the model's performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
