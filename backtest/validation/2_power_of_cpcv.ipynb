{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â­ Tutorial: The Power of CPCV (`CombinatorialPurged`)\n",
    "\n",
    "In the previous tutorial, we used `PurgedKFold` to get a single, reliable out-of-sample (OOS) accuracy score. But this leads to a critical question:\n",
    "\n",
    "**\"How do we know we weren't just lucky?\"**\n",
    "\n",
    "A single backtest path, even a purged one, could be an outlier. `CombinatorialPurged` (CPCV) solves this. Instead of one path, it runs *many* backtest paths by combining different train/test splits. This allows us to see the **distribution** of performance metrics, giving a much more robust assessment of our strategy.\n",
    "\n",
    "This notebook will show you how to:\n",
    "1.  Run `CombinatorialPurged` to get *all* backtest paths.\n",
    "2.  Calculate the performance (e.g., accuracy) for *each* path.\n",
    "3.  Plot a histogram of these performance scores to see the mean, variance, and full range of outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup and Imports\n",
    "\n",
    "This setup is identical to the `PurgedKFold` tutorial for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "335644c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numba' has no attribute 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# RiskLabAI Imports\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mRiskLabAI\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbacktest\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossValidatorController\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mRiskLabAI\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpublication_plots\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpub_plots\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Setup plotting and configuration\u001b[39;00m\n\u001b[32m     18\u001b[39m pub_plots.setup_publication_style()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hamid\\.conda\\envs\\risklab311\\Lib\\site-packages\\RiskLabAI\\__init__.py:36\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mRiskLabAI: Financial AI with Python\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m \u001b[33;03m    Common helper functions, constants, and plotting utilities.\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Import all sub-packages to make them available\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backtest\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m controller\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hamid\\.conda\\envs\\risklab311\\Lib\\site-packages\\RiskLabAI\\backtest\\__init__.py:13\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mRiskLabAI Backtesting Module\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03m- Advanced cross-validation (in the .validation submodule)\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validation\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbacktest_statistics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     14\u001b[39m     bet_timing,\n\u001b[32m     15\u001b[39m     calculate_holding_period,\n\u001b[32m     16\u001b[39m     calculate_hhi_concentration,\n\u001b[32m     17\u001b[39m     calculate_hhi,\n\u001b[32m     18\u001b[39m     compute_drawdowns_time_under_water,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbacktest_synthetic_data\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m synthetic_back_testing\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbet_sizing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     22\u001b[39m     probability_bet_size,\n\u001b[32m     23\u001b[39m     average_bet_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m     getW,\n\u001b[32m     34\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hamid\\.conda\\envs\\risklab311\\Lib\\site-packages\\RiskLabAI\\backtest\\backtest_statistics.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m jit\n\u001b[32m     11\u001b[39m \u001b[38;5;129m@jit\u001b[39m(nopython=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msharpe_ratio\u001b[39m(\n\u001b[32m     13\u001b[39m     returns: np.ndarray, risk_free_rate: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.0\u001b[39m\n\u001b[32m     14\u001b[39m ) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m     15\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m    Calculate the Sharpe Ratio (Numba-optimized).\u001b[39;00m\n\u001b[32m     17\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m \u001b[33;03m        The calculated Sharpe Ratio.\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hamid\\.conda\\envs\\risklab311\\Lib\\site-packages\\numba\\__init__.py:74\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m generate_version_info\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m types, errors\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Re-export typeof\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspecial\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     78\u001b[39m     typeof, prange, pndindex, gdb, gdb_breakpoint, gdb_init,\n\u001b[32m     79\u001b[39m     literally, literal_unroll,\n\u001b[32m     80\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hamid\\.conda\\envs\\risklab311\\Lib\\site-packages\\numba\\core\\types\\__init__.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabstract\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontainers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01miterators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hamid\\.conda\\envs\\risklab311\\Lib\\site-packages\\numba\\core\\types\\containers.py:23\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabstract\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      6\u001b[39m     ConstSized,\n\u001b[32m      7\u001b[39m     Container,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     Poison,\n\u001b[32m     16\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     Buffer,\n\u001b[32m     19\u001b[39m     IterableType,\n\u001b[32m     20\u001b[39m     SimpleIterableType,\n\u001b[32m     21\u001b[39m     SimpleIteratorType,\n\u001b[32m     22\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Undefined, unliteral, Optional, NoneType\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypeconv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conversion\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TypingError\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hamid\\.conda\\envs\\risklab311\\Lib\\site-packages\\numba\\core\\types\\misc.py:6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypeconv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conversion\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TypingError, LiteralTypingError\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mir\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UndefinedType\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_hashable_key\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPyObject\u001b[39;00m(Dummy):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hamid\\.conda\\envs\\risklab311\\Lib\\site-packages\\numba\\core\\ir.py:22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m consts\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# terminal color markup\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m _termcolor = \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtermcolor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mLoc\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[32m     26\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Source location\u001b[39;00m\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hamid\\.conda\\envs\\risklab311\\Lib\\site-packages\\numba\\core\\errors.py:352\u001b[39m, in \u001b[36mtermcolor\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _termcolor_inst\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _termcolor_inst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     scheme = themes[\u001b[43mnumba\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcore\u001b[49m.config.COLOR_SCHEME]\n\u001b[32m    353\u001b[39m     _termcolor_inst = HighlightColorScheme(scheme)\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _termcolor_inst\n",
      "\u001b[31mAttributeError\u001b[39m: module 'numba' has no attribute 'core'"
     ]
    }
   ],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Third-party for data and modeling\n",
    "import yfinance as yf\n",
    "import ta\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# RiskLabAI Imports\n",
    "from RiskLabAI.backtest.validation import CrossValidatorController\n",
    "import RiskLabAI.utils.publication_plots as pub_plots\n",
    "\n",
    "# Setup plotting and configuration\n",
    "pub_plots.setup_publication_style()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86535aa4",
   "metadata": {},
   "source": [
    "## 1. Load Data & Generate Signals\n",
    "\n",
    "We use the same data generation as the previous tutorial to create our `X`, `y`, and `event_times`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068d174c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Close'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hamid\\.conda\\envs\\risklab311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# --- 1. Generate Features (X) ---\u001b[39;00m\n\u001b[32m      5\u001b[39m X = pd.DataFrame(index=data.index)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m X[\u001b[33m'\u001b[39m\u001b[33mrsi\u001b[39m\u001b[33m'\u001b[39m] = ta.momentum.RSIIndicator(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mClose\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, window=\u001b[32m14\u001b[39m).rsi()\n\u001b[32m      7\u001b[39m X[\u001b[33m'\u001b[39m\u001b[33mroc\u001b[39m\u001b[33m'\u001b[39m] = ta.momentum.ROCIndicator(data[\u001b[33m'\u001b[39m\u001b[33mClose\u001b[39m\u001b[33m'\u001b[39m], window=\u001b[32m10\u001b[39m).roc()\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# --- 2. Generate Labels (y) ---\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hamid\\.conda\\envs\\risklab311\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hamid\\.conda\\envs\\risklab311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Close'"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Data ---\n",
    "# Use the stable yf.Ticker().history() method.\n",
    "# We use \"SPY\" (the ETF) and auto_adjust=True.\n",
    "# This correctly gives us the dividend-adjusted 'Close' price.\n",
    "ticker_symbol = \"SPY\"\n",
    "start_date = \"2010-01-01\"\n",
    "end_date = \"2025-01-01\"\n",
    "\n",
    "data = yf.Ticker(ticker_symbol).history(\n",
    "    start=start_date, \n",
    "    end=end_date, \n",
    "    auto_adjust=True  # Automatically adjusts for dividends/splits\n",
    ")\n",
    "\n",
    "# --- 2. Generate Features (X) ---\n",
    "X = pd.DataFrame(index=data.index)\n",
    "# data['Close'] is the dividend-adjusted price\n",
    "X['rsi'] = ta.momentum.RSIIndicator(data['Close'], window=14).rsi()\n",
    "X['roc'] = ta.momentum.ROCIndicator(data['Close'], window=10).roc()\n",
    "\n",
    "# --- 3. Generate Labels (y) ---\n",
    "look_forward = 20\n",
    "y = data['Close'].pct_change(look_forward).shift(-look_forward)\n",
    "y = pd.Series((y > 0).astype(int), name='label')\n",
    "\n",
    "# --- 4. Define Event Times (t1) ---\n",
    "# The label's 'end time' is 20 days after the observation.\n",
    "event_times = pd.Series(y.index, index=y.index).apply(lambda x: x + pd.DateOffset(days=look_forward))\n",
    "\n",
    "# --- 5. Align Data ---\n",
    "# Combine all data and drop NaNs to ensure X, y, and t1 are aligned\n",
    "all_data = pd.concat([X, y, event_times.rename('t1')], axis=1).dropna()\n",
    "\n",
    "X = all_data.drop(columns=['label', 't1'])\n",
    "y = all_data['label']\n",
    "event_times = all_data['t1']\n",
    "\n",
    "print(f\"--- SPY (ETF) Data Loaded ---\")\n",
    "print(f\"Aligned data shapes: X={X.shape}, y={y.shape}, t1={event_times.shape}\")\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running the CPCV Backtest\n",
    "\n",
    "This is the core of the tutorial. Instead of manually looping, we will use the `backtest_predictions` method built into our cross-validators. This method is highly optimized and uses parallel processing.\n",
    "\n",
    "We define:\n",
    "* `n_splits = 10`: The data is split into 10 groups.\n",
    "* `n_test_groups = 2`: Each test set will consist of 2 of these groups.\n",
    "\n",
    "This will generate $C(10, 2) = 45$ total splits and, from those, $k=5$ backtest paths. (Note: $k$ is $n\\_splits / n\\_test\\_groups$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "n_test_groups = 2\n",
    "embargo_pct = 0.01\n",
    "\n",
    "# --- 1. Instantiate the Validator ---\n",
    "# We use the CrossValidatorController for easy creation.\n",
    "cv_controller = CrossValidatorController(\n",
    "    validator_type='combinatorialpurged',\n",
    "    n_splits=n_splits,\n",
    "    n_test_groups=n_test_groups,\n",
    "    times=event_times,\n",
    "    embargo=embargo_pct\n",
    ")\n",
    "\n",
    "cv = cv_controller.get_validator()\n",
    "\n",
    "# --- 2. Define the Model ---\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# --- 3. Run All Backtest Paths --- \n",
    "print(f\"Running Combinatorial Backtest... (This may take a moment)\")\n",
    "\n",
    "# This single call runs all C(n,k) training jobs and assembles all paths.\n",
    "# n_jobs=-1 will parallelize the training of the 45 estimators.\n",
    "paths_predictions = cv.backtest_predictions(\n",
    "    estimator=model,\n",
    "    data=X,\n",
    "    labels=y,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"Backtest complete.\")\n",
    "print(f\"Received {len(paths_predictions)} backtest paths.\")\n",
    "print(f\"Keys: {list(paths_predictions.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate the Distribution of Performance\n",
    "\n",
    "This is the \"Aha!\" moment. `paths_predictions` is not a single array, but a **dictionary** where each key is a path ID and each value is the OOS prediction array for that path.\n",
    "\n",
    "We can now calculate the accuracy for *each path* and see the full distribution of our model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_accuracies = []\n",
    "\n",
    "print(\"Calculating accuracy for each path...\")\n",
    "for path_name, predictions in paths_predictions.items():\n",
    "    # Align true labels with this path's predictions\n",
    "    # Note: All paths have the same length and indices in this implementation\n",
    "    y_true = y.loc[predictions.index]\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_score(y_true, predictions)\n",
    "    path_accuracies.append(acc)\n",
    "    print(f\"  {path_name}: Accuracy = {acc * 100:.2f}%\")\n",
    "\n",
    "path_accuracies = pd.Series(path_accuracies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize the Results\n",
    "\n",
    "Now we plot the histogram of our path accuracies. This tells us far more than a single score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = path_accuracies.mean()\n",
    "std_acc = path_accuracies.std()\n",
    "p5 = path_accuracies.quantile(0.05)\n",
    "p95 = path_accuracies.quantile(0.95)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.hist(path_accuracies, bins=20, alpha=0.7, color='#00aedb', edgecolor='black')\n",
    "\n",
    "ax.axvline(mean_acc, color='#d11141', linestyle='--', lw=2, \n",
    "             label=f'Mean Acc: {mean_acc*100:.2f}%')\n",
    "             \n",
    "ax.axvspan(p5, p95, color='#f37735', alpha=0.2, \n",
    "             label=f'90% C.I. [{p5*100:.2f}% - {p95*100:.2f}%]')\n",
    "\n",
    "ax.set_xlabel('Out-of-Sample Accuracy')\n",
    "ax.set_ylabel('Frequency (Number of Paths)')\n",
    "ax.set_title(f'Distribution of CPCV Path Accuracies (k={len(path_accuracies)} paths)')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Summary Statistics:\")\n",
    "print(f\"Mean Accuracy: {mean_acc*100:.2f}%\")\n",
    "print(f\"Std. Dev:      {std_acc*100:.2f}%\")\n",
    "print(f\"Min Accuracy:  {path_accuracies.min()*100:.2f}%\")\n",
    "print(f\"Max Accuracy:  {path_accuracies.max()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have successfully moved from a single, potentially misleading, performance score to a full-blown *distribution* of performance.\n",
    "\n",
    "We now have a much more honest and robust understanding of our strategy. Instead of just saying \"the accuracy is 5X.XX%,\" we can now say:\n",
    "\n",
    "\"The strategy's mean accuracy is **$Y\\%$**, with a 90% confidence interval of **$[A\\%, B\\%]$**. In the worst-case paths, performance dropped to **$Min\\%$**, and in the best-case, it rose to **$Max\\%$**.\"\n",
    "\n",
    "This result, which accounts for the stochasticity of the train/test split, is a core requirement for robust financial machine learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risklab311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
