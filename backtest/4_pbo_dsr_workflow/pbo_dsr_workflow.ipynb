{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5380c255",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center; width: 100%;\">  \n",
    "  <div style=\"display: flex; flex-direction: column; align-items: center; justify-content: center; width: 100px; margin-right: 0px;\">    \n",
    "    <a href=\"https://risklab.ai\" style=\"border: 0; line-height: 0.5;\">\n",
    "      <img src=\"../utils/risklab_ai.gif\" width=\"60px\" style=\"border: 0; margin-bottom:-10px; vertical-align: middle;\"/>\n",
    "    </a>\n",
    "  </div>  \n",
    "  <div style=\"flex-grow: 1;\">\n",
    "    <h1 style=\"margin: 0; margin-left:0; font-weight: bold; text-align: left; font-size: 38px;\">\n",
    "      PBO/DSR Overfitting Workflow\n",
    "    </h1>\n",
    "  </div>  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workflow uses the `overall_backtest_overfitting_simulation` function. This function orchestrates the entire process:\n",
    "\n",
    "1.  **Feature Engineering:** Creates features from prices (FracDiff, Volatility, TA-Lib).\n",
    "2.  **Labeling:** Generates CUSUM events, triple barriers, and meta-labels.\n",
    "3.  **Strategy Generation:** Runs multiple strategy parameter combinations (e.g., different moving average windows).\n",
    "4.  **Model Training:** Trains multiple ML models with hyperparameter grids.\n",
    "5.  **Cross-Validation:** Backtests every combination using all specified CV methods ('Walk-Forward', 'K-Fold', 'Purged K-Fold', 'Combinatorial Purged').\n",
    "6.  **Analysis:** Calculates the final Probability of Backtest Overfitting (PBO) and Deflated Sharpe Ratio (DSR) for each CV method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "# ML Model Import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# RiskLabAI Imports\n",
    "# Note: This is the main simulation engine\n",
    "from RiskLabAI.backtest import (\n",
    "    overall_backtest_overfitting_simulation\n",
    ")\n",
    "\n",
    "# Setup plotting and configuration\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Price Data from FRED\n",
    "\n",
    "We will use `pandas-datareader` to download data from the Federal Reserve Economic Data (FRED), a public and academically legitimate source.\n",
    "\n",
    "We'll use the S&P 500 Index (`SP500`) as our price series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- User Configuration ---\n",
    "ticker = 'SP500'       # S&P 500 Index (You can change this to any FRED ticker)\n",
    "data_source = 'fred'\n",
    "start_date = '2000-01-01'\n",
    "end_date = datetime.date.today()\n",
    "# -------------------------\n",
    "\n",
    "try:\n",
    "    print(f\"Loading '{ticker}' data from FRED (St. Louis Fed)...\\n\")\n",
    "    # Download the data\n",
    "    prices_with_nans = web.DataReader(ticker, data_source, start_date, end_date)\n",
    "    \n",
    "    # FRED data includes NaNs for holidays/weekends, so we drop them\n",
    "    prices = prices_with_nans[ticker].dropna()\n",
    "    \n",
    "    print(f\"Successfully loaded {len(prices)} observations for {ticker}.\")\n",
    "    prices.plot(title=f\"Loaded Price Data ({ticker} from FRED)\", figsize=(10, 6));\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    print(\"Please ensure 'pandas-datareader' is installed: pip install pandas-datareader\")\n",
    "    prices = pd.Series() # Create empty series to prevent later errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Strategy & Model Parameters\n",
    "\n",
    "This is the core configuration for the simulation engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define Strategy Parameters\n",
    "# These are passed to `determine_strategy_side`\n",
    "# We will test 4 combinations of moving average crossovers.\n",
    "strategy_parameters = {\n",
    "    'fast_window': [10, 20, 10, 20], \n",
    "    'slow_window': [30, 50, 40, 60]\n",
    "}\n",
    "\n",
    "# 2. Define ML Models and their Hyperparameter Grids\n",
    "# The simulation will run every model with every hyperparameter set.\n",
    "models = {\n",
    "    'LogisticRegression_L2': {\n",
    "        'Model': LogisticRegression(penalty='l2', solver='liblinear'),\n",
    "        'Parameters': {\n",
    "            'C': [1e-3, 1e-2, 1e-1]\n",
    "        }\n",
    "    },\n",
    "    'LogisticRegression_L1': {\n",
    "        'Model': LogisticRegression(penalty='l1', solver='liblinear'),\n",
    "        'Parameters': {\n",
    "            'C': [1e-3, 1e-2, 1e-1]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# 3. Define Simulation Parameters\n",
    "step_risk_free_rate = 0.0 # Daily risk-free rate for Sharpe calculation\n",
    "n_jobs = 4 # Number of parallel jobs for cross-validation\n",
    "\n",
    "print(\"Configuration defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new-cell-8-markdown",
   "metadata": {},
   "source": [
    "## Before You Run: Bug Fix Required\n",
    "\n",
    "> **Action Required: Bug Fix**\n",
    "> \n",
    "> The simulation in the next cell (Cell 9) will fail with a `KeyError` due to a bug in the `backtest_overfitting_simulation.py` library file.\n",
    "> \n",
    "> **File to Edit:** `RiskLabAI/backtest/backtest_overfitting_simulation.py`\n",
    "> **Function:** `backtest_overfitting_simulation_results`\n",
    "> \n",
    "> **Find this line (around line 223):**\n",
    "> ```python\n",
    "> positions = strategy_bet_sizing(prices.index, times.loc[probabilities.index], strategy_sides[probabilities.index], probabilities)\n",
    "> ```\n",
    "> \n",
    "> **Replace it with this:**\n",
    "> ```python\n",
    "> positions = strategy_bet_sizing(prices.index, times.loc[probabilities.index], strategy_sides.loc[probabilities.index], probabilities)\n",
    "> ```\n",
    "> \n",
    "> **Reason:** `strategy_sides` is a pandas Series, and you must use `.loc[]` to index it with a DatetimeIndex (`probabilities.index`), not standard brackets (`[]`).\n",
    "> \n",
    "> After applying this fix, re-start the kernel and run all cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81a5ca3",
   "metadata": {},
   "source": [
    "## 3. Run the Full Simulation\n",
    "\n",
    "We now pass all our configurations to the `overall_backtest_overfitting_simulation` function.\n",
    "\n",
    "**Note:** This is computationally expensive! It is testing:\n",
    "`4 CV Methods` x `4 Strategies` x `2 Models` x `3 Hyperparameters` = **96 backtests**.\n",
    "\n",
    "This may take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not prices.empty:\n",
    "    print(\"Starting simulation... This may take a few minutes.\")\n",
    "    \n",
    "    try:\n",
    "        cv_pbo, cv_deflated_sr = overall_backtest_overfitting_simulation(\n",
    "            prices=prices,\n",
    "            strategy_parameters=strategy_parameters,\n",
    "            models=models,\n",
    "            step_risk_free_rate=step_risk_free_rate,\n",
    "            noise_scale=0.0,\n",
    "            random_state=42,\n",
    "            n_jobs=n_jobs\n",
    "        )\n",
    "    \n",
    "        print(\"\\n--- Simulation Complete ---\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during simulation. \\nDid you apply the bug fix described in the cell above? \\nError: {e}\")\n",
    "        cv_pbo = {}\n",
    "        cv_deflated_sr = {}\n",
    "else:\n",
    "    print(\"Price data is empty. Please load data in Cell 5 and re-run.\")\n",
    "    cv_pbo = {}\n",
    "    cv_deflated_sr = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Results\n",
    "\n",
    "The simulation returns two dictionaries, `cv_pbo` and `cv_deflated_sr`, containing the final scores for each cross-validation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cv_pbo:\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    print(\"--- Probability of Backtest Overfitting (PBO) ---\")\n",
    "    pbo_series = pd.Series(cv_pbo, name=\"PBO_Score\")\n",
    "    pbo_series.index.name = \"CV_Method\"\n",
    "    print(pbo_series.to_markdown(floatfmt=\".2%\"))\n",
    "\n",
    "    print(\"\\n--- Deflated Sharpe Ratio (DSR) Test Statistic ---\")\n",
    "    dsr_series = pd.Series(cv_deflated_sr, name=\"DSR_Score\")\n",
    "    dsr_series.index.name = \"CV_Method\"\n",
    "    print(dsr_series.to_markdown(floatfmt=\".4f\"))\n",
    "\n",
    "    # Plotting\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(16, 6))\n",
    "    pbo_series.plot(kind='bar', ax=ax1, title='Probability of Backtest Overfitting (Lower is Better)')\n",
    "    ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.1%}'.format(y)))\n",
    "    ax1.axhline(0.5, ls='--', color='red', label='Overfit Threshold (50%)')\n",
    "    ax1.legend()\n",
    "\n",
    "    dsr_series.plot(kind='bar', ax=ax2, title='Deflated Sharpe Ratio (Higher is Better)')\n",
    "    ax2.axhline(0, ls='--', color='red')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Simulation did not complete successfully. Please apply the bug fix from Cell 8 and re-run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Conclusion\n",
    "\n",
    "The PBO score (Prob. of Backtest Overfitting) tells us the likelihood that our 'best' strategy was just a fluke. A score > 50% suggests a high chance of overfitting.\n",
    "\n",
    "In a successful run, you will typically see that **'Combinatorial Purged'** (CPCV) and **'Purged K-Fold'** produce a significantly *lower* (better) PBO score than standard 'K-Fold' or 'Walk-Forward', proving they are more robust against overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risklab311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
