{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import necessary modules \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from numpy.linalg import eigvalsh\n",
    "from plotly.subplots import make_subplots\n",
    "import torch\n",
    "import itertools\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rbf_volatility_surface import RBFVolatilitySurface\n",
    "from smoothness_prior import RBFQuadraticSmoothnessPrior\n",
    "from dataset_sabr import generate_sabr_call_options\n",
    "from dupire_pinn_trainer import DupirePINNTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the strike price list and maturity time list\n",
    "strike_price_list = np.array([0.75, 0.85, 0.9, 0.95, 1.0, 1.05, 1.1, 1.2, 1.3, 1.5])\n",
    "maturity_time_list = np.array([0.02, 0.08, 0.17, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0])\n",
    "\n",
    "# Create the product grid of maturity times and strike prices\n",
    "product_grid = list(product(maturity_time_list, strike_price_list))\n",
    "maturity_times, strike_prices = zip(*product_grid)\n",
    "\n",
    "# Convert to arrays for further operations\n",
    "maturity_times = np.array(maturity_times)\n",
    "strike_prices = np.array(strike_prices)\n",
    "\n",
    "# Variance formula for log-uniform distribution\n",
    "def log_uniform_variance(a, b):\n",
    "    log_term = np.log(b / a)\n",
    "    var = ((b ** 2 - a ** 2) / (2 * log_term)) - ((b - a) / log_term) ** 2\n",
    "    return var\n",
    "\n",
    "# Calculate standard deviations for maturity times and strike prices\n",
    "maturity_std = np.sqrt(log_uniform_variance(maturity_time_list.min(), maturity_time_list.max()))\n",
    "strike_std = np.sqrt(log_uniform_variance(strike_price_list.min(), strike_price_list.max()))\n",
    "\n",
    "# Define the SABR model parameters\n",
    "alpha = 0.20  # Stochastic volatility parameter\n",
    "beta = 0.50   # Elasticity parameter\n",
    "rho = -0.75   # Correlation between asset price and volatility\n",
    "nu = 1.0      # Volatility of volatility parameter\n",
    "\n",
    "# Other model parameters\n",
    "risk_free_rate = np.log(1.02)  # Risk-free interest rate\n",
    "underlying_price = 1.0         # Current price of the underlying asset\n",
    "\n",
    "# Generate the dataset using the SABR model and Black-Scholes formula\n",
    "call_option_dataset = generate_sabr_call_options(\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    rho=rho,\n",
    "    nu=nu,\n",
    "    maturity_times=maturity_times,\n",
    "    strike_prices=strike_prices,\n",
    "    risk_free_rate=risk_free_rate,\n",
    "    underlying_price=underlying_price\n",
    ")\n",
    "\n",
    "# Maturity times and strike prices from the previous product grid setup\n",
    "hypothetical_maturity_time_list = np.logspace(np.log10(0.01), np.log10(3.1), 100)\n",
    "hypothetical_strike_price_list = np.logspace(np.log10(0.7), np.log10(1.75), 100)\n",
    "\n",
    "# Create the product grid of maturity times and strike prices\n",
    "hypothetical_product_grid = list(product(hypothetical_maturity_time_list, hypothetical_strike_price_list))\n",
    "hypothetical_maturity_times, hypothetical_strike_prices = zip(*hypothetical_product_grid)\n",
    "hypothetical_maturity_times, hypothetical_strike_prices = np.array(hypothetical_maturity_times), np.array(hypothetical_strike_prices)\n",
    "\n",
    "# Reshape the data for 3D surface plotting\n",
    "hypothetical_maturities_grid = hypothetical_maturity_times.reshape((len(hypothetical_maturity_time_list), len(hypothetical_strike_price_list)))  \n",
    "hypothetical_strikes_grid = hypothetical_strike_prices.reshape((len(hypothetical_maturity_time_list), len(hypothetical_strike_price_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_roots = 350\n",
    "# n_roots = 10\n",
    "smoothness_controller = 3.274549162877732e-05\n",
    "\n",
    "# Initialize the RBFQuadraticSmoothnessPrior class\n",
    "smoothness_prior = RBFQuadraticSmoothnessPrior(\n",
    "    maturity_times=maturity_times,\n",
    "    strike_prices=strike_prices,\n",
    "    maturity_std=maturity_std,\n",
    "    strike_std=strike_std,\n",
    "    n_roots=n_roots,\n",
    "    smoothness_controller=smoothness_controller,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "# The constant_volatility is set to a reasonable value\n",
    "constant_volatility = RBFVolatilitySurface.calculate_constant_volatility(\n",
    "    call_option_dataset[\"Implied Volatility\"],\n",
    "    call_option_dataset[\"Time to Maturity\"],\n",
    "    call_option_dataset[\"Strike Price\"],\n",
    "    risk_free_rate,\n",
    "    underlying_price\n",
    ")\n",
    "\n",
    "sampled_surface_coefficients = smoothness_prior.sample_smooth_surfaces(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the sampled coefficients \n",
    "sampled_volatilities = []\n",
    "for coefficients in sampled_surface_coefficients:\n",
    "    \n",
    "    # Initialize the RBFVolatilitySurface class for each set of coefficients\n",
    "    rbf_surface = RBFVolatilitySurface(\n",
    "        coefficients=coefficients,\n",
    "        maturity_times=maturity_times,\n",
    "        strike_prices=strike_prices,\n",
    "        maturity_std=maturity_std,\n",
    "        strike_std=strike_std,\n",
    "        constant_volatility=constant_volatility\n",
    "    )\n",
    "\n",
    "    # Generate the volatility surface over the product grid of times and strikes\n",
    "    surface_volatilities = [\n",
    "        rbf_surface.implied_volatility_surface(T, K)\n",
    "        for T, K in product_grid\n",
    "    ]\n",
    "    sampled_volatilities.extend(surface_volatilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "pde_loss_coefficient = 1.0\n",
    "maturity_zero_loss_coefficient = 1.0\n",
    "strike_zero_loss_coefficient = 0.1\n",
    "strike_infinity_loss_coefficient = 1.0\n",
    "pre_train_learning_rate = 1e-3\n",
    "fine_tune_learning_rate = 1e-4\n",
    "pre_train_epochs = 50\n",
    "fine_tune_epochs = 20\n",
    "maturity_min = maturity_time_list.min()\n",
    "maturity_max = maturity_time_list.max()\n",
    "strike_min = strike_price_list.min()\n",
    "strike_max = strike_price_list.max()\n",
    "volatility_mean = np.mean(sampled_volatilities)\n",
    "volatility_std = np.std(sampled_volatilities)\n",
    "strike_infinity = 2.5\n",
    "device = 'cpu'\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "hidden_dim_grid = [64, 128, 256]  # Example grid for hidden_dim\n",
    "n_layers_grid = [2, 4, 8]         # Example grid for n_layers\n",
    "pre_train_learning_rate_grid = [1e-4, 1e-3, 1e-2]  # Example grid for learning rate\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "# Define the grid search\n",
    "grid = itertools.product(hidden_dim_grid, n_layers_grid, pre_train_learning_rate_grid)\n",
    "\n",
    "for hidden_dim, n_layers, pre_train_learning_rate in tqdm(grid):\n",
    "    # Initialize the DupirePINNTrainer class\n",
    "    trainer = DupirePINNTrainer(\n",
    "        hidden_dim=hidden_dim,\n",
    "        n_layers=n_layers,\n",
    "        batch_size=batch_size,\n",
    "        pde_loss_coefficient=pde_loss_coefficient,\n",
    "        maturity_zero_loss_coefficient=maturity_zero_loss_coefficient,\n",
    "        strike_zero_loss_coefficient=strike_zero_loss_coefficient,\n",
    "        strike_infinity_loss_coefficient=strike_infinity_loss_coefficient,\n",
    "        pre_train_learning_rate=pre_train_learning_rate,\n",
    "        fine_tune_learning_rate=fine_tune_learning_rate,\n",
    "        pre_train_epochs=pre_train_epochs,\n",
    "        fine_tune_epochs=fine_tune_epochs,\n",
    "        maturity_min=maturity_min,\n",
    "        maturity_max=maturity_max,\n",
    "        strike_min=strike_min,\n",
    "        strike_max=strike_max,\n",
    "        volatility_mean=volatility_mean,\n",
    "        volatility_std=volatility_std,\n",
    "        maturity_time_list=maturity_time_list,\n",
    "        strike_price_list=strike_price_list,\n",
    "        strike_std=strike_std,\n",
    "        maturity_std=maturity_std,\n",
    "        constant_volatility=constant_volatility,\n",
    "        strike_infinity=strike_infinity,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Train the model using pre_train\n",
    "    trainer.pre_train_with_sampling(\n",
    "        smoothness_prior=smoothness_prior,\n",
    "        experiment_name=f\"test_hd_{hidden_dim}_nl_{n_layers}_lr_{pre_train_learning_rate}\"\n",
    "    )\n",
    "\n",
    "    # Retrieve the last row of the loss history (assuming it's stored in trainer.pre_train_loss_history)\n",
    "    loss_df = pd.DataFrame(trainer.pre_train_loss_history)\n",
    "    last_row = loss_df.iloc[-1].copy()\n",
    "\n",
    "    # Add the configuration as columns in the last row\n",
    "    last_row['hidden_dim'] = hidden_dim\n",
    "    last_row['n_layers'] = n_layers\n",
    "    last_row['pre_train_learning_rate'] = pre_train_learning_rate\n",
    "\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([last_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank the losses for each column (except 'Total Loss')\n",
    "ranked_losses = results_df.drop(columns=['Total Loss', 'hidden_dim', 'n_layers', 'pre_train_learning_rate']).rank()\n",
    "\n",
    "ranked_df = results_df.copy()\n",
    "\n",
    "# Compute the average rank for each configuration\n",
    "ranked_df['average_rank'] = ranked_losses.mean(axis=1)\n",
    "\n",
    "# Sort by the average rank (lower is better)\n",
    "ranked_df = ranked_df.sort_values('average_rank')\n",
    "\n",
    "# Print the top-ranked configurations\n",
    "ranked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 64\n",
    "n_layers = 8\n",
    "batch_size = 1000\n",
    "pde_loss_coefficient = 1.0\n",
    "maturity_zero_loss_coefficient = 1.0\n",
    "strike_zero_loss_coefficient = 1.0\n",
    "strike_infinity_loss_coefficient = 1.0\n",
    "pre_train_learning_rate = 1e-3\n",
    "fine_tune_learning_rate = 1e-4\n",
    "pre_train_epochs = 3\n",
    "fine_tune_epochs = 20\n",
    "maturity_min = maturity_time_list.min()\n",
    "maturity_max = maturity_time_list.max()\n",
    "strike_min = strike_price_list.min()\n",
    "strike_max = strike_price_list.max()\n",
    "volatility_mean = np.mean(sampled_volatilities)\n",
    "volatility_std = np.std(sampled_volatilities)\n",
    "strike_infinity = 2.5\n",
    "device = 'cpu'\n",
    "\n",
    "init_loss = pd.DataFrame()\n",
    "\n",
    "for i in range(100):\n",
    "    # Initialize the DupirePINNTrainer class\n",
    "    trainer = DupirePINNTrainer(\n",
    "        hidden_dim=hidden_dim,\n",
    "        n_layers=n_layers,\n",
    "        batch_size=batch_size,\n",
    "        pde_loss_coefficient=pde_loss_coefficient,\n",
    "        maturity_zero_loss_coefficient=maturity_zero_loss_coefficient,\n",
    "        strike_zero_loss_coefficient=strike_zero_loss_coefficient,\n",
    "        strike_infinity_loss_coefficient=strike_infinity_loss_coefficient,\n",
    "        pre_train_learning_rate=pre_train_learning_rate,\n",
    "        fine_tune_learning_rate=fine_tune_learning_rate,\n",
    "        pre_train_epochs=pre_train_epochs,\n",
    "        fine_tune_epochs=fine_tune_epochs,\n",
    "        maturity_min=maturity_min,\n",
    "        maturity_max=maturity_max,\n",
    "        strike_min=strike_min,\n",
    "        strike_max=strike_max,\n",
    "        volatility_mean=volatility_mean,\n",
    "        volatility_std=volatility_std,\n",
    "        maturity_time_list=maturity_time_list,\n",
    "        strike_price_list=strike_price_list,\n",
    "        strike_std=strike_std,\n",
    "        maturity_std=maturity_std,\n",
    "        constant_volatility=constant_volatility,\n",
    "        strike_infinity=strike_infinity,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    trainer.pre_train_with_sampling(\n",
    "        smoothness_prior=smoothness_prior,\n",
    "        experiment_name='test 1'\n",
    "    )\n",
    "\n",
    "    init_loss = pd.concat([init_loss, pd.DataFrame(trainer.pre_train_loss_history)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 / init_loss).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 64\n",
    "n_layers = 8\n",
    "batch_size = 100\n",
    "pde_loss_coefficient = 650.0\n",
    "maturity_zero_loss_coefficient = 800.0\n",
    "strike_zero_loss_coefficient = 40.0\n",
    "strike_infinity_loss_coefficient = 200.0\n",
    "pre_train_learning_rate = 1e-3\n",
    "fine_tune_learning_rate = 1e-4\n",
    "pre_train_epochs = 200\n",
    "fine_tune_epochs = 20\n",
    "maturity_min = maturity_time_list.min()\n",
    "maturity_max = maturity_time_list.max()\n",
    "strike_min = strike_price_list.min()\n",
    "strike_max = strike_price_list.max()\n",
    "volatility_mean = np.mean(sampled_volatilities)\n",
    "volatility_std = np.std(sampled_volatilities)\n",
    "strike_infinity = 2.5\n",
    "device = 'cpu'\n",
    "\n",
    "# Initialize the DupirePINNTrainer class\n",
    "trainer = DupirePINNTrainer(\n",
    "    hidden_dim=hidden_dim,\n",
    "    n_layers=n_layers,\n",
    "    batch_size=batch_size,\n",
    "    pde_loss_coefficient=pde_loss_coefficient,\n",
    "    maturity_zero_loss_coefficient=maturity_zero_loss_coefficient,\n",
    "    strike_zero_loss_coefficient=strike_zero_loss_coefficient,\n",
    "    strike_infinity_loss_coefficient=strike_infinity_loss_coefficient,\n",
    "    pre_train_learning_rate=pre_train_learning_rate,\n",
    "    fine_tune_learning_rate=fine_tune_learning_rate,\n",
    "    pre_train_epochs=pre_train_epochs,\n",
    "    fine_tune_epochs=fine_tune_epochs,\n",
    "    maturity_min=maturity_min,\n",
    "    maturity_max=maturity_max,\n",
    "    strike_min=strike_min,\n",
    "    strike_max=strike_max,\n",
    "    volatility_mean=volatility_mean,\n",
    "    volatility_std=volatility_std,\n",
    "    maturity_time_list=maturity_time_list,\n",
    "    strike_price_list=strike_price_list,\n",
    "    strike_std=strike_std,\n",
    "    maturity_std=maturity_std,\n",
    "    constant_volatility=constant_volatility,\n",
    "    strike_infinity=strike_infinity,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "trainer.pre_train_with_sampling(\n",
    "    smoothness_prior=smoothness_prior,\n",
    "    experiment_name='test 1'\n",
    ")\n",
    "\n",
    "loss_history = pd.DataFrame(trainer.pre_train_loss_history)\n",
    "\n",
    "# Create a subplot figure with 2x2 grid for individual losses, and a third row spanning the entire width for total loss\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    subplot_titles=(\"PDE Loss\", \"Zero Maturity Loss\", \"Zero Strike Loss\", \"Infinity Strike Loss\", \"Total Loss\"),\n",
    "    specs=[[{'type': 'scatter'}, {'type': 'scatter'}],\n",
    "           [{'type': 'scatter'}, {'type': 'scatter'}],\n",
    "           [{'colspan': 2, 'type': 'scatter'}, None]],\n",
    "    vertical_spacing=0.1,\n",
    "    horizontal_spacing=0.1\n",
    ")\n",
    "\n",
    "# Add traces for individual losses\n",
    "fig.add_trace(go.Scatter(x=loss_history.index, y=loss_history[\"PDE Loss\"], mode=\"lines\", name=\"PDE Loss\"), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=loss_history.index, y=loss_history[\"Zero Maturity Loss\"], mode=\"lines\", name=\"Zero Maturity Loss\"), row=1, col=2)\n",
    "fig.add_trace(go.Scatter(x=loss_history.index, y=loss_history[\"Zero Strike Loss\"], mode=\"lines\", name=\"Zero Strike Loss\"), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(x=loss_history.index, y=loss_history[\"Infinity Strike Loss\"], mode=\"lines\", name=\"Infinity Strike Loss\"), row=2, col=2)\n",
    "\n",
    "# Add a trace for the total loss spanning the entire third row\n",
    "fig.add_trace(go.Scatter(x=loss_history.index, y=loss_history[\"Total Loss\"], mode=\"lines\", name=\"Total Loss\"), row=3, col=1)\n",
    "\n",
    "# Update the layout to include 'Iterations' as the x-axis name for each subplot\n",
    "fig.update_xaxes(title_text=\"Iterations\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Iterations\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Iterations\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Iterations\", row=2, col=2)\n",
    "fig.update_xaxes(title_text=\"Iterations\", row=3, col=1)  # The third row spans two columns\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(height=900, width=900, title_text=\"PINN Training Losses\", showlegend=False)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image('figs/pinn_training_loss_history.png', format='png', scale=4, width=900, height=900)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
