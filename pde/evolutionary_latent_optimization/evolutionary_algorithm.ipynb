{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import necessary modules \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rbf_volatility_surface import RBFVolatilitySurface\n",
    "from smoothness_prior import RBFQuadraticSmoothnessPrior\n",
    "from dataset_sabr import generate_sabr_call_options\n",
    "from surface_vae_trainer import SurfaceVAETrainer\n",
    "from dupire_pinn_trainer import DupirePINNTrainer\n",
    "from evolutionary_algorithm import EvolutionaryAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the strike price list and maturity time list\n",
    "strike_price_list = np.array([0.75, 0.85, 0.9, 0.95, 1.0, 1.05, 1.1, 1.2, 1.3, 1.5])\n",
    "maturity_time_list = np.array([0.02, 0.08, 0.17, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0])\n",
    "\n",
    "# Create the product grid of maturity times and strike prices\n",
    "product_grid = list(product(maturity_time_list, strike_price_list))\n",
    "maturity_times, strike_prices = zip(*product_grid)\n",
    "\n",
    "# Convert to arrays for further operations\n",
    "maturity_times = np.array(maturity_times)\n",
    "strike_prices = np.array(strike_prices)\n",
    "\n",
    "# Variance formula for log-uniform distribution\n",
    "def log_uniform_variance(a, b):\n",
    "    log_term = np.log(b / a)\n",
    "    var = ((b ** 2 - a ** 2) / (2 * log_term)) - ((b - a) / log_term) ** 2\n",
    "    return var\n",
    "\n",
    "# Calculate standard deviations for maturity times and strike prices\n",
    "maturity_std = np.sqrt(log_uniform_variance(maturity_time_list.min(), maturity_time_list.max()))\n",
    "strike_std = np.sqrt(log_uniform_variance(strike_price_list.min(), strike_price_list.max()))\n",
    "\n",
    "# Define the SABR model parameters\n",
    "alpha = 0.20  # Stochastic volatility parameter\n",
    "beta = 0.50   # Elasticity parameter\n",
    "rho = -0.75   # Correlation between asset price and volatility\n",
    "nu = 1.0      # Volatility of volatility parameter\n",
    "\n",
    "# Other model parameters\n",
    "risk_free_rate = np.log(1.02)  # Risk-free interest rate\n",
    "underlying_price = 1.0         # Current price of the underlying asset\n",
    "\n",
    "# Generate the dataset using the SABR model and Black-Scholes formula\n",
    "call_option_dataset = generate_sabr_call_options(\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    rho=rho,\n",
    "    nu=nu,\n",
    "    maturity_times=maturity_times,\n",
    "    strike_prices=strike_prices,\n",
    "    risk_free_rate=risk_free_rate,\n",
    "    underlying_price=underlying_price\n",
    ")\n",
    "\n",
    "# Maturity times and strike prices from the previous product grid setup\n",
    "hypothetical_maturity_time_list = np.logspace(np.log10(0.01), np.log10(3.1), 100)\n",
    "hypothetical_strike_price_list = np.logspace(np.log10(0.7), np.log10(1.75), 100)\n",
    "\n",
    "# Create the product grid of maturity times and strike prices\n",
    "hypothetical_product_grid = list(product(hypothetical_maturity_time_list, hypothetical_strike_price_list))\n",
    "hypothetical_maturity_times, hypothetical_strike_prices = zip(*hypothetical_product_grid)\n",
    "hypothetical_maturity_times, hypothetical_strike_prices = np.array(hypothetical_maturity_times), np.array(hypothetical_strike_prices)\n",
    "\n",
    "# Reshape the data for 3D surface plotting\n",
    "hypothetical_maturities_grid = hypothetical_maturity_times.reshape((len(hypothetical_maturity_time_list), len(hypothetical_strike_price_list)))  \n",
    "hypothetical_strikes_grid = hypothetical_strike_prices.reshape((len(hypothetical_maturity_time_list), len(hypothetical_strike_price_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_roots = 350\n",
    "# n_roots = 10\n",
    "smoothness_controller = 3.274549162877732e-05\n",
    "\n",
    "# Initialize the RBFQuadraticSmoothnessPrior class\n",
    "smoothness_prior = RBFQuadraticSmoothnessPrior(\n",
    "    maturity_times=maturity_times,\n",
    "    strike_prices=strike_prices,\n",
    "    maturity_std=maturity_std,\n",
    "    strike_std=strike_std,\n",
    "    n_roots=n_roots,\n",
    "    smoothness_controller=smoothness_controller,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "prior_covariance_matrix = smoothness_prior.prior_covariance()\n",
    "prior_eigenvalues = np.sort(np.linalg.eigvalsh(prior_covariance_matrix))[::-1].copy()\n",
    "\n",
    "# The constant_volatility is set to a reasonable value\n",
    "constant_volatility = RBFVolatilitySurface.calculate_constant_volatility(\n",
    "    call_option_dataset[\"Implied Volatility\"],\n",
    "    call_option_dataset[\"Time to Maturity\"],\n",
    "    call_option_dataset[\"Strike Price\"],\n",
    "    risk_free_rate,\n",
    "    underlying_price\n",
    ")\n",
    "\n",
    "sampled_surface_coefficients = smoothness_prior.sample_smooth_surfaces(1000)\n",
    "\n",
    "# Loop through the sampled coefficients \n",
    "sampled_volatilities = []\n",
    "for coefficients in sampled_surface_coefficients:\n",
    "    \n",
    "    # Initialize the RBFVolatilitySurface class for each set of coefficients\n",
    "    rbf_surface = RBFVolatilitySurface(\n",
    "        coefficients=coefficients,\n",
    "        maturity_times=maturity_times,\n",
    "        strike_prices=strike_prices,\n",
    "        maturity_std=maturity_std,\n",
    "        strike_std=strike_std,\n",
    "        constant_volatility=constant_volatility\n",
    "    )\n",
    "\n",
    "    # Generate the volatility surface over the product grid of times and strikes\n",
    "    surface_volatilities = [\n",
    "        rbf_surface.implied_volatility_surface(T, K)\n",
    "        for T, K in product_grid\n",
    "    ]\n",
    "    sampled_volatilities.extend(surface_volatilities)\n",
    "\n",
    "hidden_dim = 64\n",
    "n_layers = 8\n",
    "batch_size = 100\n",
    "pde_loss_coefficient = 650.0\n",
    "maturity_zero_loss_coefficient = 800.0\n",
    "strike_zero_loss_coefficient = 40.0\n",
    "strike_infinity_loss_coefficient = 200.0\n",
    "pre_train_learning_rate = 1e-3\n",
    "fine_tune_learning_rate = 1e-4\n",
    "pre_train_epochs = 200\n",
    "fine_tune_epochs = 20\n",
    "maturity_min = maturity_time_list.min()\n",
    "maturity_max = maturity_time_list.max()\n",
    "strike_min = strike_price_list.min()\n",
    "strike_max = strike_price_list.max()\n",
    "volatility_mean = np.mean(sampled_volatilities)\n",
    "volatility_std = np.std(sampled_volatilities)\n",
    "strike_infinity = 2.5\n",
    "device = 'cpu'\n",
    "\n",
    "# Initialize the DupirePINNTrainer class\n",
    "torch.manual_seed(0)\n",
    "pinn_trainer = DupirePINNTrainer(\n",
    "    hidden_dim=hidden_dim,\n",
    "    n_layers=n_layers,\n",
    "    batch_size=batch_size,\n",
    "    pde_loss_coefficient=pde_loss_coefficient,\n",
    "    maturity_zero_loss_coefficient=maturity_zero_loss_coefficient,\n",
    "    strike_zero_loss_coefficient=strike_zero_loss_coefficient,\n",
    "    strike_infinity_loss_coefficient=strike_infinity_loss_coefficient,\n",
    "    pre_train_learning_rate=pre_train_learning_rate,\n",
    "    fine_tune_learning_rate=fine_tune_learning_rate,\n",
    "    pre_train_epochs=pre_train_epochs,\n",
    "    fine_tune_epochs=fine_tune_epochs,\n",
    "    maturity_min=maturity_min,\n",
    "    maturity_max=maturity_max,\n",
    "    strike_min=strike_min,\n",
    "    strike_max=strike_max,\n",
    "    volatility_mean=volatility_mean,\n",
    "    volatility_std=volatility_std,\n",
    "    maturity_time_list=maturity_time_list,\n",
    "    strike_price_list=strike_price_list,\n",
    "    strike_std=strike_std,\n",
    "    maturity_std=maturity_std,\n",
    "    constant_volatility=constant_volatility,\n",
    "    strike_infinity=strike_infinity,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "pinn_trainer.load_model()\n",
    "\n",
    "pinn_trainer.dupire_price_prediction_loss(\n",
    "    torch.tensor(sampled_surface_coefficients, device=device, dtype=torch.float32),\n",
    "    call_option_dataset[\"Call Option Price\"],\n",
    "    call_option_dataset[\"Time to Maturity\"],\n",
    "    call_option_dataset[\"Strike Price\"],\n",
    ")\n",
    "print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 40  # Latent dimension\n",
    "data_dim = 100  # Data dimension of input\n",
    "hidden_dim = 512\n",
    "n_layers = 8\n",
    "latent_diagonal = prior_eigenvalues[:latent_dim]  # Eigenvalues for latent prior\n",
    "batch_size = 1000  # Batch size for training\n",
    "beta_ = 1.0  # Beta value for beta-VAE\n",
    "pre_train_learning_rate = 1e-3\n",
    "fine_tune_learning_rate = 1e-4  # Fine-tune learning rate\n",
    "pre_train_epochs = 600  # Number of pre-train epochs\n",
    "fine_tune_epochs = 20  # Number of fine-tune epochs\n",
    "device = \"cpu\"  # Use CPU as the device\n",
    "\n",
    "torch.manual_seed(2)\n",
    "vae_trainer = SurfaceVAETrainer(\n",
    "    latent_dim=latent_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    n_layers=n_layers,\n",
    "    data_dim=data_dim,\n",
    "    latent_diagonal=latent_diagonal,\n",
    "    batch_size=batch_size,\n",
    "    beta=beta_,\n",
    "    pre_train_learning_rate=pre_train_learning_rate,\n",
    "    fine_tune_learning_rate=fine_tune_learning_rate,\n",
    "    pre_train_epochs=pre_train_epochs,\n",
    "    fine_tune_epochs=fine_tune_epochs,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "vae_trainer.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "# population_sizes = [10, 100, 1000]\n",
    "population_sizes = [100]\n",
    "mutation_strengths = [0.1, 1.0, 10.0]\n",
    "selection_pressure_parameters = [0.01, 0.1, 0.3, 0.5, 0.7]\n",
    "n_generations = 1000\n",
    "truncation_clip = 3\n",
    "\n",
    "# Store results for each configuration\n",
    "results = []\n",
    "\n",
    "for population_size, mutation_strength, selection_pressure_parameter in tqdm(\n",
    "    product(population_sizes, mutation_strengths, selection_pressure_parameters),\n",
    "    total=len(population_sizes) * len(mutation_strengths) * len(selection_pressure_parameters),\n",
    "    desc=\"Processing combinations\"\n",
    "):\n",
    "    # Initialize Evolutionary Algorithm with the current parameters\n",
    "    torch.manual_seed(2)\n",
    "    evolution_algo = EvolutionaryAlgorithm(\n",
    "        vae_trainer=vae_trainer,\n",
    "        pinn_trainer=pinn_trainer,\n",
    "        latent_diagonal=latent_diagonal,\n",
    "        population_size=population_size,\n",
    "        mutation_strength=mutation_strength,\n",
    "        selection_pressure_parameter=selection_pressure_parameter,\n",
    "        n_generations=n_generations,\n",
    "        truncation_clip=truncation_clip\n",
    "    )\n",
    "\n",
    "    # Run the optimization\n",
    "    evolution_algo.optimize()\n",
    "\n",
    "    # Metrics calculation\n",
    "    final_best_fitness = evolution_algo.optimization_history[\"Best Fitness\"][-1]  # Best fitness\n",
    "    initial_fitness = evolution_algo.optimization_history[\"Best Fitness\"][0]\n",
    "    n_generation = n_generations\n",
    "\n",
    "    # Calculate the diversity\n",
    "    population_variance = np.var(evolution_algo.population.cpu().numpy(), axis=0)\n",
    "    diversity = np.sum(population_variance / latent_diagonal)\n",
    "\n",
    "    # Store the results for this configuration\n",
    "    results.append({\n",
    "        \"population_size\": population_size,\n",
    "        \"mutation_strength\": mutation_strength,\n",
    "        \"selection_pressure_parameter\": selection_pressure_parameter,\n",
    "        \"final_best_fitness\": final_best_fitness,\n",
    "        \"diversity\": diversity,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Rank the configurations based on each metric\n",
    "results_df[\"rank_best_fitness\"] = results_df[\"final_best_fitness\"].rank(ascending=False)\n",
    "results_df[\"rank_diversity\"] = results_df[\"diversity\"].rank(ascending=False)\n",
    "\n",
    "# Calculate the average rank\n",
    "results_df[\"average_rank\"] = results_df[[\"rank_best_fitness\", \"rank_diversity\"]].mean(axis=1)\n",
    "\n",
    "# Sort by the average rank (lower is better)\n",
    "results_df_sorted = results_df.sort_values(by=\"average_rank\", ascending=True)\n",
    "\n",
    "# Display the sorted results\n",
    "results_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evolutionary algorithm hyperparameters\n",
    "population_size = 100 # Population size\n",
    "mutation_strength = 1.0  # Mutation strength for Gaussian noise\n",
    "selection_pressure_parameter = 0.7  # Selection pressure parameter (eta)\n",
    "n_generations = 1000  # Number of generations for the evolutionary process\n",
    "truncation_clip = 3\n",
    "torch.manual_seed(2)\n",
    "# Initialize the EvolutionaryAlgorithm\n",
    "evolution_algo = EvolutionaryAlgorithm(\n",
    "    vae_trainer=vae_trainer,\n",
    "    pinn_trainer=pinn_trainer,\n",
    "    latent_diagonal=latent_diagonal,\n",
    "    population_size=population_size,\n",
    "    mutation_strength=mutation_strength,\n",
    "    selection_pressure_parameter=selection_pressure_parameter,\n",
    "    n_generations=n_generations,\n",
    "    truncation_clip=truncation_clip\n",
    ")\n",
    "\n",
    "# Run the optimization process\n",
    "evolution_algo.optimize()\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Calculate the diversity\n",
    "population_variance = np.var(evolution_algo.population.cpu().numpy(), axis=0)\n",
    "diversity = np.sum(population_variance / latent_diagonal)\n",
    "\n",
    "optimization_history = pd.DataFrame(evolution_algo.optimization_history)\n",
    "best_fitness = optimization_history[\"Best Fitness\"].iloc[-1]\n",
    "\n",
    "# Add trace for best fitness\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(1, len(optimization_history[\"Best Fitness\"]) + 1)),\n",
    "    y=optimization_history[\"Best Fitness\"],\n",
    "    mode='lines+markers',\n",
    "    name='Best Fitness',\n",
    "    line=dict(color='royalblue', width=3),\n",
    "    marker=dict(size=6, symbol='circle'),\n",
    "    hovertemplate='<b>Iteration %{x}</b><br>Best Fitness: %{y:.4f}<extra></extra>'\n",
    "))\n",
    "\n",
    "# Add trace for average fitness\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(1, len(optimization_history[\"Average Fitness\"]) + 1)),\n",
    "    y=optimization_history[\"Average Fitness\"],\n",
    "    mode='lines+markers',\n",
    "    name='Average Fitness',\n",
    "    line=dict(color='firebrick', width=3, dash='dash'),\n",
    "    marker=dict(size=6, symbol='square'),\n",
    "    hovertemplate='<b>Iteration %{x}</b><br>Average Fitness: %{y:.4f}<extra></extra>'\n",
    "))\n",
    "\n",
    "# Add trace for avg fitness - 1.96 * std fitness\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(1, len(optimization_history[\"0.05 Percentile Fitness\"]) + 1)),\n",
    "    y=optimization_history[\"0.05 Percentile Fitness\"],\n",
    "    mode='lines+markers',\n",
    "    name='0.05 Percentile Fitness',\n",
    "    line=dict(color='green', width=3, dash='dot'),\n",
    "    marker=dict(size=6, symbol='triangle-up'),\n",
    "    hovertemplate='<b>Iteration %{x}</b><br>0.05 Percentile Fitness: %{y:.4f}<extra></extra>'\n",
    "))\n",
    "\n",
    "# Add an annotation for best fitness and diversity\n",
    "fig.add_annotation(\n",
    "    xref='paper', yref='paper', \n",
    "    x=0.96, y=0.05,\n",
    "    text=f\"Best Fitness: {best_fitness:.4f}<br>Diversity: {diversity:.4f}\",\n",
    "    showarrow=False,\n",
    "    # font=dict(\n",
    "    #     size=14,\n",
    "    #     color=\"black\"\n",
    "    # ),\n",
    "    align=\"left\",\n",
    "    # bordercolor=\"black\",\n",
    "    borderwidth=2,\n",
    "    borderpad=4,\n",
    "    bgcolor=\"white\",\n",
    "    opacity=1.\n",
    ")\n",
    "\n",
    "# Update layout to make the plot detailed and visually appealing\n",
    "fig.update_layout(\n",
    "    title=\"Initial Evolutionary Optimization History\",\n",
    "    xaxis_title=\"Generation\",\n",
    "    yaxis_title=\"Fitness Value\",\n",
    "    legend=dict(\n",
    "        x=0.75,\n",
    "        y=0.15,\n",
    "    ),\n",
    "    hovermode='x unified',\n",
    "    width=900,\n",
    "    height=900,\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "fig.write_image('figs/initial_evolutionary_optimization_history.png', format='png', scale=4, width=900, height=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 4 surface coefficients using the smoothness prior\n",
    "n_samples = 4\n",
    "fine_tune_surface_coefficients = evolution_algo.final_population.values\n",
    "sampled_coefficients = fine_tune_surface_coefficients[:4]\n",
    "\n",
    "# The constant_volatility is set to a reasonable value\n",
    "constant_volatility = RBFVolatilitySurface.calculate_constant_volatility(\n",
    "    call_option_dataset[\"Implied Volatility\"],\n",
    "    call_option_dataset[\"Time to Maturity\"],\n",
    "    call_option_dataset[\"Strike Price\"],\n",
    "    risk_free_rate,\n",
    "    underlying_price\n",
    ")\n",
    "\n",
    "# Create the 3x3 subplots\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=[f\"Sample Surface {i+1}\" for i in range(n_samples)],\n",
    "    specs=[[{'type': 'surface'}] * 2] * 2,\n",
    "    vertical_spacing=0.075, horizontal_spacing=0.001\n",
    ")\n",
    "\n",
    "# Loop through the sampled coefficients to generate and plot each surface\n",
    "for idx, coefficients in enumerate(sampled_coefficients):\n",
    "    row = (idx // 2) + 1\n",
    "    col = (idx % 2) + 1\n",
    "    \n",
    "    # Initialize the RBFVolatilitySurface class for each set of coefficients\n",
    "    rbf_surface = RBFVolatilitySurface(\n",
    "        coefficients=coefficients,\n",
    "        maturity_times=maturity_times,\n",
    "        strike_prices=strike_prices,\n",
    "        maturity_std=maturity_std,\n",
    "        strike_std=strike_std,\n",
    "        constant_volatility=constant_volatility\n",
    "    )\n",
    "\n",
    "    # Generate the volatility surface over the product grid of times and strikes\n",
    "    surface_volatilities = np.array([\n",
    "        rbf_surface.implied_volatility_surface(T, K)\n",
    "        for T, K in hypothetical_product_grid\n",
    "    ]).reshape(len(hypothetical_maturity_time_list), len(hypothetical_strike_price_list))\n",
    "\n",
    "    # Add the surface plot to the subplot\n",
    "    fig.add_trace(\n",
    "        go.Surface(\n",
    "            x=hypothetical_strikes_grid,\n",
    "            y=hypothetical_maturities_grid,\n",
    "            z=surface_volatilities,\n",
    "            colorscale='Cividis',\n",
    "            showscale=False  # Hide the scale on individual plots\n",
    "        ),\n",
    "        row=row, col=col\n",
    "    )\n",
    "\n",
    "for i in range(1, 3):  # Rows\n",
    "    for j in range(1, 3):  # Columns\n",
    "        fig.update_scenes(\n",
    "            dict(\n",
    "                xaxis_title=\"Strike Price\",\n",
    "                yaxis_title=\"Time to Maturity\",\n",
    "                zaxis_title=\"Implied Volatility\",\n",
    "                camera=dict(\n",
    "                    eye=dict(x=1.5, y=1.5, z=1.5)  # Controls the zoom level, adjust these to zoom out\n",
    "                ),\n",
    "                aspectratio=dict(x=1, y=1, z=0.8)\n",
    "            ),\n",
    "            row=i, col=j\n",
    "        )    \n",
    "\n",
    "# Update the layout of the figure\n",
    "fig.update_layout(\n",
    "    title=\"Initial Latent Evolutionary Optimization Top Surfaces\",\n",
    "    height=900, width=900, title_x=0.5,\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "fig.write_image('figs/initial_evolutionary_optimization_top_surfaces.png', format='png', scale=4, width=900, height=900)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
