{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import necessary modules \n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import torch\n",
    "\n",
    "from rbf_volatility_surface import RBFVolatilitySurface\n",
    "from smoothness_prior import RBFQuadraticSmoothnessPrior\n",
    "from dataset_sabr import generate_sabr_call_options\n",
    "from surface_vae_trainer import SurfaceVAETrainer\n",
    "from dupire_pinn_trainer import DupirePINNTrainer\n",
    "from adaptive_latent_evolutionary_optimization import AdaptiveEvolutionaryLatentOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the strike price list and maturity time list\n",
    "strike_price_list = np.array([0.75, 0.85, 0.9, 0.95, 1.0, 1.05, 1.1, 1.2, 1.3, 1.5])\n",
    "maturity_time_list = np.array([0.02, 0.08, 0.17, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0])\n",
    "\n",
    "# Create the product grid of maturity times and strike prices\n",
    "product_grid = list(product(maturity_time_list, strike_price_list))\n",
    "maturity_times, strike_prices = zip(*product_grid)\n",
    "\n",
    "# Convert to arrays for further operations\n",
    "maturity_times = np.array(maturity_times)\n",
    "strike_prices = np.array(strike_prices)\n",
    "\n",
    "# Variance formula for log-uniform distribution\n",
    "def log_uniform_variance(a, b):\n",
    "    log_term = np.log(b / a)\n",
    "    var = ((b ** 2 - a ** 2) / (2 * log_term)) - ((b - a) / log_term) ** 2\n",
    "    return var\n",
    "\n",
    "# Calculate standard deviations for maturity times and strike prices\n",
    "maturity_std = np.sqrt(log_uniform_variance(maturity_time_list.min(), maturity_time_list.max()))\n",
    "strike_std = np.sqrt(log_uniform_variance(strike_price_list.min(), strike_price_list.max()))\n",
    "\n",
    "# Define the SABR model parameters\n",
    "alpha = 0.20  # Stochastic volatility parameter\n",
    "beta = 0.50   # Elasticity parameter\n",
    "rho = -0.75   # Correlation between asset price and volatility\n",
    "nu = 1.0      # Volatility of volatility parameter\n",
    "\n",
    "# Other model parameters\n",
    "risk_free_rate = np.log(1.02)  # Risk-free interest rate\n",
    "underlying_price = 1.0         # Current price of the underlying asset\n",
    "\n",
    "# Generate the dataset using the SABR model and Black-Scholes formula\n",
    "call_option_dataset = generate_sabr_call_options(\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    rho=rho,\n",
    "    nu=nu,\n",
    "    maturity_times=maturity_times,\n",
    "    strike_prices=strike_prices,\n",
    "    risk_free_rate=risk_free_rate,\n",
    "    underlying_price=underlying_price\n",
    ")\n",
    "\n",
    "# Maturity times and strike prices from the previous product grid setup\n",
    "hypothetical_maturity_time_list = np.logspace(np.log10(0.01), np.log10(3.1), 100)\n",
    "hypothetical_strike_price_list = np.logspace(np.log10(0.7), np.log10(1.75), 100)\n",
    "\n",
    "# Create the product grid of maturity times and strike prices\n",
    "hypothetical_product_grid = list(product(hypothetical_maturity_time_list, hypothetical_strike_price_list))\n",
    "hypothetical_maturity_times, hypothetical_strike_prices = zip(*hypothetical_product_grid)\n",
    "hypothetical_maturity_times, hypothetical_strike_prices = np.array(hypothetical_maturity_times), np.array(hypothetical_strike_prices)\n",
    "\n",
    "# Reshape the data for 3D surface plotting\n",
    "hypothetical_maturities_grid = hypothetical_maturity_times.reshape((len(hypothetical_maturity_time_list), len(hypothetical_strike_price_list)))  \n",
    "hypothetical_strikes_grid = hypothetical_strike_prices.reshape((len(hypothetical_maturity_time_list), len(hypothetical_strike_price_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_roots = 350\n",
    "smoothness_controller = 3.274549162877732e-05\n",
    "\n",
    "# Initialize the RBFQuadraticSmoothnessPrior class\n",
    "smoothness_prior = RBFQuadraticSmoothnessPrior(\n",
    "    maturity_times=maturity_times,\n",
    "    strike_prices=strike_prices,\n",
    "    maturity_std=maturity_std,\n",
    "    strike_std=strike_std,\n",
    "    n_roots=n_roots,\n",
    "    smoothness_controller=smoothness_controller,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "prior_covariance_matrix = smoothness_prior.prior_covariance()\n",
    "prior_eigenvalues = np.sort(np.linalg.eigvalsh(prior_covariance_matrix))[::-1].copy()\n",
    "\n",
    "# The constant_volatility is set to a reasonable value\n",
    "constant_volatility = RBFVolatilitySurface.calculate_constant_volatility(\n",
    "    call_option_dataset[\"Implied Volatility\"],\n",
    "    call_option_dataset[\"Time to Maturity\"],\n",
    "    call_option_dataset[\"Strike Price\"],\n",
    "    risk_free_rate,\n",
    "    underlying_price\n",
    ")\n",
    "\n",
    "sampled_surface_coefficients = smoothness_prior.sample_smooth_surfaces(1000)\n",
    "\n",
    "# Loop through the sampled coefficients \n",
    "sampled_volatilities = []\n",
    "for coefficients in sampled_surface_coefficients:\n",
    "    \n",
    "    # Initialize the RBFVolatilitySurface class for each set of coefficients\n",
    "    rbf_surface = RBFVolatilitySurface(\n",
    "        coefficients=coefficients,\n",
    "        maturity_times=maturity_times,\n",
    "        strike_prices=strike_prices,\n",
    "        maturity_std=maturity_std,\n",
    "        strike_std=strike_std,\n",
    "        constant_volatility=constant_volatility\n",
    "    )\n",
    "\n",
    "    # Generate the volatility surface over the product grid of times and strikes\n",
    "    surface_volatilities = [\n",
    "        rbf_surface.implied_volatility_surface(T, K)\n",
    "        for T, K in product_grid\n",
    "    ]\n",
    "    sampled_volatilities.extend(surface_volatilities)\n",
    "\n",
    "hidden_dim = 64\n",
    "n_layers = 8\n",
    "batch_size = 100\n",
    "pde_loss_coefficient = 650.0\n",
    "maturity_zero_loss_coefficient = 800.0\n",
    "strike_zero_loss_coefficient = 40.0\n",
    "strike_infinity_loss_coefficient = 200.0\n",
    "pre_train_learning_rate = 1e-3\n",
    "fine_tune_learning_rate = 1e-3\n",
    "pre_train_epochs = 200\n",
    "fine_tune_epochs = 6\n",
    "maturity_min = maturity_time_list.min()\n",
    "maturity_max = maturity_time_list.max()\n",
    "strike_min = strike_price_list.min()\n",
    "strike_max = strike_price_list.max()\n",
    "volatility_mean = np.mean(sampled_volatilities)\n",
    "volatility_std = np.std(sampled_volatilities)\n",
    "strike_infinity = 2.5\n",
    "device = 'cpu'\n",
    "\n",
    "# Initialize the DupirePINNTrainer class\n",
    "torch.manual_seed(0)\n",
    "pinn_trainer = DupirePINNTrainer(\n",
    "    hidden_dim=hidden_dim,\n",
    "    n_layers=n_layers,\n",
    "    batch_size=batch_size,\n",
    "    pde_loss_coefficient=pde_loss_coefficient,\n",
    "    maturity_zero_loss_coefficient=maturity_zero_loss_coefficient,\n",
    "    strike_zero_loss_coefficient=strike_zero_loss_coefficient,\n",
    "    strike_infinity_loss_coefficient=strike_infinity_loss_coefficient,\n",
    "    pre_train_learning_rate=pre_train_learning_rate,\n",
    "    fine_tune_learning_rate=fine_tune_learning_rate,\n",
    "    pre_train_epochs=pre_train_epochs,\n",
    "    fine_tune_epochs=fine_tune_epochs,\n",
    "    maturity_min=maturity_min,\n",
    "    maturity_max=maturity_max,\n",
    "    strike_min=strike_min,\n",
    "    strike_max=strike_max,\n",
    "    volatility_mean=volatility_mean,\n",
    "    volatility_std=volatility_std,\n",
    "    maturity_time_list=maturity_time_list,\n",
    "    strike_price_list=strike_price_list,\n",
    "    strike_std=strike_std,\n",
    "    maturity_std=maturity_std,\n",
    "    constant_volatility=constant_volatility,\n",
    "    strike_infinity=strike_infinity,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "pinn_trainer.load_model()\n",
    "\n",
    "pinn_trainer.dupire_price_prediction_loss(\n",
    "    torch.tensor(sampled_surface_coefficients, device=device, dtype=torch.float32),\n",
    "    call_option_dataset[\"Call Option Price\"],\n",
    "    call_option_dataset[\"Time to Maturity\"],\n",
    "    call_option_dataset[\"Strike Price\"],\n",
    ")\n",
    "print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 40  # Latent dimension\n",
    "data_dim = 100  # Data dimension of input\n",
    "hidden_dim = 512\n",
    "n_layers = 8\n",
    "latent_diagonal = prior_eigenvalues[:latent_dim]  # Eigenvalues for latent prior\n",
    "batch_size = 1000  # Batch size for training\n",
    "beta_ = 1.0  # Beta value for beta-VAE\n",
    "pre_train_learning_rate = 1e-3\n",
    "fine_tune_learning_rate = 1e-3  # Fine-tune learning rate\n",
    "pre_train_epochs = 600  # Number of pre-train epochs\n",
    "fine_tune_epochs = 6  # Number of fine-tune epochs\n",
    "device = \"cpu\"  # Use CPU as the device\n",
    "\n",
    "torch.manual_seed(2)\n",
    "vae_trainer = SurfaceVAETrainer(\n",
    "    latent_dim=latent_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    n_layers=n_layers,\n",
    "    data_dim=data_dim,\n",
    "    latent_diagonal=latent_diagonal,\n",
    "    batch_size=batch_size,\n",
    "    beta=beta_,\n",
    "    pre_train_learning_rate=pre_train_learning_rate,\n",
    "    fine_tune_learning_rate=fine_tune_learning_rate,\n",
    "    pre_train_epochs=pre_train_epochs,\n",
    "    fine_tune_epochs=fine_tune_epochs,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "vae_trainer.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = 100 # Population size\n",
    "mutation_strength = 1.0  # Mutation strength for Gaussian noise\n",
    "selection_pressure_parameter = 0.7  # Selection pressure parameter (eta)\n",
    "n_generations = 1000  # Number of generations for the evolutionary process\n",
    "truncation_clip = 3\n",
    "n_cycles = 30\n",
    "torch.manual_seed(2)\n",
    "# Initialize the AdaptiveEvolutionaryLatentOptimization\n",
    "adelo = AdaptiveEvolutionaryLatentOptimization(\n",
    "    vae_trainer=vae_trainer,\n",
    "    pinn_trainer=pinn_trainer,\n",
    "    latent_diagonal=latent_diagonal,\n",
    "    population_size=population_size,\n",
    "    mutation_strength=mutation_strength,\n",
    "    selection_pressure_parameter=selection_pressure_parameter,\n",
    "    n_generations=n_generations,\n",
    "    truncation_clip=truncation_clip,\n",
    "    n_cycles=n_cycles\n",
    ")\n",
    "\n",
    "# Run the optimization process\n",
    "adelo.run_cycle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adelo.plot_evolutions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 4 surface coefficients using the smoothness prior\n",
    "n_samples = 4\n",
    "fine_tune_surface_coefficients = adelo.final_population.values\n",
    "sampled_coefficients = fine_tune_surface_coefficients[:4]\n",
    "\n",
    "# The constant_volatility is set to a reasonable value\n",
    "constant_volatility = RBFVolatilitySurface.calculate_constant_volatility(\n",
    "    call_option_dataset[\"Implied Volatility\"],\n",
    "    call_option_dataset[\"Time to Maturity\"],\n",
    "    call_option_dataset[\"Strike Price\"],\n",
    "    risk_free_rate,\n",
    "    underlying_price\n",
    ")\n",
    "\n",
    "# Create the 3x3 subplots\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=[f\"Sample Surface {i+1}\" for i in range(n_samples)],\n",
    "    specs=[[{'type': 'surface'}] * 2] * 2,\n",
    "    vertical_spacing=0.075, horizontal_spacing=0.001\n",
    ")\n",
    "\n",
    "# Loop through the sampled coefficients to generate and plot each surface\n",
    "for idx, coefficients in enumerate(sampled_coefficients):\n",
    "    row = (idx // 2) + 1\n",
    "    col = (idx % 2) + 1\n",
    "    \n",
    "    # Initialize the RBFVolatilitySurface class for each set of coefficients\n",
    "    rbf_surface = RBFVolatilitySurface(\n",
    "        coefficients=coefficients,\n",
    "        maturity_times=maturity_times,\n",
    "        strike_prices=strike_prices,\n",
    "        maturity_std=maturity_std,\n",
    "        strike_std=strike_std,\n",
    "        constant_volatility=constant_volatility\n",
    "    )\n",
    "\n",
    "    # Generate the volatility surface over the product grid of times and strikes\n",
    "    surface_volatilities = np.array([\n",
    "        rbf_surface.implied_volatility_surface(T, K)\n",
    "        for T, K in hypothetical_product_grid\n",
    "    ]).reshape(len(hypothetical_maturity_time_list), len(hypothetical_strike_price_list))\n",
    "\n",
    "    # Add the surface plot to the subplot\n",
    "    fig.add_trace(\n",
    "        go.Surface(\n",
    "            x=hypothetical_strikes_grid,\n",
    "            y=hypothetical_maturities_grid,\n",
    "            z=surface_volatilities,\n",
    "            # colorscale='Viridis',\n",
    "            showscale=False  # Hide the scale on individual plots\n",
    "        ),\n",
    "        row=row, col=col\n",
    "    )\n",
    "\n",
    "for i in range(1, 3):  # Rows\n",
    "    for j in range(1, 3):  # Columns\n",
    "        fig.update_scenes(\n",
    "            dict(\n",
    "                xaxis_title=\"Strike Price\",\n",
    "                yaxis_title=\"Time to Maturity\",\n",
    "                zaxis_title=\"Implied Volatility\",\n",
    "                camera=dict(\n",
    "                    eye=dict(x=1.5, y=1.5, z=1.5)  # Controls the zoom level, adjust these to zoom out\n",
    "                ),\n",
    "                aspectratio=dict(x=1, y=1, z=0.8)\n",
    "            ),\n",
    "            row=i, col=j\n",
    "        )    \n",
    "\n",
    "# Update the layout of the figure\n",
    "fig.update_layout(\n",
    "    title=\"Adaptive Latent Evolutionary Optimization Top Surfaces\",\n",
    "    height=900, width=900, title_x=0.5,\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "fig.write_image('figs/adaptive_evolutionary_optimization_top_surfaces.png', format='png', scale=4, width=900, height=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_trainer.save_model('models/fine_tuned_vae.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinn_trainer.save_model('models/fine_tuned_pinn.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
