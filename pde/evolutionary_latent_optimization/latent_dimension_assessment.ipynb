{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import necessary modules \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import torch\n",
    "\n",
    "from rbf_volatility_surface import RBFVolatilitySurface\n",
    "from smoothness_prior import RBFQuadraticSmoothnessPrior\n",
    "from dataset_sabr import generate_sabr_call_options\n",
    "from surface_vae_trainer import SurfaceVAETrainer\n",
    "from dupire_pinn_trainer import DupirePINNTrainer\n",
    "from latent_dimension_assessment import sample_latent_vectors, latent_space_assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the strike price list and maturity time list\n",
    "strike_price_list = np.array([0.75, 0.85, 0.9, 0.95, 1.0, 1.05, 1.1, 1.2, 1.3, 1.5])\n",
    "maturity_time_list = np.array([0.02, 0.08, 0.17, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0])\n",
    "\n",
    "# Create the product grid of maturity times and strike prices\n",
    "product_grid = list(product(maturity_time_list, strike_price_list))\n",
    "maturity_times, strike_prices = zip(*product_grid)\n",
    "\n",
    "# Convert to arrays for further operations\n",
    "maturity_times = np.array(maturity_times)\n",
    "strike_prices = np.array(strike_prices)\n",
    "\n",
    "# Variance formula for log-uniform distribution\n",
    "def log_uniform_variance(a, b):\n",
    "    log_term = np.log(b / a)\n",
    "    var = ((b ** 2 - a ** 2) / (2 * log_term)) - ((b - a) / log_term) ** 2\n",
    "    return var\n",
    "\n",
    "# Calculate standard deviations for maturity times and strike prices\n",
    "maturity_std = np.sqrt(log_uniform_variance(maturity_time_list.min(), maturity_time_list.max()))\n",
    "strike_std = np.sqrt(log_uniform_variance(strike_price_list.min(), strike_price_list.max()))\n",
    "\n",
    "# Define the SABR model parameters\n",
    "alpha = 0.20  # Stochastic volatility parameter\n",
    "beta = 0.50   # Elasticity parameter\n",
    "rho = -0.75   # Correlation between asset price and volatility\n",
    "nu = 1.0      # Volatility of volatility parameter\n",
    "\n",
    "# Other model parameters\n",
    "risk_free_rate = np.log(1.02)  # Risk-free interest rate\n",
    "underlying_price = 1.0         # Current price of the underlying asset\n",
    "\n",
    "# Generate the dataset using the SABR model and Black-Scholes formula\n",
    "call_option_dataset = generate_sabr_call_options(\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    rho=rho,\n",
    "    nu=nu,\n",
    "    maturity_times=maturity_times,\n",
    "    strike_prices=strike_prices,\n",
    "    risk_free_rate=risk_free_rate,\n",
    "    underlying_price=underlying_price\n",
    ")\n",
    "\n",
    "# Maturity times and strike prices from the previous product grid setup\n",
    "hypothetical_maturity_time_list = np.logspace(np.log10(0.01), np.log10(3.1), 100)\n",
    "hypothetical_strike_price_list = np.logspace(np.log10(0.7), np.log10(1.75), 100)\n",
    "\n",
    "# Create the product grid of maturity times and strike prices\n",
    "hypothetical_product_grid = list(product(hypothetical_maturity_time_list, hypothetical_strike_price_list))\n",
    "hypothetical_maturity_times, hypothetical_strike_prices = zip(*hypothetical_product_grid)\n",
    "hypothetical_maturity_times, hypothetical_strike_prices = np.array(hypothetical_maturity_times), np.array(hypothetical_strike_prices)\n",
    "\n",
    "# Reshape the data for 3D surface plotting\n",
    "hypothetical_maturities_grid = hypothetical_maturity_times.reshape((len(hypothetical_maturity_time_list), len(hypothetical_strike_price_list)))  \n",
    "hypothetical_strikes_grid = hypothetical_strike_prices.reshape((len(hypothetical_maturity_time_list), len(hypothetical_strike_price_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_roots = 350\n",
    "# n_roots = 10\n",
    "smoothness_controller = 3.274549162877732e-05\n",
    "\n",
    "# Initialize the RBFQuadraticSmoothnessPrior class\n",
    "smoothness_prior = RBFQuadraticSmoothnessPrior(\n",
    "    maturity_times=maturity_times,\n",
    "    strike_prices=strike_prices,\n",
    "    maturity_std=maturity_std,\n",
    "    strike_std=strike_std,\n",
    "    n_roots=n_roots,\n",
    "    smoothness_controller=smoothness_controller,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "prior_covariance_matrix = smoothness_prior.prior_covariance()\n",
    "prior_eigenvalues = np.sort(np.linalg.eigvalsh(prior_covariance_matrix))[::-1].copy()\n",
    "\n",
    "# The constant_volatility is set to a reasonable value\n",
    "constant_volatility = RBFVolatilitySurface.calculate_constant_volatility(\n",
    "    call_option_dataset[\"Implied Volatility\"],\n",
    "    call_option_dataset[\"Time to Maturity\"],\n",
    "    call_option_dataset[\"Strike Price\"],\n",
    "    risk_free_rate,\n",
    "    underlying_price\n",
    ")\n",
    "\n",
    "sampled_surface_coefficients = smoothness_prior.sample_smooth_surfaces(1000)\n",
    "\n",
    "# Loop through the sampled coefficients \n",
    "sampled_volatilities = []\n",
    "for coefficients in sampled_surface_coefficients:\n",
    "    \n",
    "    # Initialize the RBFVolatilitySurface class for each set of coefficients\n",
    "    rbf_surface = RBFVolatilitySurface(\n",
    "        coefficients=coefficients,\n",
    "        maturity_times=maturity_times,\n",
    "        strike_prices=strike_prices,\n",
    "        maturity_std=maturity_std,\n",
    "        strike_std=strike_std,\n",
    "        constant_volatility=constant_volatility\n",
    "    )\n",
    "\n",
    "    # Generate the volatility surface over the product grid of times and strikes\n",
    "    surface_volatilities = [\n",
    "        rbf_surface.implied_volatility_surface(T, K)\n",
    "        for T, K in product_grid\n",
    "    ]\n",
    "    sampled_volatilities.extend(surface_volatilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 64\n",
    "n_layers = 8\n",
    "batch_size = 100\n",
    "pde_loss_coefficient = 650.0\n",
    "maturity_zero_loss_coefficient = 800.0\n",
    "strike_zero_loss_coefficient = 40.0\n",
    "strike_infinity_loss_coefficient = 200.0\n",
    "pre_train_learning_rate = 1e-3\n",
    "fine_tune_learning_rate = 1e-4\n",
    "pre_train_epochs = 200\n",
    "fine_tune_epochs = 20\n",
    "maturity_min = maturity_time_list.min()\n",
    "maturity_max = maturity_time_list.max()\n",
    "strike_min = strike_price_list.min()\n",
    "strike_max = strike_price_list.max()\n",
    "volatility_mean = np.mean(sampled_volatilities)\n",
    "volatility_std = np.std(sampled_volatilities)\n",
    "strike_infinity = 2.5\n",
    "device = 'cpu'\n",
    "\n",
    "# Initialize the DupirePINNTrainer class\n",
    "torch.manual_seed(0)\n",
    "pinn_trainer = DupirePINNTrainer(\n",
    "    hidden_dim=hidden_dim,\n",
    "    n_layers=n_layers,\n",
    "    batch_size=batch_size,\n",
    "    pde_loss_coefficient=pde_loss_coefficient,\n",
    "    maturity_zero_loss_coefficient=maturity_zero_loss_coefficient,\n",
    "    strike_zero_loss_coefficient=strike_zero_loss_coefficient,\n",
    "    strike_infinity_loss_coefficient=strike_infinity_loss_coefficient,\n",
    "    pre_train_learning_rate=pre_train_learning_rate,\n",
    "    fine_tune_learning_rate=fine_tune_learning_rate,\n",
    "    pre_train_epochs=pre_train_epochs,\n",
    "    fine_tune_epochs=fine_tune_epochs,\n",
    "    maturity_min=maturity_min,\n",
    "    maturity_max=maturity_max,\n",
    "    strike_min=strike_min,\n",
    "    strike_max=strike_max,\n",
    "    volatility_mean=volatility_mean,\n",
    "    volatility_std=volatility_std,\n",
    "    maturity_time_list=maturity_time_list,\n",
    "    strike_price_list=strike_price_list,\n",
    "    strike_std=strike_std,\n",
    "    maturity_std=maturity_std,\n",
    "    constant_volatility=constant_volatility,\n",
    "    strike_infinity=strike_infinity,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "pinn_trainer.load_model()\n",
    "\n",
    "pinn_trainer.dupire_price_prediction_loss(\n",
    "    torch.tensor(sampled_surface_coefficients, device=device, dtype=torch.float32),\n",
    "    call_option_dataset[\"Call Option Price\"],\n",
    "    call_option_dataset[\"Time to Maturity\"],\n",
    "    call_option_dataset[\"Strike Price\"],\n",
    ")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = 100  # Data dimension of input\n",
    "hidden_dim = 512\n",
    "n_layers = 8\n",
    "batch_size = 1000  # Batch size for training\n",
    "beta_ = 1.0  # Beta value for beta-VAE\n",
    "pre_train_learning_rate = 1e-3\n",
    "fine_tune_learning_rate = 1e-4  # Fine-tune learning rate\n",
    "pre_train_epochs = 600  # Number of pre-train epochs\n",
    "fine_tune_epochs = 20  # Number of fine-tune epochs\n",
    "device = \"cpu\"  # Use CPU as the device\n",
    "\n",
    "# List of candidate latent dimensions\n",
    "latent_dimensions = [2, 4, 8, 10, 15, 20, 25, 30, 40, 50, 60, 75]\n",
    "\n",
    "# Initialize dictionaries to store the results for each latent dimension\n",
    "condition_number_percentiles = {}\n",
    "lipschitz_constants = {}\n",
    "\n",
    "# Loop over the candidate latent dimensions\n",
    "for latent_dim in latent_dimensions:\n",
    "    # Initialize the VAE trainer for the current latent dimension\n",
    "    torch.manual_seed(2)\n",
    "    vae_trainer = SurfaceVAETrainer(\n",
    "        latent_dim=latent_dim,\n",
    "        hidden_dim=hidden_dim,  # Keep hidden_dim fixed for all latent dimensions\n",
    "        n_layers=n_layers,\n",
    "        data_dim=data_dim,\n",
    "        latent_diagonal=prior_eigenvalues[:latent_dim],  # Eigenvalues for latent prior\n",
    "        batch_size=batch_size,\n",
    "        beta=beta_,\n",
    "        pre_train_learning_rate=pre_train_learning_rate,\n",
    "        fine_tune_learning_rate=fine_tune_learning_rate,\n",
    "        pre_train_epochs=pre_train_epochs,\n",
    "        fine_tune_epochs=fine_tune_epochs,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # Train the model using pre_train_with_sampling\n",
    "    vae_trainer.pre_train_with_sampling(\n",
    "        smoothness_prior=smoothness_prior,\n",
    "    )\n",
    "\n",
    "    # Sample latent vectors and assess the latent space\n",
    "    # Initialize variables\n",
    "    all_condition_numbers = []\n",
    "    max_lipschitz_constant = float('-inf')  # Start with negative infinity for comparison\n",
    "    # Repeat the process 10 times\n",
    "    for i in range(100):\n",
    "        # Sample latent vectors and assess the latent space\n",
    "        torch.manual_seed(i + 2)  # Update seed for each iteration\n",
    "        latent_samples_batch = sample_latent_vectors(100, prior_eigenvalues[:latent_dim])\n",
    "        \n",
    "        # Assess the latent space for condition numbers and Lipschitz constant\n",
    "        condition_numbers, lipschitz_constant = latent_space_assessment(latent_samples_batch, vae_trainer, pinn_trainer)\n",
    "        \n",
    "        # Extend the condition numbers list with the new condition numbers\n",
    "        all_condition_numbers.extend(condition_numbers)\n",
    "        \n",
    "        # Update the Lipschitz constant by taking the maximum of the current and new value\n",
    "        max_lipschitz_constant = max(max_lipschitz_constant, lipschitz_constant)\n",
    "\n",
    "    # Calculate the percentiles of condition numbers\n",
    "    all_condition_numbers = np.array(all_condition_numbers)\n",
    "    condition_number_percentiles[latent_dim] = {\n",
    "        \"0.5 Percentile\": np.percentile(all_condition_numbers, 50),\n",
    "        \"0.05 Percentile\": np.percentile(all_condition_numbers, 5),\n",
    "        \"0.95 Percentile\": np.percentile(all_condition_numbers, 95),\n",
    "    }\n",
    "\n",
    "    # Record the Lipschitz constant for the current latent dimension\n",
    "    lipschitz_constants[latent_dim] = max_lipschitz_constant\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Latent Dimension: {latent_dim}\")\n",
    "    print(f\"Condition Number Percentiles: {condition_number_percentiles[latent_dim]}\")\n",
    "    print(f\"Lipschitz Constant: {lipschitz_constants[latent_dim]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for plotting\n",
    "latent_dims = list(condition_number_percentiles.keys())\n",
    "condition_medians = [condition_number_percentiles[ld][\"0.5 Percentile\"] for ld in latent_dims]\n",
    "condition_lower = [condition_number_percentiles[ld][\"0.05 Percentile\"] for ld in latent_dims]\n",
    "condition_upper = [condition_number_percentiles[ld][\"0.95 Percentile\"] for ld in latent_dims]\n",
    "lipschitz_values = [lipschitz_constants[ld] for ld in latent_dims]\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add scatter plot for condition number with error bars\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=latent_dims,\n",
    "    y=condition_medians,\n",
    "    mode='lines+markers',\n",
    "    name='Condition Number',\n",
    "    marker=dict(symbol='circle', size=7.5)\n",
    "))\n",
    "\n",
    "# Add scatter plot for Lipschitz constant on secondary y-axis\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=latent_dims,\n",
    "    y=lipschitz_values,\n",
    "    mode='lines+markers',\n",
    "    name='Lipschitz Constant',\n",
    "    yaxis='y2',\n",
    "    marker=dict(symbol='square', size=7.5)\n",
    "))\n",
    "\n",
    "# Update the layout for the double y-axis\n",
    "fig.update_layout(\n",
    "    title=\"Condition Number and Lipschitz Constant vs Latent Dimension\",\n",
    "    xaxis=dict(\n",
    "        title=\"Latent Dimension\",\n",
    "        tickvals=latent_dims,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Condition Number\",\n",
    "        showgrid=True,\n",
    "        zeroline=False,\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title=\"Lipschitz Constant\",\n",
    "        overlaying='y',\n",
    "        side='right',\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0.01, y=0.99,\n",
    "    ),\n",
    "    width=900,\n",
    "    height=900,\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n",
    "fig.write_image('figs/latent_dimension_condition_number_libschitz.png', format='png', scale=4, width=900, height=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 40  # Latent dimension\n",
    "data_dim = 100  # Data dimension of input\n",
    "hidden_dim = 512\n",
    "n_layers = 8\n",
    "latent_diagonal = prior_eigenvalues[:latent_dim]  # Eigenvalues for latent prior\n",
    "batch_size = 1000  # Batch size for training\n",
    "beta_ = 1.0  # Beta value for beta-VAE\n",
    "pre_train_learning_rate = 1e-3\n",
    "fine_tune_learning_rate = 1e-4  # Fine-tune learning rate\n",
    "pre_train_epochs = 600  # Number of pre-train epochs\n",
    "fine_tune_epochs = 20  # Number of fine-tune epochs\n",
    "device = \"cpu\"  # Use CPU as the device\n",
    "\n",
    "torch.manual_seed(2)\n",
    "vae_trainer = SurfaceVAETrainer(\n",
    "    latent_dim=latent_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    n_layers=n_layers,\n",
    "    data_dim=data_dim,\n",
    "    latent_diagonal=latent_diagonal,\n",
    "    batch_size=batch_size,\n",
    "    beta=beta_,\n",
    "    pre_train_learning_rate=pre_train_learning_rate,\n",
    "    fine_tune_learning_rate=fine_tune_learning_rate,\n",
    "    pre_train_epochs=pre_train_epochs,\n",
    "    fine_tune_epochs=fine_tune_epochs,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Train the model using pre_train\n",
    "vae_trainer.pre_train_with_sampling(\n",
    "    smoothness_prior=smoothness_prior,\n",
    ")\n",
    "\n",
    "vae_trainer.save_model()\n",
    "\n",
    "loss_history = pd.DataFrame(vae_trainer.pre_train_loss_history)\n",
    "\n",
    "# Create a subplot figure with 1x2 grid for individual losses, and a second row spanning the entire width for total loss\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=(\"Reconstruction Loss\", \"KL Loss\", \"Total Loss\"),\n",
    "    specs=[[{'type': 'scatter'}, {'type': 'scatter'}],\n",
    "           [{'colspan': 2, 'type': 'scatter'}, None]],\n",
    "    vertical_spacing=0.1,\n",
    "    horizontal_spacing=0.1\n",
    ")\n",
    "\n",
    "# Add traces for individual losses\n",
    "fig.add_trace(go.Scatter(x=loss_history.index, y=loss_history[\"Reconstruction Loss\"], mode=\"lines\", name=\"Reconstruction Loss\"), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=loss_history.index, y=loss_history[\"KL Loss\"], mode=\"lines\", name=\"KL Loss\"), row=1, col=2)\n",
    "\n",
    "# Add a trace for the total loss spanning the entire second row\n",
    "fig.add_trace(go.Scatter(x=loss_history.index, y=loss_history[\"Total Loss\"], mode=\"lines\", name=\"Total Loss\"), row=2, col=1)\n",
    "\n",
    "# Update the layout to include 'Iterations' as the x-axis name for each subplot\n",
    "fig.update_xaxes(title_text=\"Iterations\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Iterations\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Iterations\", row=2, col=1)  # The third row spans two columns\n",
    "\n",
    "fig.update_yaxes(type=\"log\", row=1, col=1)\n",
    "fig.update_yaxes(type=\"log\", row=1, col=2)\n",
    "fig.update_yaxes(type=\"log\", row=2, col=1)  # The third row spans two columns\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(height=900, width=900, title_text=\"Beta-VAE Training Losses\", showlegend=False)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "fig.write_image('figs/vae_training_loss_history.png', format='png', scale=4, width=900, height=900)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
