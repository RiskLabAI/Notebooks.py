{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â­ Tutorial: High-Performance Computing (HPC) with `parallel_run`\n",
    "\n",
    "This notebook demonstrates how to use the `RiskLabAI.hpc.parallel_run` utility to significantly speed up your code by executing it on multiple CPUs.\n",
    "\n",
    "Many tasks in finance, like running a Monte Carlo simulation or backtesting many parameters, are 'embarrassingly parallel'. This means the work can be split into independent jobs and run simultaneously.\n",
    "\n",
    "We will:\n",
    "1.  Define a 'slow' task that simulates a piece of work.\n",
    "2.  Run it **serially** (on 1 CPU) to get a baseline time.\n",
    "3.  Run it **in parallel** using `parallel_run` with both `lin_partition=False` (item-by-item) and `lin_partition=True` (chunked).\n",
    "4.  Compare the execution times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmultiprocessing\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# RiskLabAI Imports\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mRiskLabAI\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhpc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhpc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parallel_run\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mRiskLabAI\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpublication_plots\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpub_plots\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Setup plotting and configuration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hamid\\.conda\\envs\\risklab313\\Lib\\site-packages\\RiskLabAI\\__init__.py:36\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mRiskLabAI: Financial AI with Python\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m    Common helper functions, constants, and plotting utilities.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Import all sub-packages to make them available\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backtest\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m controller\n",
      "File \u001b[1;32mc:\\Users\\Hamid\\.conda\\envs\\risklab313\\Lib\\site-packages\\RiskLabAI\\backtest\\__init__.py:63\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprobability_of_backtest_overfitting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     56\u001b[0m     performance_evaluation,\n\u001b[0;32m     57\u001b[0m     probability_of_backtest_overfitting,\n\u001b[0;32m     58\u001b[0m )\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprobabilistic_sharpe_ratio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     60\u001b[0m     probabilistic_sharpe_ratio,\n\u001b[0;32m     61\u001b[0m     benchmark_sharpe_ratio,\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbacktest_overfitting_simulation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# This file contains many functions, exporting the main ones\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     overall_backtest_overfitting_simulation,\n\u001b[0;32m     66\u001b[0m     temporal_backtest_overfitting_simulation,\n\u001b[0;32m     67\u001b[0m     time_temporal_backtest_overfitting_simulation,\n\u001b[0;32m     68\u001b[0m     varying_embargo_backtest_overfitting_simulation,\n\u001b[0;32m     69\u001b[0m     backtest_overfitting_simulation_financial_metrics_rank_correlation,\n\u001b[0;32m     70\u001b[0m     backtest_overfitting_simulation_model_complexity,\n\u001b[0;32m     71\u001b[0m     noised_backtest_overfitting_simulation,\n\u001b[0;32m     72\u001b[0m     overall_novel_methods_backtest_overfitting_simulation,\n\u001b[0;32m     73\u001b[0m     measure_all_cv_computational_requirements,\n\u001b[0;32m     74\u001b[0m     measure_cpcv_parallelization,\n\u001b[0;32m     75\u001b[0m     measure_cpcv_scalability,\n\u001b[0;32m     76\u001b[0m     get_cpu_info,\n\u001b[0;32m     77\u001b[0m     format_cpu_info,\n\u001b[0;32m     78\u001b[0m )\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Define what `from RiskLabAI.backtest import *` will import\u001b[39;00m\n\u001b[0;32m     81\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# from backtest_statistics\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_cpu_info\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    142\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\Hamid\\.conda\\envs\\risklab313\\Lib\\site-packages\\RiskLabAI\\backtest\\backtest_overfitting_simulation.py:33\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmemory_profiler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m memory_usage\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mRiskLabAI\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdifferentiation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fractionally_differentiated_log_price\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mRiskLabAI\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlabeling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m daily_volatility_with_log_returns, cusum_filter_events_dynamic_threshold, vertical_barrier, meta_events, meta_labeling\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mRiskLabAI\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mweights\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sample_weight_absolute_return_meta_labeling\n",
      "File \u001b[1;32mc:\\Users\\Hamid\\.conda\\envs\\risklab313\\Lib\\site-packages\\RiskLabAI\\data\\__init__.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distance\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m labeling\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structures\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m synthetic_data\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m weights\n",
      "File \u001b[1;32mc:\\Users\\Hamid\\.conda\\envs\\risklab313\\Lib\\site-packages\\RiskLabAI\\data\\structures\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mRiskLabAI Data Structures Module\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Exports from standard_bars.py\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstandard_bars\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardBars\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Exports from time_bars.py\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtime_bars\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeBars\n",
      "File \u001b[1;32mc:\\Users\\Hamid\\.conda\\envs\\risklab313\\Lib\\site-packages\\RiskLabAI\\data\\structures\\standard_bars.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Union, List, Any, Iterable\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mRiskLabAI\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstructures\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabstract_bars\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AbstractBars, TickData\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mStandardBars\u001b[39;00m(AbstractBars):\n\u001b[0;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    Concrete class for Standard Bars (Tick, Volume, Dollar).\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    Generates a new bar whenever a cumulative threshold of ticks,\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    volume, or dollars is reached.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hamid\\.conda\\envs\\risklab313\\Lib\\site-packages\\RiskLabAI\\data\\structures\\abstract_bars.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tuple, Union, List, Any, Dict, Iterable, Optional\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mRiskLabAI\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Type hint for a single tick: (datetime, price, volume)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m TickData \u001b[38;5;241m=\u001b[39m Union[List[Any], Tuple[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], np\u001b[38;5;241m.\u001b[39mndarray]\n",
      "File \u001b[1;32mc:\\Users\\Hamid\\.conda\\envs\\risklab313\\Lib\\site-packages\\RiskLabAI\\utils\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprogress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m progress_bar\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmomentum_mean_reverting_strategy_sides\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m determine_strategy_side\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mupdate_figure_layout\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m update_figure_layout\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpublication_plots\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     setup_publication_style,\n\u001b[0;32m     21\u001b[0m     apply_plot_style,\n\u001b[0;32m     22\u001b[0m     finalize_plot\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# --- Alias for Backward Compatibility ---\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# 'smoothing_average.py' is a duplicate of 'ewma.py'.\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# We import 'ewma' and alias it to 'compute_exponential_weighted_moving_average'\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# to maintain compatibility with modules that imported the old name.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# You can safely delete the 'smoothing_average.py' file.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hamid\\.conda\\envs\\risklab313\\Lib\\site-packages\\RiskLabAI\\utils\\update_figure_layout.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mA helper function to apply a consistent, dark-themed layout\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mto Plotly figures.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mupdate_figure_layout\u001b[39m(\n\u001b[0;32m     10\u001b[0m     fig: go\u001b[38;5;241m.\u001b[39mFigure,\n\u001b[0;32m     11\u001b[0m     title: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     legend_y: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m     16\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "# Standard Imports\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "\n",
    "# RiskLabAI Imports\n",
    "from RiskLabAI.hpc.hpc import parallel_run\n",
    "import RiskLabAI.utils.publication_plots as pub_plots\n",
    "\n",
    "# Setup plotting and configuration\n",
    "pub_plots.setup_publication_style()\n",
    "N_JOBS = 40 # Total number of jobs to run\n",
    "SLEEP_TIME = 0.1 # Each job takes 0.1s\n",
    "jobs_list = list(range(N_JOBS))\n",
    "N_CPUS = multiprocessing.cpu_count()\n",
    "print(f\"Running {N_JOBS} jobs. Expected serial time: {N_JOBS * SLEEP_TIME:.1f}s\")\n",
    "print(f\"Using {N_CPUS} CPUs for parallel execution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Slow Way: Serial Execution\n",
    "\n",
    "First, we define our simple task and run it in a standard `for` loop. This will be our benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_task(item):\n",
    "    \"\"\"A simple task that simulates 0.1s of work.\"\"\"\n",
    "    time.sleep(SLEEP_TIME)\n",
    "    return item * 2\n",
    "\n",
    "\n",
    "print(\"Running serially (1 CPU)...\")\n",
    "start_time_serial = time.time()\n",
    "results_serial = [simple_task(job) for job in jobs_list]\n",
    "end_time_serial = time.time()\n",
    "\n",
    "serial_time = end_time_serial - start_time_serial\n",
    "print(f\"Serial execution took: {serial_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Fast Way: Parallel (Item-by-Item)\n",
    "\n",
    "Now we use `parallel_run` with `lin_partition=False`. \n",
    "\n",
    "The `parallel_run` function handles all the logic: it dispatches one job to each available CPU, waits for it to finish, and dispatches the next, until all jobs are done. Notice that our `simple_task` function is the *exact same* as in the serial version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Running in parallel ({N_CPUS} CPUs, item-by-item)...\")\n",
    "start_time_parallel = time.time()\n",
    "\n",
    "results_parallel = parallel_run(\n",
    "    simple_task, \n",
    "    jobs_list, \n",
    "    lin_partition=False\n",
    ")\n",
    "\n",
    "end_time_parallel = time.time()\n",
    "parallel_time = end_time_parallel - start_time_parallel\n",
    "\n",
    "print(f\"Parallel (item-by-item) execution took: {parallel_time:.2f} seconds\")\n",
    "print(f\"Results match: {results_serial == results_parallel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The 'Chunked' Method (`lin_partition=True`)\n",
    "\n",
    "This is the second mode, which is the default in your original file. Here, `parallel_run` splits the list of 40 jobs into `N_CPUS` chunks. \n",
    "\n",
    "This requires us to write a *different* target function (`chunked_task`) that is designed to receive a *list of indices* (e.g., `[0, 1, 2, 3]`) and loop over them itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunked_task(indices):\n",
    "    \"\"\"\n",
    "    A task designed for lin_partition=True.\n",
    "    It receives a list of *indices* and must process them.\n",
    "    \"\"\"\n",
    "    local_results = []\n",
    "    for idx in indices:\n",
    "        # We get the item from the global 'jobs_list'\n",
    "        item = jobs_list[idx]\n",
    "        result = simple_task(item) # Re-use the 0.1s sleep\n",
    "        local_results.append(result)\n",
    "    return local_results\n",
    "\n",
    "\n",
    "print(f\"Running in parallel ({N_CPUS} CPUs, by chunk)...\")\n",
    "start_time_chunked = time.time()\n",
    "\n",
    "results_chunked = parallel_run(\n",
    "    chunked_task,\n",
    "    jobs_list, # 'jobs_list' is only used for its length here\n",
    "    lin_partition=True\n",
    ")\n",
    "\n",
    "end_time_chunked = time.time()\n",
    "chunked_time = end_time_chunked - start_time_chunked\n",
    "\n",
    "print(f\"Chunked parallel execution took: {chunked_time:.2f} seconds\")\n",
    "print(f\"Results match: {results_serial == results_chunked}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance Comparison\n",
    "\n",
    "Finally, let's plot the results. Both parallel methods should be significantly faster than the serial method. The small difference between the two parallel methods is due to `joblib`'s overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [serial_time, parallel_time, chunked_time]\n",
    "labels = ['Serial (1 CPU)', 'Parallel (Item-by-Item)', 'Parallel (Chunked)']\n",
    "colors = ['#d11141', '#00aedb', '#00b159']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars = ax.bar(labels, times, color=colors)\n",
    "ax.bar_label(bars, fmt='%.2fs')\n",
    "\n",
    "pub_plots.apply_plot_style(\n",
    "    ax,\n",
    "    title='Parallel vs. Serial Execution Time',\n",
    "    xlabel='Execution Method',\n",
    "    ylabel='Time Taken (seconds)'\n",
    ")\n",
    "ax.grid(axis='x') # Turn off vertical grid lines for bar chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risklab313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
