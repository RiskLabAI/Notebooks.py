{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠ê Tutorial: High-Performance Computing (HPC) with `parallel_run`\n",
    "\n",
    "This notebook demonstrates how to use the `RiskLabAI.hpc.parallel_run` utility to significantly speed up your code by executing it on multiple CPUs.\n",
    "\n",
    "Many tasks in finance, like running a Monte Carlo simulation or backtesting many parameters, are 'embarrassingly parallel'. This means the work can be split into independent jobs and run simultaneously.\n",
    "\n",
    "We will:\n",
    "1.  Define a 'slow' task that simulates a piece of work.\n",
    "2.  Run it **serially** (on 1 CPU) to get a baseline time.\n",
    "3.  Run it **in parallel** using `parallel_run` with both `lin_partition=False` (item-by-item) and `lin_partition=True` (chunked).\n",
    "4.  Compare the execution times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "\n",
    "# RiskLabAI Imports\n",
    "from RiskLabAI.hpc.hpc import parallel_run\n",
    "import RiskLabAI.utils.publication_plots as pub_plots\n",
    "\n",
    "# Setup plotting and configuration\n",
    "pub_plots.setup_publication_style()\n",
    "N_JOBS = 40 # Total number of jobs to run\n",
    "SLEEP_TIME = 0.1 # Each job takes 0.1s\n",
    "jobs_list = list(range(N_JOBS))\n",
    "N_CPUS = multiprocessing.cpu_count()\n",
    "print(f\"Running {N_JOBS} jobs. Expected serial time: {N_JOBS * SLEEP_TIME:.1f}s\")\n",
    "print(f\"Using {N_CPUS} CPUs for parallel execution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Slow Way: Serial Execution\n",
    "\n",
    "First, we define our simple task and run it in a standard `for` loop. This will be our benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_task(item):\n",
    "    \"\"\"A simple task that simulates 0.1s of work.\"\"\"\n",
    "    time.sleep(SLEEP_TIME)\n",
    "    return item * 2\n",
    "\n",
    "\n",
    "print(\"Running serially (1 CPU)...\")\n",
    "start_time_serial = time.time()\n",
    "results_serial = [simple_task(job) for job in jobs_list]\n",
    "end_time_serial = time.time()\n",
    "\n",
    "serial_time = end_time_serial - start_time_serial\n",
    "print(f\"Serial execution took: {serial_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Fast Way: Parallel (Item-by-Item)\n",
    "\n",
    "Now we use `parallel_run` with `lin_partition=False`. \n",
    "\n",
    "The `parallel_run` function handles all the logic: it dispatches one job to each available CPU, waits for it to finish, and dispatches the next, until all jobs are done. Notice that our `simple_task` function is the *exact same* as in the serial version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Running in parallel ({N_CPUS} CPUs, item-by-item)...\")\n",
    "start_time_parallel = time.time()\n",
    "\n",
    "results_parallel = parallel_run(\n",
    "    simple_task, \n",
    "    jobs_list, \n",
    "    lin_partition=False\n",
    ")\n",
    "\n",
    "end_time_parallel = time.time()\n",
    "parallel_time = end_time_parallel - start_time_parallel\n",
    "\n",
    "print(f\"Parallel (item-by-item) execution took: {parallel_time:.2f} seconds\")\n",
    "print(f\"Results match: {results_serial == results_parallel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The 'Chunked' Method (`lin_partition=True`)\n",
    "\n",
    "This is the second mode, which is the default in your original file. Here, `parallel_run` splits the list of 40 jobs into `N_CPUS` chunks. \n",
    "\n",
    "This requires us to write a *different* target function (`chunked_task`) that is designed to receive a *list of indices* (e.g., `[0, 1, 2, 3]`) and loop over them itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunked_task(indices):\n",
    "    \"\"\"\n",
    "    A task designed for lin_partition=True.\n",
    "    It receives a list of *indices* and must process them.\n",
    "    \"\"\"\n",
    "    local_results = []\n",
    "    for idx in indices:\n",
    "        # We get the item from the global 'jobs_list'\n",
    "        item = jobs_list[idx]\n",
    "        result = simple_task(item) # Re-use the 0.1s sleep\n",
    "        local_results.append(result)\n",
    "    return local_results\n",
    "\n",
    "\n",
    "print(f\"Running in parallel ({N_CPUS} CPUs, by chunk)...\")\n",
    "start_time_chunked = time.time()\n",
    "\n",
    "results_chunked = parallel_run(\n",
    "    chunked_task,\n",
    "    jobs_list, # 'jobs_list' is only used for its length here\n",
    "    lin_partition=True\n",
    ")\n",
    "\n",
    "end_time_chunked = time.time()\n",
    "chunked_time = end_time_chunked - start_time_chunked\n",
    "\n",
    "print(f\"Chunked parallel execution took: {chunked_time:.2f} seconds\")\n",
    "print(f\"Results match: {results_serial == results_chunked}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance Comparison\n",
    "\n",
    "Finally, let's plot the results. Both parallel methods should be significantly faster than the serial method. The small difference between the two parallel methods is due to `joblib`'s overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [serial_time, parallel_time, chunked_time]\n",
    "labels = ['Serial (1 CPU)', 'Parallel (Item-by-Item)', 'Parallel (Chunked)']\n",
    "colors = ['#d11141', '#00aedb', '#00b159']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars = ax.bar(labels, times, color=colors)\n",
    "ax.bar_label(bars, fmt='%.2fs')\n",
    "\n",
    "pub_plots.apply_plot_style(\n",
    "    ax,\n",
    "    title='Parallel vs. Serial Execution Time',\n",
    "    xlabel='Execution Method',\n",
    "    ylabel='Time Taken (seconds)'\n",
    ")\n",
    "ax.grid(axis='x') # Turn off vertical grid lines for bar chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
