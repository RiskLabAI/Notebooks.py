{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⭐ Tutorial: Weighted Bagging Classifiers\n",
    "\n",
    "This notebook explores advanced bagging techniques from Chapter 6 of 'Advances in Financial Machine Learning' by Marcos López de Prado.\n",
    "\n",
    "A standard `BaggingClassifier` weights all of its estimators (trees) equally. De Prado suggests this may be suboptimal. Some trees in the ensemble may be more 'skilled' than others. We can test two alternative weighting schemes:\n",
    "\n",
    "1.  **`c_i` Weighting:** Give more weight to trees that are more accurate on the *full* training set. ($w_i \\propto c_i$)\n",
    "2.  **Variance Weighting:** Give more weight to trees that are 'less certain'. The variance of a tree's accuracy is proportional to $1 - c_i^2$. ($w_i \\propto 1 - c_i^2$)\n",
    "\n",
    "This notebook will:\n",
    "1.  Use the `RiskLabAI.ensemble.BaggingClassifierAccuracy` class to compare all three weighting schemes.\n",
    "2.  Use the `calculate_bootstrap_accuracy` function to analyze the stability and distribution of the standard classifier's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import from our library\n",
    "from RiskLabAI.ensemble.bagging_classifier_accuracy import (\n",
    "    BaggingClassifierAccuracy,\n",
    "    calculate_bootstrap_accuracy,\n",
    "    plot_bootstrap_accuracy_distribution\n",
    ")\n",
    "import RiskLabAI.utils.publication_plots as pub_plots\n",
    "\n",
    "# Setup plotting\n",
    "pub_plots.setup_publication_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Data\n",
    "\n",
    "We'll create a standard classification dataset to test our classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_informative=5,\n",
    "    n_redundant=2,\n",
    "    n_clusters_per_class=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Convert to DataFrames and Series for easier handling\n",
    "X = pd.DataFrame(X, columns=[f'feat_{i}' for i in range(10)])\n",
    "y = pd.Series(y, name='target')\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Weighted Voting Schemes\n",
    "\n",
    "We instantiate our `BaggingClassifierAccuracy` class and call the `evaluate_all_schemes` method. This single method handles fitting the classifier, calculating the $c_i$ scores for all trees, computing the three sets of weights, and returning the test set accuracy for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_clf = BaggingClassifierAccuracy(\n",
    "    n_estimators=100,\n",
    "    max_samples=100, # Use 100 samples per tree\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "accuracies = weighted_clf.evaluate_all_schemes(\n",
    "    X_test, y_test, X_train, y_train\n",
    ")\n",
    "\n",
    "print(\"Accuracy by Weighting Scheme:\")\n",
    "for scheme, acc in accuracies.items():\n",
    "    print(f\"- {scheme.capitalize()}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** On this synthetic dataset, the weighted schemes perform similarly to the uniform (standard) bagging classifier. This test confirms our implementation works and is ready to be applied to real financial data, where the $c_i$ scores might have a wider distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Bootstrap Accuracy\n",
    "\n",
    "Next, we'll analyze the stability of the standard bagging classifier's accuracy. A model's accuracy score is just a point estimate. By bootstrapping the *test set* 1,000 times, we can build a distribution of accuracy scores to see how stable that estimate is.\n",
    "\n",
    "We use the `calculate_bootstrap_accuracy` function for this. We can access the fitted classifier from the previous step via `weighted_clf.clf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the standard classifier fitted in the previous step\n",
    "standard_clf = weighted_clf.clf\n",
    "\n",
    "a_n_values, a_n_mean, a_n_std = calculate_bootstrap_accuracy(\n",
    "    standard_clf, \n",
    "    X_test, \n",
    "    y_test, \n",
    "    n_bootstraps=1000\n",
    ")\n",
    "\n",
    "print(f\"Mean Accuracy (a_n): {a_n_mean:.4f}\")\n",
    "print(f\"Std Dev of Accuracy (std(a_n)): {a_n_std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Plot the Accuracy Distribution\n",
    "\n",
    "Finally, we use our `plot_bootstrap_accuracy_distribution` utility to visualize this distribution and compare it to a normal distribution with the same mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "plot_bootstrap_accuracy_distribution(\n",
    "    a_n_values, \n",
    "    a_n_mean, \n",
    "    a_n_std, \n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "pub_plots.apply_plot_style(\n",
    "    ax,\n",
    "    title='Distribution of Bootstrapped Accuracies',\n",
    "    xlabel='Accuracy Score',\n",
    "    ylabel='Density'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The distribution of accuracies appears roughly normal, centered around our mean of ~0.90. This gives us confidence in the classifier's performance on the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
