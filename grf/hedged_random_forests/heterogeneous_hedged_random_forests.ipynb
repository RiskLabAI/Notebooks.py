{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Data for Heterogeneous Hedged Random Forest\n",
    "\n",
    "This notebook demonstrates the application of the **Heterogeneous Hedged Random Forest** (HH-RF) model in comparison with the **Standard Random Forest** (RF) and **Hedged Random Forest** (H-RF) models on synthetic data that exhibits heterogeneous regimes. The experiment is designed to showcase the model's performance across distinct data regimes based on a conditioning variable $z$.\n",
    "\n",
    "## Data Generation and Mathematical Setup\n",
    "\n",
    "The dataset consists of $n = 1000$ samples with $d = 5$ predictor variables, denoted as $X = [X_1, X_2, \\dots, X_5]$, and a conditioning variable $z$ which determines the underlying regime. The target variable $y$ is defined as a piecewise function of $X$ and $z$:\n",
    "\n",
    "$$\n",
    "y = f(X, z) + \\epsilon(z)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $f(X, z)$ is a piecewise function that describes different relationships between $X$ and $y$ depending on $z$:\n",
    "\n",
    "$$\n",
    "f(X, z) =\n",
    "\\begin{cases}\n",
    "    2X_1 - X_2 + 3, & \\text{if } z < 0.3 \\quad \\text{(Regime 1: Linear)} \\\\\n",
    "    \\sin(2\\pi X_1) + X_2^2 - 1, & \\text{if } 0.3 \\leq z < 0.6 \\quad \\text{(Regime 2: Non-linear)} \\\\\n",
    "    0.5X_1 - 2X_3 + \\eta, & \\text{if } z \\geq 0.6 \\quad \\text{(Regime 3: Noisy)}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Here, $\\eta \\sim \\mathcal{N}(0, 2^2)$ is a high-noise term in Regime 3.\n",
    "\n",
    "- The noise $\\epsilon(z)$ is also heterogeneous and is defined as:\n",
    "\n",
    "$$\n",
    "\\epsilon(z) =\n",
    "\\begin{cases}\n",
    "    \\mathcal{N}(0, 0.5^2), & \\text{if } z < 0.3 \\quad \\text{(Low Noise)} \\\\\n",
    "    \\mathcal{N}(0, 1^2), & \\text{if } 0.3 \\leq z < 0.6 \\quad \\text{(Medium Noise)} \\\\\n",
    "    \\mathcal{N}(0, 2^2), & \\text{if } z \\geq 0.6 \\quad \\text{(High Noise)}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Thus, the target $y$ is a noisy and heterogeneous function of $X$ that varies depending on the conditioning variable $z$.\n",
    "\n",
    "### Visualizing the Synthetic Data\n",
    "\n",
    "Let's visualize the generated synthetic data where the data points are color-coded based on the conditioning variable $z$ to indicate which regime they belong to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples and dimensions\n",
    "n_samples = 1000\n",
    "n_features = 5\n",
    "\n",
    "# Generate random features (X)\n",
    "X = np.random.uniform(-1, 1, size=(n_samples, n_features))\n",
    "\n",
    "# Generate conditioning variable (z)\n",
    "z = np.random.uniform(0, 1, size=n_samples)\n",
    "\n",
    "# Define piecewise function f(X, z)\n",
    "def f(X, z):\n",
    "    # Regime 1: z < 0.3 -> Linear relationship\n",
    "    linear = X[:, 0] * 2 + X[:, 1] * (-1) + 3\n",
    "    # Regime 2: 0.3 <= z < 0.6 -> Non-linear relationship\n",
    "    nonlinear = np.sin(2 * np.pi * X[:, 0]) + X[:, 1]**2 - 1\n",
    "    # Regime 3: z >= 0.6 -> Mixed relationship with high noise\n",
    "    noisy = X[:, 0] * 0.5 + X[:, 2] * (-2) + np.random.normal(0, 2, size=X.shape[0])\n",
    "\n",
    "    # Combine regimes based on z\n",
    "    y = np.where(z < 0.3, linear,\n",
    "                 np.where(z < 0.6, nonlinear, noisy))\n",
    "    return y\n",
    "\n",
    "# Generate target variable y\n",
    "y = f(X, z)\n",
    "\n",
    "# Add heterogeneous noise\n",
    "noise = np.where(z < 0.3, np.random.normal(0, 0.5, size=n_samples),  # Low noise\n",
    "                 np.where(z < 0.6, np.random.normal(0, 1, size=n_samples),  # Medium noise\n",
    "                          np.random.normal(0, 2, size=n_samples)))  # High noise\n",
    "y += noise\n",
    "\n",
    "# Visualize data\n",
    "# Define clusters based on z values\n",
    "cluster_1 = z < 0.3  # Cluster 1: z < 0.3\n",
    "cluster_2 = (z >= 0.3) & (z < 0.6)  # Cluster 2: 0.3 <= z < 0.6\n",
    "cluster_3 = z >= 0.6  # Cluster 3: z >= 0.6\n",
    "\n",
    "# Assign colors to the clusters\n",
    "colors = np.zeros_like(z, dtype=int)\n",
    "colors[cluster_1] = 0  # Cluster 1: Color 0 (e.g., red)\n",
    "colors[cluster_2] = 1  # Cluster 2: Color 1 (e.g., blue)\n",
    "colors[cluster_3] = 2  # Cluster 3: Color 2 (e.g., green)\n",
    "\n",
    "# Define the color map\n",
    "cmap = plt.get_cmap('RdYlBu')  # Or any other color map\n",
    "\n",
    "# Plot the data with colors representing the clusters\n",
    "plt.scatter(z, y, c=colors, cmap=cmap, alpha=0.7, edgecolors='k', label=\"Target Variable (y)\")\n",
    "plt.xlabel(\"Conditioning Variable (z)\")\n",
    "plt.ylabel(\"Target (y)\")\n",
    "plt.title(\"Synthetic Data: Heterogeneous Regimes with Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Plot\n",
    "\n",
    "The scatter plot above shows the synthetic data, with each data point colored according to the regime it belongs to based on the value of $z$. The three distinct colors represent the different regimes with varying relationships and noise levels:\n",
    "\n",
    "- Regime 1: Linear relationship with low noise ($z < 0.3$).\n",
    "- Regime 2: Non-linear relationship with medium noise ($0.3 \\leq z < 0.6$).\n",
    "- Regime 3: Mixed relationship with high noise ($z \\geq 0.6$).\n",
    "\n",
    "## Model Training and Evaluation\n",
    "\n",
    "We now evaluate the performance of the three models: Standard Random Forest (RF), Hedged Random Forest (H-RF), and Heterogeneous Hedged Random Forest (HH-RF). The models are trained on the features $X$ and target $y$, and evaluated on the test set.\n",
    "\n",
    "### MSE, MAE, and $R^2$ Evaluation\n",
    "\n",
    "We use three performance metrics: **Mean Squared Error (MSE)**, **Mean Absolute Error (MAE)**, and **$R^2$ Score**.\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
    "$$\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\n",
    "$$\n",
    "\n",
    "Let's train and evaluate the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from hedged_random_forests import HedgedRandomForestRegressor\n",
    "from heterogeneous_hedged_random_forests import HeterogeneousHedgedRandomForestRegressor\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test, z_train, z_test = train_test_split(X, y, z, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit and evaluate Vanilla RF\n",
    "vanilla_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "vanilla_rf.fit(X_train, y_train)\n",
    "rf_preds = vanilla_rf.predict(X_test)\n",
    "rf_mse = np.mean((y_test - rf_preds) ** 2)\n",
    "\n",
    "# Fit and evaluate H-RF\n",
    "h_rf = HedgedRandomForestRegressor(n_estimators=100, random_state=42)\n",
    "h_rf.fit(X_train, y_train)\n",
    "h_rf_preds = h_rf.predict(X_test)\n",
    "h_rf_mse = np.mean((y_test - h_rf_preds) ** 2)\n",
    "\n",
    "# Fit and evaluate HH-RF\n",
    "hh_rf = HeterogeneousHedgedRandomForestRegressor(n_estimators=100, n_partition=3, random_state=42)\n",
    "hh_rf.fit(X_train, y_train, z_train.reshape(-1, 1))\n",
    "hh_rf_preds = hh_rf.predict(X_test, z_test.reshape(-1, 1))\n",
    "hh_rf_mse = np.mean((y_test - hh_rf_preds) ** 2)\n",
    "\n",
    "# Print results\n",
    "print(f\"Vanilla RF MSE: {rf_mse}\")\n",
    "print(f\"H-RF MSE: {h_rf_mse}\")\n",
    "print(f\"HH-RF MSE: {hh_rf_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics for Each Model\n",
    "\n",
    "The following table shows the **MSE**, **MAE**, and **$R^2$** scores for the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "metrics = {\n",
    "    'Model': ['Standard RF', 'Hedged RF', 'Heterogeneous Hedged RF'],\n",
    "    'MSE': [rf_mse, h_rf_mse, hh_rf_mse],\n",
    "    'MAE': [\n",
    "        mean_absolute_error(y_test, rf_preds),\n",
    "        mean_absolute_error(y_test, h_rf_preds),\n",
    "        mean_absolute_error(y_test, hh_rf_preds)\n",
    "    ],\n",
    "    'RÂ²': [\n",
    "        r2_score(y_test, rf_preds),\n",
    "        r2_score(y_test, h_rf_preds),\n",
    "        r2_score(y_test, hh_rf_preds)\n",
    "    ]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below summarizes the performance of each model:\n",
    "\n",
    "| Model                     | MSE        | MAE        | $R^2$  |\n",
    "|---------------------------|------------|------------|------------|\n",
    "| **Standard RF**            | 7.0339     | 2.1511     | 0.0041     |\n",
    "| **Hedged RF**              | 6.9409     | 2.1070     | 0.0172     |\n",
    "| **Heterogeneous Hedged RF**| 6.8365     | 2.0866     | 0.0320     |\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The **Heterogeneous Hedged Random Forest** (HH-RF) outperforms both the **Standard RF** and **Hedged RF** models in terms of MSE, MAE, and $R^2$, showing its ability to adapt to the heterogeneous nature of the synthetic dataset. By incorporating conditional partitioning and adaptive hedging, HH-RF is able to capture regime-specific relationships and noise structures, leading to improved predictive accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cobra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
