{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cvxopt import matrix, solvers\n",
    "\n",
    "class HedgedForecastCombination(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Implements hedged forecast combinations by solving a convex optimization problem\n",
    "    to find optimal weights for combining individual forecasts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_models, kappa=2.0, shrinkage='ledoit_wolf'):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - base_models: List of sklearn-like regressors.\n",
    "        - kappa: Gross-exposure constraint parameter.\n",
    "        - shrinkage: Method for covariance estimation ('ledoit_wolf' or 'sample').\n",
    "        \"\"\"\n",
    "        self.base_models = base_models\n",
    "        self.kappa = kappa\n",
    "        self.shrinkage = shrinkage\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the base models and compute optimal weights.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Training features.\n",
    "        - y: Training targets.\n",
    "        \"\"\"\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.n_samples_, self.n_features_ = X.shape\n",
    "        self.p_ = len(self.base_models)\n",
    "\n",
    "        # Fit base models and collect predictions\n",
    "        predictions = np.zeros((self.n_samples_, self.p_))\n",
    "        for idx, model in enumerate(self.base_models):\n",
    "            cloned_model = clone(model)\n",
    "            cloned_model.fit(X, y)\n",
    "            predictions[:, idx] = cloned_model.predict(X)\n",
    "        self.predictions_ = predictions\n",
    "\n",
    "        # Compute residuals\n",
    "        residuals = y.reshape(-1, 1) - self.predictions_\n",
    "\n",
    "        # Estimate mean and covariance of residuals\n",
    "        self.mu_ = residuals.mean(axis=0)\n",
    "        if self.shrinkage == 'ledoit_wolf':\n",
    "            self.Sigma_ = self._ledoit_wolf_shrinkage(residuals)\n",
    "        else:\n",
    "            self.Sigma_ = np.cov(residuals, rowvar=False)\n",
    "\n",
    "        # Solve the optimization problem to find weights\n",
    "        self.weights_ = self._solve_optimization()\n",
    "\n",
    "        # Store fitted base models\n",
    "        self.fitted_models_ = []\n",
    "        for model in self.base_models:\n",
    "            fitted_model = clone(model).fit(X, y)\n",
    "            self.fitted_models_.append(fitted_model)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions using the hedged forecast combination.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Test features.\n",
    "\n",
    "        Returns:\n",
    "        - Combined predictions.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, ['weights_', 'fitted_models_'])\n",
    "        X = check_array(X)\n",
    "\n",
    "        # Collect predictions from base models\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.fitted_models_\n",
    "        ])\n",
    "\n",
    "        # Compute weighted combination\n",
    "        combined_predictions = predictions @ self.weights_\n",
    "        return combined_predictions\n",
    "\n",
    "    def _solve_optimization(self):\n",
    "        \"\"\"\n",
    "        Solve the convex optimization problem to find optimal weights.\n",
    "        \"\"\"\n",
    "        p = self.p_\n",
    "        mu = self.mu_.reshape(-1, 1)\n",
    "        Sigma = self.Sigma_\n",
    "\n",
    "        # Objective: Minimize (w^T mu)^2 + w^T Sigma w\n",
    "        P = 2 * (Sigma + mu @ mu.T)\n",
    "        q = np.zeros((p, 1))\n",
    "\n",
    "        # Constraints\n",
    "        G_list = []\n",
    "\n",
    "        # Gross-exposure constraint: ||w||_1 <= kappa\n",
    "        G_list.append(np.vstack((np.eye(p), -np.eye(p))))\n",
    "        h_list = [self.kappa * np.ones((p, 1)), np.zeros((p, 1))]\n",
    "\n",
    "        # Sum of weights equals 1\n",
    "        A = np.ones((1, p))\n",
    "        b = np.array([[1.0]])\n",
    "\n",
    "        G = np.vstack(G_list)\n",
    "        h = np.vstack(h_list)\n",
    "\n",
    "        # Convert to cvxopt matrices\n",
    "        P_cvx = matrix(P)\n",
    "        q_cvx = matrix(q)\n",
    "        G_cvx = matrix(G)\n",
    "        h_cvx = matrix(h)\n",
    "        A_cvx = matrix(A)\n",
    "        b_cvx = matrix(b)\n",
    "\n",
    "        # Solve the quadratic program\n",
    "        solvers.options['show_progress'] = False\n",
    "        solution = solvers.qp(P_cvx, q_cvx, G_cvx, h_cvx, A_cvx, b_cvx)\n",
    "\n",
    "        weights = np.array(solution['x']).flatten()\n",
    "        return weights\n",
    "\n",
    "    def _ledoit_wolf_shrinkage(self, residuals):\n",
    "        \"\"\"\n",
    "        Estimate the covariance matrix using Ledoit-Wolf shrinkage.\n",
    "\n",
    "        Parameters:\n",
    "        - residuals: Residuals matrix.\n",
    "\n",
    "        Returns:\n",
    "        - Shrinkage covariance matrix.\n",
    "        \"\"\"\n",
    "        from sklearn.covariance import ledoit_wolf\n",
    "        Sigma, _ = ledoit_wolf(residuals)\n",
    "        return Sigma\n",
    "\n",
    "class HedgedRandomForestRegressor(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Implements a hedged random forest by applying hedged forecast combinations\n",
    "    to the individual trees of a random forest.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_estimators=100, max_depth=None, kappa=2.0, shrinkage='ledoit_wolf'):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - n_estimators: Number of trees in the forest.\n",
    "        - max_depth: Maximum depth of the trees.\n",
    "        - kappa: Gross-exposure constraint parameter.\n",
    "        - shrinkage: Method for covariance estimation.\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.kappa = kappa\n",
    "        self.shrinkage = shrinkage\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the hedged random forest.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Training features.\n",
    "        - y: Training targets.\n",
    "        \"\"\"\n",
    "        # Initialize base models (individual trees)\n",
    "        base_models = [\n",
    "            DecisionTreeRegressor(max_depth=self.max_depth, random_state=i)\n",
    "            for i in range(self.n_estimators)\n",
    "        ]\n",
    "\n",
    "        # Create bootstrap samples and fit base models\n",
    "        n_samples = X.shape[0]\n",
    "        predictions = np.zeros((n_samples, self.n_estimators))\n",
    "        for idx, model in enumerate(base_models):\n",
    "            X_sample, y_sample = self._bootstrap_sample(X, y)\n",
    "            model.fit(X_sample, y_sample)\n",
    "            predictions[:, idx] = model.predict(X)\n",
    "        self.predictions_ = predictions\n",
    "\n",
    "        # Compute residuals\n",
    "        residuals = y.reshape(-1, 1) - self.predictions_\n",
    "\n",
    "        # Estimate mean and covariance of residuals\n",
    "        self.mu_ = residuals.mean(axis=0)\n",
    "        if self.shrinkage == 'ledoit_wolf':\n",
    "            self.Sigma_ = self._ledoit_wolf_shrinkage(residuals)\n",
    "        else:\n",
    "            self.Sigma_ = np.cov(residuals, rowvar=False)\n",
    "\n",
    "        # Solve the optimization problem to find weights\n",
    "        self.weights_ = self._solve_optimization()\n",
    "\n",
    "        # Store fitted base models\n",
    "        self.fitted_models_ = base_models\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions using the hedged random forest.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Test features.\n",
    "\n",
    "        Returns:\n",
    "        - Combined predictions.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, ['weights_', 'fitted_models_'])\n",
    "        X = check_array(X)\n",
    "\n",
    "        # Collect predictions from base models\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.fitted_models_\n",
    "        ])\n",
    "\n",
    "        # Compute weighted combination\n",
    "        combined_predictions = predictions @ self.weights_\n",
    "        return combined_predictions\n",
    "\n",
    "    def _bootstrap_sample(self, X, y):\n",
    "        \"\"\"\n",
    "        Generate a bootstrap sample from the training data.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Features.\n",
    "        - y: Targets.\n",
    "\n",
    "        Returns:\n",
    "        - X_sample: Bootstrapped features.\n",
    "        - y_sample: Bootstrapped targets.\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        return X[indices], y[indices]\n",
    "\n",
    "    def _solve_optimization(self):\n",
    "        \"\"\"\n",
    "        Solve the convex optimization problem to find optimal weights.\n",
    "        \"\"\"\n",
    "        p = self.n_estimators\n",
    "        mu = self.mu_.reshape(-1, 1)\n",
    "        Sigma = self.Sigma_\n",
    "\n",
    "        # Objective: Minimize (w^T mu)^2 + w^T Sigma w\n",
    "        P = 2 * (Sigma + mu @ mu.T)\n",
    "        q = np.zeros((p, 1))\n",
    "\n",
    "        # Constraints\n",
    "        G_list = []\n",
    "\n",
    "        # Gross-exposure constraint: ||w||_1 <= kappa\n",
    "        G_list.append(np.vstack((np.eye(p), -np.eye(p))))\n",
    "        h_list = [self.kappa * np.ones((p, 1)), np.zeros((p, 1))]\n",
    "\n",
    "        # Sum of weights equals 1\n",
    "        A = np.ones((1, p))\n",
    "        b = np.array([[1.0]])\n",
    "\n",
    "        G = np.vstack(G_list)\n",
    "        h = np.vstack(h_list)\n",
    "\n",
    "        # Convert to cvxopt matrices\n",
    "        P_cvx = matrix(P)\n",
    "        q_cvx = matrix(q)\n",
    "        G_cvx = matrix(G)\n",
    "        h_cvx = matrix(h)\n",
    "        A_cvx = matrix(A)\n",
    "        b_cvx = matrix(b)\n",
    "\n",
    "        # Solve the quadratic program\n",
    "        solvers.options['show_progress'] = False\n",
    "        solution = solvers.qp(P_cvx, q_cvx, G_cvx, h_cvx, A_cvx, b_cvx)\n",
    "\n",
    "        weights = np.array(solution['x']).flatten()\n",
    "        return weights\n",
    "\n",
    "    def _ledoit_wolf_shrinkage(self, residuals):\n",
    "        \"\"\"\n",
    "        Estimate the covariance matrix using Ledoit-Wolf shrinkage.\n",
    "\n",
    "        Parameters:\n",
    "        - residuals: Residuals matrix.\n",
    "\n",
    "        Returns:\n",
    "        - Shrinkage covariance matrix.\n",
    "        \"\"\"\n",
    "        from sklearn.covariance import ledoit_wolf\n",
    "        Sigma, _ = ledoit_wolf(residuals)\n",
    "        return Sigma\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == '__main__':\n",
    "    # Generate synthetic data\n",
    "    from sklearn.datasets import make_regression\n",
    "    X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize and fit hedged random forest\n",
    "    hrf = HedgedRandomForestRegressor(n_estimators=100, max_depth=None, kappa=2.0, shrinkage='ledoit_wolf')\n",
    "    hrf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = hrf.predict(X_test)\n",
    "\n",
    "    # Evaluate performance\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Hedged Random Forest MSE: {mse:.4f}\")\n",
    "\n",
    "    # Compare with standard Random Forest\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "    print(f\"Standard Random Forest MSE: {mse_rf:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
