{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⭐ Tutorial: Financial Data Structures with RiskLabAI\n",
    "\n",
    "This notebook serves as a tutorial for the `RiskLabAI` library, demonstrating how to convert standard tick data into advanced financial data structures, as described in \"Advances in Financial Machine learning\" by Marcos López de Prado.\n",
    "\n",
    "We will cover:\n",
    "1.  **Standard Bars:** Time, Tick, Volume, and Dollar.\n",
    "2.  **Analysis:** We'll show *why* alternative bars are superior by testing their returns for normality.\n",
    "3.  **Information-Driven Bars:** Imbalance and Run bars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "\n",
    "First, we install and import all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Installation ---\n",
    "# Ensure the RiskLabAI library is installed\n",
    "!pip install RiskLabAI\n",
    "\n",
    "# --- 2. Standard Library Imports ---\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# --- 3. Third-Party Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# --- 4. RiskLabAI Library Imports ---\n",
    "\n",
    "# Import the bar generation classes directly\n",
    "from RiskLabAI.data.structures.standard_bars import StandardBars\n",
    "from RiskLabAI.data.structures.time_bars import TimeBars\n",
    "from RiskLabAI.data.structures.imbalance_bars import ExpectedImbalanceBars, FixedImbalanceBars\n",
    "from RiskLabAI.data.structures.run_bars import ExpectedRunBars, FixedRunBars\n",
    "\n",
    "# Import constants to make our code readable\n",
    "from RiskLabAI.utils.constants import (\n",
    "    CUMULATIVE_DOLLAR, \n",
    "    CUMULATIVE_VOLUME, \n",
    "    CUMULATIVE_TICKS\n",
    ")\n",
    "\n",
    "# --- 5. Notebook Configuration ---\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"darkgrid\")\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "We will use a publicly available tick dataset for the IVE ETF from 2020. The raw data is a list of tick data tuples: `(datetime, price, volume)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from a public URL\n",
    "data_url = \"https://raw.githubusercontent.com/risk-labratory/data/main/IVE_2020.csv\"\n",
    "raw_df = pd.read_csv(data_url, parse_dates=['dates'])\n",
    "\n",
    "# Filter for standard market hours (9:00 - 16:00)\n",
    "raw_df = raw_df[\n",
    "    (raw_df['dates'].dt.hour >= 9) & (raw_df['dates'].dt.hour < 16)\n",
    "]\n",
    "\n",
    "# The bar generation classes expect an iterable of tick data.\n",
    "# We'll create a list of tuples: (datetime, price, volume)\n",
    "# Note: We must sort by date first!\n",
    "raw_df = raw_df.sort_values(by='dates').drop_duplicates()\n",
    "tick_data_iterable = [\n",
    "    (row.dates, row.price, row.size) \n",
    "    for row in raw_df.itertuples(index=False)\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(tick_data_iterable)} ticks.\")\n",
    "\n",
    "# Preview the first 5 ticks\n",
    "print(tick_data_iterable[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Standard Bars\n",
    "\n",
    "Standard bars aggregate ticks by a fixed unit of time, ticks, volume, or dollars.\n",
    "\n",
    "### 2.1. Helper Function\n",
    "\n",
    "We'll create a helper function to convert the list-of-lists output from our library into a clean, labeled `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bars_to_dataframe(bars_list: list) -> pd.DataFrame:\n",
    "    \"\"\"Converts the list output from bar constructors to a DataFrame.\"\"\"\n",
    "    \n",
    "    # These are the column names our library generates\n",
    "    # (from the `_construct_next_bar` method in `abstract_bars.py`)\n",
    "    COL_NAMES = [\n",
    "        'Date Time', 'Tick Index', 'Open', 'High', 'Low', 'Close',\n",
    "        'Cumulative Volume', 'Cumulative Buy Volume', 'Cumulative Sell Volume',\n",
    "        'Cumulative Ticks', 'Cumulative Dollar', 'Threshold'\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(bars_list, columns=COL_NAMES)\n",
    "    df = df.set_index('Date Time')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Time Bars\n",
    "\n",
    "Time bars are the most common, sampling at fixed time intervals (e.g., 15 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiate the TimeBars class\n",
    "# We will sample every 15 minutes\n",
    "time_bar_generator = TimeBars(resolution_type='MIN', resolution_units=15)\n",
    "\n",
    "# 2. Construct the bars\n",
    "time_bars_list = time_bar_generator.construct_bars_from_data(tick_data_iterable)\n",
    "\n",
    "# 3. Convert to a DataFrame\n",
    "time_bars = bars_to_dataframe(time_bars_list)\n",
    "\n",
    "print(f\"Generated {len(time_bars)} 15-minute time bars.\")\n",
    "time_bars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Tick, Volume, and Dollar Bars\n",
    "\n",
    "These bars are all generated by the `StandardBars` class. We just need to change the `bar_type` and `threshold`.\n",
    "\n",
    "To set a reasonable threshold, we'll first calculate the daily averages and sample ~20 bars per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of trading days\n",
    "num_days = len(raw_df['dates'].dt.date.unique())\n",
    "\n",
    "# Calculate daily averages\n",
    "daily_ticks = len(raw_df) / num_days\n",
    "daily_volume = raw_df['size'].sum() / num_days\n",
    "daily_dollar = (raw_df['price'] * raw_df['size']).sum() / num_days\n",
    "\n",
    "# Set thresholds to get ~20 bars per day\n",
    "bars_per_day = 20\n",
    "tick_threshold = daily_ticks / bars_per_day\n",
    "volume_threshold = daily_volume / bars_per_day\n",
    "dollar_threshold = daily_dollar / bars_per_day\n",
    "\n",
    "print(f\"Tick Threshold: {tick_threshold:,.0f}\")\n",
    "print(f\"Volume Threshold: {volume_threshold:,.0f}\")\n",
    "print(f\"Dollar Threshold: {dollar_threshold:,.0f}\")\n",
    "\n",
    "# --- Generate Tick Bars ---\n",
    "tick_bar_generator = StandardBars(\n",
    "    bar_type=CUMULATIVE_TICKS, \n",
    "    threshold=tick_threshold\n",
    ")\n",
    "tick_bars_list = tick_bar_generator.construct_bars_from_data(tick_data_iterable)\n",
    "tick_bars = bars_to_dataframe(tick_bars_list)\n",
    "\n",
    "# --- Generate Volume Bars ---\n",
    "volume_bar_generator = StandardBars(\n",
    "    bar_type=CUMULATIVE_VOLUME, \n",
    "    threshold=volume_threshold\n",
    ")\n",
    "volume_bars_list = volume_bar_generator.construct_bars_from_data(tick_data_iterable)\n",
    "volume_bars = bars_to_dataframe(volume_bars_list)\n",
    "\n",
    "# --- Generate Dollar Bars ---\n",
    "dollar_bar_generator = StandardBars(\n",
    "    bar_type=CUMULATIVE_DOLLAR, \n",
    "    threshold=dollar_threshold\n",
    ")\n",
    "dollar_bars_list = dollar_bar_generator.construct_bars_from_data(tick_data_iterable)\n",
    "dollar_bars = bars_to_dataframe(dollar_bars_list)\n",
    "\n",
    "print(f\"\\nGenerated {len(tick_bars)} Tick Bars\")\n",
    "print(f\"Generated {len(volume_bars)} Volume Bars\")\n",
    "print(f\"Generated {len(dollar_bars)} Dollar Bars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis: Standard Bars\n",
    "\n",
    "Now, we'll replicate the analyses from your original notebook to show *why* Dollar Bars are a superior data structure.\n",
    "\n",
    "### 3.1. Analysis 1: Bar Count Stability\n",
    "\n",
    "Time bars are inconsistent. We get one 15-minute bar even if *nothing happens*. Dollar, Volume, and Tick bars, however, sample more frequently when market activity is high. This plot shows the number of bars generated per week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample each bar type to get the count per week\n",
    "count_df = pd.DataFrame({\n",
    "    'Time': time_bars['Close'].resample('1W').count(),\n",
    "    'Tick': tick_bars['Close'].resample('1W').count(),\n",
    "    'Volume': volume_bars['Close'].resample('1W').count(),\n",
    "    'Dollar': dollar_bars['Close'].resample('1W').count(),\n",
    "}).dropna()\n",
    "\n",
    "\n",
    "# Plot with Plotly\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=count_df.index, y=count_df['Time'], name='Time'))\n",
    "fig.add_trace(go.Scatter(x=count_df.index, y=count_df['Tick'], name='Tick'))\n",
    "fig.add_trace(go.Scatter(x=count_df.index, y=count_df['Volume'], name='Volume'))\n",
    "fig.add_trace(go.Scatter(x=count_df.index, y=count_df['Dollar'], name='Dollar'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Standard Bars Frequency (Bars per Week)\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Frequency (Count)\",\n",
    "    template=\"plotly_dark\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** As expected, Time bars have a perfectly constant frequency. Tick, Volume, and Dollar bars show a huge spike in activity during the March 2020 COVID-19 crash. This shows they are adapting to market volatility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Analysis 2: Normality of Returns\n",
    "\n",
    "The primary goal of these bars is to create a return series that is closer to the \"Normal\" distribution (IID) required by many financial models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log returns\n",
    "returns_df = pd.DataFrame({\n",
    "    'Time': np.log(time_bars['Close']).diff().dropna(),\n",
    "    'Tick': np.log(tick_bars['Close']).diff().dropna(),\n",
    "    'Volume': np.log(volume_bars['Close']).diff().dropna(),\n",
    "    'Dollar': np.log(dollar_bars['Close']).diff().dropna(),\n",
    "})\n",
    "\n",
    "# Standardize (z-score) for a clean comparison\n",
    "standardized_returns = {\n",
    "    'Time': (returns_df['Time'] - returns_df['Time'].mean()) / returns_df['Time'].std(),\n",
    "    'Tick': (returns_df['Tick'] - returns_df['Tick'].mean()) / returns_df['Tick'].std(),\n",
    "    'Volume': (returns_df['Volume'] - returns_df['Volume'].mean()) / returns_df['Volume'].std(),\n",
    "    'Dollar': (returns_df['Dollar'] - returns_df['Dollar'].mean()) / returns_df['Dollar'].std(),\n",
    "}\n",
    "\n",
    "# --- Plot the distributions ---\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.kdeplot(standardized_returns['Time'], label=\"Time Bars\")\n",
    "sns.kdeplot(standardized_returns['Tick'], label=\"Tick Bars\")\n",
    "sns.kdeplot(standardized_returns['Volume'], label=\"Volume Bars\")\n",
    "sns.kdeplot(standardized_returns['Dollar'], label=\"Dollar Bars\")\n",
    "sns.kdeplot(np.random.normal(size=1000000), label=\"Normal (Ref.)\", linestyle=\"--\", color=\"black\")\n",
    "\n",
    "plt.title(\"Distribution of Standardized Log Returns\", fontsize=16)\n",
    "plt.xlim(-5, 5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run the Jarque-Bera Test ---\n",
    "# The null hypothesis is that the data is normally distributed.\n",
    "# A high statistic (and low p-value) means we reject the null.\n",
    "# We want to see a *lower* test statistic.\n",
    "\n",
    "print(\"--- Jarque-Bera Test for Normality ---\")\n",
    "print(f\"(Lower is better)\")\n",
    "\n",
    "jb_time = stats.jarque_bera(returns_df['Time'])\n",
    "jb_tick = stats.jarque_bera(returns_df['Tick'])\n",
    "jb_volume = stats.jarque_bera(returns_df['Volume'])\n",
    "jb_dollar = stats.jarque_bera(returns_df['Dollar'])\n",
    "\n",
    "print(f\"Time Bars:   \\t{jb_time[0]:>10.2f} (p={jb_time[1]:.0f})\")\n",
    "print(f\"Tick Bars:   \\t{jb_tick[0]:>10.2f} (p={jb_tick[1]:.0f})\")\n",
    "print(f\"Volume Bars: \\t{jb_volume[0]:>10.2f} (p={jb_volume[1]:.0f})\")\n",
    "print(f\"Dollar Bars: \\t{jb_dollar[0]:>10.2f} (p={jb_dollar[1]:.0f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The results are clear. The Time bars have a very high Jarque-Bera statistic, showing they are extremely non-normal (high kurtosis, or \"fat tails\"). The **Dollar Bars** have the lowest statistic, and their distribution plot is visibly the closest to the normal reference. This confirms they are the most statistically \"well-behaved\" data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Information-Driven Bars\n",
    "\n",
    "Information-Driven Bars are more advanced. They sample not when a *threshold* is met, but when a *disequilibrium* in trade flow is detected.\n",
    "\n",
    "### 4.1. Imbalance Bars\n",
    "\n",
    "Imbalance bars sample when the cumulative imbalance (e.g., `ticks * tick_sign`) exceeds a dynamic threshold based on the expected number of ticks and the expected imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiate the ExpectedImbalanceBars class\n",
    "# We'll use 'dollar_imbalance' as it's often the most robust.\n",
    "# We'll start with an initial guess of 2,000 ticks per bar (E[T])\n",
    "# and use a 10,000-tick EWMA for the imbalance (E[b]).\n",
    "e_imb_bar_generator = ExpectedImbalanceBars(\n",
    "    bar_type=\"dollar_imbalance\",\n",
    "    window_size_for_expected_n_ticks_estimation=500, # EWMA window for E[T]\n",
    "    initial_estimate_of_expected_n_ticks_in_bar=2000,\n",
    "    window_size_for_expected_imbalance_estimation=10000 # EWMA window for E[b]\n",
    ")\n",
    "\n",
    "# 2. Construct the bars\n",
    "e_imb_bars_list = e_imb_bar_generator.construct_bars_from_data(tick_data_iterable)\n",
    "\n",
    "# 3. Convert to a DataFrame\n",
    "e_imb_bars = bars_to_dataframe(e_imb_bars_list)\n",
    "\n",
    "print(f\"Generated {len(e_imb_bars)} Expected Dollar Imbalance Bars.\")\n",
    "e_imb_bars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Run Bars\n",
    "\n",
    "Run bars are similar but sample when a sequence of *buy* imbalances or *sell* imbalances exceeds a dynamic threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiate the ExpectedRunBars class\n",
    "e_run_bar_generator = ExpectedRunBars(\n",
    "    bar_type=\"dollar_run\",\n",
    "    window_size_for_expected_n_ticks_estimation=500,\n",
    "    initial_estimate_of_expected_n_ticks_in_bar=2000,\n",
    "    window_size_for_expected_imbalance_estimation=10000\n",
    ")\n",
    "\n",
    "# 2. Construct the bars\n",
    "e_run_bars_list = e_run_bar_generator.construct_bars_from_data(tick_data_iterable)\n",
    "\n",
    "# 3. Convert to a DataFrame\n",
    "e_run_bars = bars_to_dataframe(e_run_bars_list)\n",
    "\n",
    "print(f\"Generated {len(e_run_bars)} Expected Dollar Run Bars.\")\n",
    "e_run_bars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "This notebook demonstrated how to use the `RiskLabAI` library to:\n",
    "1.  **Directly instantiate** bar generation classes like `TimeBars`, `StandardBars`, `ExpectedImbalanceBars`, and `ExpectedRunBars`.\n",
    "2.  **Pass an iterable** of tick data to the `construct_bars_from_data` method.\n",
    "3.  **Analyze the results**, confirming that Dollar Bars produce a return series with more \"normal\" statistical properties than standard Time Bars."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
