{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⭐ Tutorial: Financial Asset Clustering with RiskLabAI\n",
    "\n",
    "This notebook is a tutorial for the asset clustering functions in the `RiskLabAI` library, based on Chapter 4 of 'Advances in Financial Machine Learning' by Marcos López de Prado.\n",
    "\n",
    "Clustering is a fundamental step for modern portfolio construction techniques like Hierarchical Risk Parity (HRP). The goal is to identify groups of similar assets *before* optimizing allocations.\n",
    "\n",
    "We will demonstrate:\n",
    "1.  **Data Preparation:** Load real stock data, convert it to returns, and compute the correlation matrix.\n",
    "2.  **Visualizing the Problem:** Show a heatmap of the original, unsorted correlation matrix.\n",
    "3.  **Synthetic Benchmark:** Use `random_block_correlation` to create a synthetic matrix with a *known* cluster structure.\n",
    "4.  **Base K-Means (Snippet 4.1):** Apply the `cluster_k_means_base` algorithm to find the optimal number of clusters based on the silhouette score t-statistic.\n",
    "5.  **Optimized Nested Clustering (ONC) (Snippet 4.2):** Apply the `cluster_k_means_top` function, which recursively re-clusters unstable groups to find a more robust solution.\n",
    "6.  **Visualizing the Solution:** Show heatmaps of the sorted correlation matrices to see the clusters our algorithms uncovered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup and Imports\n",
    "\n",
    "First, we import our libraries and the necessary modules from `RiskLabAI`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# RiskLabAI Imports\n",
    "import RiskLabAI.cluster.clustering as cl\n",
    "import RiskLabAI.utils.publication_plots as pub_plots\n",
    "\n",
    "# --- Notebook Configuration ---\n",
    "pub_plots.setup_publication_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n",
    "\n",
    "We will load daily price data for a list of 30 symbols from Yahoo Finance. To analyze their relationships, we must first convert prices to **percentage returns**.\n",
    "\n",
    "From these returns, we compute the Pearson correlation matrix, which will be the input for our clustering algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"TSLA\", \"META\", \"JPM\", \"UNH\", \"V\", \"JNJ\",\n",
    "    \"HD\", \"WMT\", \"PG\", \"BAC\", \"MA\", \"PFE\", \"DIS\", \"AVGO\", \"XOM\", \"ACM\",\n",
    "    \"CSCO\", \"NFLX\", \"NKE\", \"LLY\", \"KO\", \"TMO\", \"CRM\", \"COST\", \"AAL\", \"X\"\n",
    "]\n",
    "\n",
    "# Download price data\n",
    "all_stocks = pd.DataFrame()\n",
    "for symbol in symbols:\n",
    "    data = pd.Series(\n",
    "        yf.Ticker(symbol).history(start=\"2019-01-01\", end=\"2021-08-08\")[\"Close\"],\n",
    "        name=symbol,\n",
    "    )\n",
    "    if symbol == symbols[0]:\n",
    "        all_stocks = pd.DataFrame(data)\n",
    "    else:\n",
    "        all_stocks[symbol] = data\n",
    "\n",
    "# Convert to percentage returns and compute correlation matrix\n",
    "# We use returns, as correlation of raw prices is often spurious.\n",
    "returns = all_stocks.pct_change(1).dropna()\n",
    "corr_matrix = returns.corr()\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "corr_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualizing the Problem\n",
    "\n",
    "Let's plot a heatmap of the raw correlation matrix. It's difficult to see any clear, defined clusters. The assets are sorted alphabetically, so correlated assets (like `V` and `MA`, or `JPM` and `BAC`) are far apart.\n",
    "\n",
    "The goal of clustering is to re-order this matrix to reveal the hidden block structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, ax=ax, cmap='viridis', vmin=-1, vmax=1)\n",
    "pub_plots.apply_plot_style(ax, 'Original (Unsorted) Correlation Matrix', '', '')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Snippet 4.3: Synthetic Data Benchmark\n",
    "\n",
    "Before we cluster the real data, let's see what a \"perfect\" result would look like. We use `random_block_correlation` to generate a synthetic matrix with **4 known blocks** plus a market component.\n",
    "\n",
    "This is our target. We want our clustering algorithm to find and re-order the real matrix to look like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a synthetic correlation matrix with a known structure\n",
    "synth_corr = cl.random_block_correlation(\n",
    "    n_columns=30, \n",
    "    n_blocks=4, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Plot the synthetic matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(synth_corr, ax=ax, cmap='viridis', vmin=-1, vmax=1)\n",
    "pub_plots.apply_plot_style(ax, 'Synthetic Block Correlation Matrix', '', '')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Snippet 4.1: Base K-Means Clustering\n",
    "\n",
    "The `cluster_k_means_base` function is the first step. It runs K-Means multiple times for different numbers of clusters (k) and uses the **t-statistic of the silhouette scores** to determine the optimal `k`.\n",
    "\n",
    "It returns the sorted matrix, the cluster assignments, and the silhouette scores for each asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_sorted_base, clusters_base, silh_base = cl.cluster_k_means_base(\n",
    "    corr_matrix,\n",
    "    max_clusters=10, \n",
    "    iterations=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Found {len(clusters_base)} clusters with base K-Means:\")\n",
    "from pprint import pprint\n",
    "pprint(clusters_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the heatmap of the matrix sorted by these base clusters. It's much better, but you can see some \"noisy\" assets within the blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(corr_sorted_base, ax=ax, cmap='viridis', vmin=-1, vmax=1)\n",
    "pub_plots.apply_plot_style(ax, 'Correlation Matrix Sorted by Base K-Means', '', '')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Snippet 4.2: Optimized Nested Clustering (ONC)\n",
    "\n",
    "The `cluster_k_means_top` function implements the full **Optimized Nested Clustering (ONC)** algorithm. \n",
    "\n",
    "It works by:\n",
    "1. Running `cluster_k_means_base` (as we did above).\n",
    "2. Identifying \"unstable\" clusters (those with a silhouette t-stat below the average).\n",
    "3. Taking all unstable clusters, grouping them together, and **re-clustering them recursively**.\n",
    "4. Merging the stable clusters with the new sub-clusters.\n",
    "\n",
    "This recursive process results in more stable and homogeneous clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_sorted_onc, clusters_onc, silh_onc = cl.cluster_k_means_top(\n",
    "    corr_matrix, \n",
    "    max_clusters=10, \n",
    "    iterations=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Found {len(clusters_onc)} clusters with Optimized Nested Clustering (ONC):\")\n",
    "pprint(clusters_onc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the final heatmap. The resulting clusters are tighter and make more intuitive sense. For example, `AAL` (Airlines) and `X` (US Steel) are now isolated, while the financial (`JPM`, `BAC`, `V`, `MA`) and tech (`AAPL`, `MSFT`, `GOOG`, `CRM`) groups are more clearly defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(corr_sorted_onc, ax=ax, cmap='viridis', vmin=-1, vmax=1)\n",
    "pub_plots.apply_plot_style(ax, 'Correlation Matrix Sorted by ONC (cluster_k_means_top)', '', '')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "This notebook demonstrated the use of the `RiskLabAI.cluster` module to identify hidden structures in financial data.\n",
    "\n",
    "1.  We started with a messy, alphabetized correlation matrix from real stock returns.\n",
    "2.  We benchmarked our goal by creating a `random_block_correlation` matrix with a known structure.\n",
    "3.  We applied `cluster_k_means_base`, which found an optimal `k` but produced slightly noisy clusters.\n",
    "4.  We used the more advanced **Optimized Nested Clustering (ONC)** via `cluster_k_means_top`, which recursively refined the clusters to produce a much cleaner, more stable, and more intuitive block structure.\n",
    "\n",
    "This sorted matrix and its corresponding cluster list are the essential inputs for the Hierarchical Risk Parity (HRP) portfolio optimization algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
